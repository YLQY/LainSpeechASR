encoder.embed.conv.0.weight-torch.Size([32, 1, 3, 3])-torch.float32
tensor([[[[ 2.8281e-02, -2.7699e-02,  2.6628e-02],
          [ 3.7427e-02, -6.8776e-02,  3.5076e-02],
          [-8.1822e-03, -1.4228e-01, -6.3911e-03]]],


        [[[-8.0671e-02, -1.2025e-01, -3.6727e-02],
          [ 4.3224e-03, -3.5225e-02, -6.1420e-02],
          [ 8.7680e-02,  1.4939e-01,  1.2412e-01]]],


        [[[ 4.3368e-02, -7.6936e-02, -4.6976e-03],
          [ 9.6892e-02,  9.5786e-02, -1.7138e-01],
          [-1.1007e-01,  2.1329e-01, -7.5868e-02]]],


        [[[-2.7891e-02, -1.5570e-01,  1.9808e-01],
          [ 1.4609e-04, -1.9748e-01,  1.8413e-01],
          [ 7.2242e-03, -1.5053e-01,  1.2959e-01]]],


        [[[-4.4264e-02,  2.3409e-02, -1.1173e-01],
          [-6.9889e-03, -1.1951e-02, -1.1058e-01],
          [-3.1886e-03,  6.2456e-02, -1.0968e-01]]],


        [[[-1.6611e-01,  2.1647e-01, -4.6127e-02],
          [-5.1344e-03,  1.5088e-01, -1.2489e-01],
          [ 3.2370e-02,  9.9561e-03, -6.0729e-02]]],


        [[[ 9.6451e-02, -2.1287e-01, -1.4955e-01],
          [-9.3886e-02,  2.1015e-01,  1.5549e-01],
          [-4.0488e-03,  3.1298e-03, -5.2156e-03]]],


        [[[-8.8027e-02,  7.9314e-02,  3.1330e-02],
          [-6.1430e-02,  9.9053e-02,  3.7364e-02],
          [-8.9874e-02, -2.0584e-03,  2.6392e-02]]],


        [[[ 8.0293e-02,  2.5295e-01,  1.5702e-01],
          [-1.2059e-01, -2.0301e-01, -1.8203e-01],
          [ 4.1845e-03, -2.7656e-02,  2.2286e-02]]],


        [[[ 1.1467e-02,  2.2922e-02,  2.2407e-02],
          [ 1.0667e-01,  1.1142e-01,  9.2559e-02],
          [-1.0899e-01, -1.3009e-01, -9.6507e-02]]],


        [[[ 1.7477e-01, -1.0215e-01, -7.2330e-02],
          [ 2.1240e-01, -1.9141e-01, -2.0787e-02],
          [ 1.0503e-01, -1.1909e-01,  2.4541e-02]]],


        [[[-1.7242e-01,  1.8808e-02,  3.9106e-03],
          [ 8.0011e-03,  4.5030e-03,  9.4728e-03],
          [ 2.2297e-02,  9.8699e-03, -3.0434e-03]]],


        [[[-7.5374e-03,  3.3588e-02, -1.1148e-01],
          [-2.5706e-02, -9.1995e-02,  3.8814e-01],
          [ 6.2669e-03,  2.9243e-02, -1.6165e-01]]],


        [[[-6.5611e-02, -3.3822e-02,  5.3282e-02],
          [-1.2681e-02,  1.1208e-01,  4.1144e-02],
          [-3.1472e-02, -4.0583e-02, -5.2230e-02]]],


        [[[-1.4246e-01, -1.2307e-01,  3.9355e-01],
          [-1.7405e-02,  2.3666e-02, -3.7799e-02],
          [ 2.1863e-02,  1.7114e-02, -6.5271e-02]]],


        [[[ 5.0815e-03, -3.0668e-03,  1.6940e-03],
          [-1.7799e-02, -2.6311e-01, -8.9429e-02],
          [ 4.0412e-03,  2.7845e-01,  8.4930e-02]]],


        [[[ 6.4476e-02,  9.4775e-02,  1.5040e-01],
          [-7.6874e-02, -9.9931e-02, -1.3564e-01],
          [ 1.2168e-02, -1.7209e-02,  5.6789e-03]]],


        [[[ 5.0247e-03,  1.2210e-02,  3.6344e-02],
          [-7.7063e-03, -3.6716e-02,  1.0114e-02],
          [-3.5949e-02, -1.5451e-02, -1.5578e-02]]],


        [[[ 5.2664e-02,  1.0525e-01,  8.7135e-02],
          [ 1.7904e-02, -7.4689e-02, -7.4528e-02],
          [-5.1297e-02, -1.5124e-02, -1.3729e-02]]],


        [[[ 3.0861e-03, -3.7559e-02, -3.4428e-03],
          [-6.6562e-02, -3.2269e-02, -7.4253e-02],
          [ 4.6941e-02,  5.3148e-02,  5.9143e-02]]],


        [[[-4.8629e-02, -6.5419e-03, -3.3253e-02],
          [-7.6261e-04,  5.7698e-02,  8.1814e-02],
          [-2.5814e-02, -5.7825e-03,  3.2262e-02]]],


        [[[ 7.1919e-03, -7.5646e-02, -7.1036e-03],
          [-1.4661e-01,  4.4946e-01, -1.1659e-01],
          [ 3.2673e-03, -7.8687e-02,  1.3195e-02]]],


        [[[ 3.5179e-02, -8.2815e-02,  8.7890e-02],
          [ 4.5238e-02, -1.8372e-01,  7.8621e-02],
          [ 4.3834e-02, -1.1101e-01,  1.0311e-01]]],


        [[[ 1.6163e-01, -1.7646e-01,  1.0805e-02],
          [ 2.0785e-01, -2.1905e-01, -7.5099e-03],
          [ 1.6129e-01, -1.5847e-01, -4.2323e-03]]],


        [[[-6.2403e-03, -1.2517e-02, -1.5031e-02],
          [ 1.2037e-02, -1.6211e-02, -2.5693e-02],
          [-1.0218e-02, -1.0678e-03, -1.0137e-02]]],


        [[[ 1.4176e-02, -1.7822e-01,  1.5038e-01],
          [-2.2164e-02, -1.8115e-01,  2.1203e-01],
          [-5.3569e-02, -4.8721e-02,  1.1951e-01]]],


        [[[-1.1206e-01,  3.6982e-01, -1.1426e-01],
          [-1.8434e-02, -5.9775e-02,  1.3887e-02],
          [ 4.6344e-03, -4.3933e-02,  1.8468e-02]]],


        [[[-1.4308e-01, -1.5574e-01,  1.2645e-01],
          [ 1.3544e-01,  1.7037e-01, -1.2864e-01],
          [ 2.0283e-03, -7.8836e-03,  2.2718e-03]]],


        [[[ 1.5424e-02,  5.9988e-02, -9.0445e-02],
          [ 3.4093e-02,  9.0047e-02, -9.3640e-02],
          [ 2.1575e-02,  7.9359e-02, -8.7696e-02]]],


        [[[-5.8187e-02, -8.3598e-02,  1.3504e-01],
          [ 1.0217e-01, -1.9957e-01,  7.2323e-02],
          [ 1.6383e-01, -7.7397e-02, -4.9624e-02]]],


        [[[-9.3133e-02,  3.6078e-03,  1.5040e-02],
          [-3.9862e-02,  4.4314e-02,  3.6838e-02],
          [ 2.9818e-02, -6.9065e-03,  6.7868e-02]]],


        [[[ 5.3078e-02,  8.0249e-03,  4.6328e-02],
          [ 1.2415e-02,  3.8341e-02,  4.1904e-02],
          [ 1.8986e-02,  6.1435e-03,  5.0470e-02]]]], requires_grad=True)

encoder.embed.conv.0.bias-torch.Size([32])-torch.float32
tensor([-0.0588,  0.1118, -0.0444, -0.1469, -0.1650, -0.0098,  0.0003,  0.1899,
        -0.2212,  0.1280,  0.1323,  0.1087, -0.0661,  0.1281, -0.0199, -0.0006,
         0.1127,  0.1800,  0.0666,  0.0490,  0.1494, -0.0659,  0.1437, -0.1674,
         0.2173,  0.1247, -0.0611, -0.0004,  0.1642,  0.0165,  0.1866,  0.1470],
       requires_grad=True)

encoder.embed.conv.2.weight-torch.Size([32, 32, 3, 3])-torch.float32
tensor([[[[ 1.8204e-02, -5.2158e-02, -4.8448e-02],
          [-7.1113e-02, -8.1134e-02, -1.6353e-02],
          [-7.2939e-03,  2.2176e-02,  1.5995e-04]],

         [[-3.5111e-02, -3.4808e-02,  2.1039e-02],
          [-5.5445e-02, -4.0192e-02, -7.6962e-02],
          [-2.7434e-02,  1.1192e-02, -8.4809e-02]],

         [[ 1.0397e-01,  1.7122e-01,  1.2563e-01],
          [-1.0217e-01, -1.6466e-01,  2.3367e-02],
          [-6.1511e-02, -1.2387e-01, -4.6171e-02]],

         ...,

         [[-3.7407e-03,  1.0864e-01,  1.2611e-01],
          [-4.2543e-02, -1.5433e-01, -1.1406e-01],
          [-6.6199e-02, -3.5355e-02,  3.2631e-03]],

         [[-8.2081e-02,  1.4603e-02,  6.7290e-02],
          [-9.0901e-02,  6.0366e-02, -4.8847e-02],
          [ 7.6458e-03, -1.6877e-02, -1.1691e-02]],

         [[ 6.1591e-02,  1.2230e-01,  3.4003e-03],
          [-2.2699e-02, -7.0114e-03,  3.4395e-02],
          [-7.0724e-02,  2.9885e-02, -2.5598e-02]]],


        [[[ 5.9693e-02, -2.1930e-03, -1.2545e-01],
          [ 2.3712e-02,  1.3126e-02, -7.8637e-02],
          [-2.7178e-02,  4.8270e-02, -4.2695e-03]],

         [[-2.8600e-02,  1.4138e-02,  3.5371e-02],
          [-8.8985e-03,  1.5067e-02,  3.2240e-02],
          [ 2.1768e-02, -4.7809e-02,  1.5361e-02]],

         [[-5.1563e-02, -2.1586e-02,  1.1000e-01],
          [-5.4162e-02, -9.6695e-03,  2.2621e-01],
          [-6.5609e-02,  4.9177e-02,  9.4328e-02]],

         ...,

         [[-7.3670e-03, -1.7100e-02,  2.5227e-01],
          [ 2.9250e-02, -5.4798e-02,  3.2825e-01],
          [ 3.4764e-02, -1.0572e-02,  1.1206e-01]],

         [[-4.4700e-02,  4.2805e-02, -6.3344e-02],
          [-5.7789e-02,  9.3671e-02,  1.0449e-02],
          [-3.8121e-02, -3.7089e-02, -1.1370e-02]],

         [[-9.0184e-02,  3.3424e-02, -1.7379e-02],
          [-3.5152e-02, -6.4466e-02,  5.7071e-02],
          [-6.9767e-02,  7.2489e-02,  8.9247e-02]]],


        [[[ 1.4062e-02, -4.7962e-02,  3.5177e-02],
          [ 4.7840e-02,  1.1924e-01,  6.2704e-02],
          [-2.6666e-02, -9.2536e-02,  9.2153e-03]],

         [[-9.3786e-04, -5.5555e-02,  1.3299e-02],
          [ 1.1930e-01,  1.5428e-01,  1.3902e-02],
          [ 3.1662e-02,  1.2229e-01,  4.8194e-02]],

         [[-4.8027e-02, -2.8040e-02, -3.5862e-02],
          [-4.7284e-02, -8.3414e-02, -6.7939e-02],
          [ 5.5148e-02,  3.5960e-02,  3.6997e-02]],

         ...,

         [[-4.3893e-02,  4.2237e-02,  2.8093e-02],
          [ 4.5396e-02, -1.2777e-02, -2.4299e-02],
          [ 2.1986e-02,  5.5258e-02,  8.9167e-02]],

         [[ 7.5344e-02,  1.2493e-02,  1.2997e-02],
          [ 4.5211e-02,  2.4291e-02,  1.4411e-02],
          [ 3.7583e-02,  2.3755e-02,  7.4493e-03]],

         [[ 2.3369e-02, -1.5144e-02, -3.9675e-02],
          [ 2.2564e-02,  3.6950e-02, -4.7449e-02],
          [ 1.0134e-01,  1.0939e-01, -3.9211e-02]]],


        ...,


        [[[ 2.7996e-02, -1.3591e-01,  1.0434e-02],
          [ 2.0795e-02, -7.0358e-03, -6.4043e-03],
          [ 5.3471e-02, -4.7071e-03,  5.7441e-02]],

         [[-1.1474e-01, -2.7065e-01, -6.1195e-02],
          [-3.3103e-02, -6.8744e-02, -1.0273e-02],
          [-2.7423e-02, -6.0461e-02, -3.5074e-02]],

         [[-1.1465e-01,  5.0413e-02,  3.3917e-02],
          [ 1.1261e-01, -3.2045e-03, -1.5865e-02],
          [ 7.6574e-02,  1.5291e-02,  1.2045e-02]],

         ...,

         [[-9.2340e-02,  8.2865e-02,  9.0175e-02],
          [ 8.8232e-03,  4.3238e-02,  1.4137e-02],
          [ 4.9650e-02,  7.4517e-02, -1.3672e-02]],

         [[-6.2105e-02, -5.4604e-02, -5.6310e-02],
          [-3.8908e-02, -6.8513e-02,  5.3209e-02],
          [-4.4794e-02, -2.0973e-02,  8.0873e-02]],

         [[ 3.6721e-02,  1.9826e-01,  4.8729e-02],
          [ 4.9870e-02,  8.2276e-03,  1.2841e-02],
          [ 1.9100e-02, -6.5530e-02, -1.7927e-02]]],


        [[[-2.0878e-02, -7.4712e-02, -5.3617e-02],
          [-1.0098e-03, -1.7988e-02, -3.2778e-02],
          [ 2.0794e-02, -8.3886e-03,  1.2397e-02]],

         [[ 1.8082e-02,  6.1983e-02,  1.2239e-01],
          [-1.0759e-02, -2.2400e-02, -3.3534e-02],
          [-3.6620e-03,  3.4017e-02, -2.5963e-02]],

         [[ 9.7783e-02,  2.6147e-01,  1.9341e-01],
          [-1.9832e-02,  6.1880e-02,  8.8750e-02],
          [ 2.0246e-02, -4.9274e-02, -2.2390e-02]],

         ...,

         [[ 3.5212e-02,  1.6486e-01,  1.9462e-01],
          [-6.5590e-02, -4.6892e-02,  1.0546e-01],
          [-2.1897e-02, -4.1346e-02, -5.7660e-03]],

         [[ 5.9795e-02,  3.5519e-02, -1.9161e-02],
          [ 1.3771e-02, -5.7121e-02,  7.0808e-02],
          [ 6.1016e-02, -1.0612e-01, -2.2074e-02]],

         [[-2.4993e-02,  5.4141e-02,  1.4615e-02],
          [-3.7635e-02,  5.9712e-02,  4.0527e-02],
          [ 4.3187e-02,  5.9505e-02,  3.4122e-02]]],


        [[[ 7.2387e-02,  4.2768e-02, -4.3008e-02],
          [ 4.3203e-02, -7.7966e-03, -3.7521e-02],
          [-2.8231e-02, -1.9483e-02, -9.8038e-02]],

         [[ 4.5719e-02,  5.0059e-02, -2.5645e-02],
          [ 2.9091e-02,  8.2779e-02,  1.1062e-01],
          [ 3.7896e-02,  8.5312e-02,  8.6228e-02]],

         [[-2.4237e-02,  2.7226e-02,  3.8241e-02],
          [ 1.0466e-01,  8.6055e-02,  9.3714e-02],
          [ 1.8000e-02,  3.9410e-02, -5.3105e-03]],

         ...,

         [[-9.3177e-03, -6.5313e-02, -2.4098e-02],
          [ 8.9902e-02,  5.2880e-02, -4.9554e-03],
          [-3.2257e-02, -1.8571e-02, -4.8637e-02]],

         [[-2.7976e-02, -2.1017e-02, -8.7401e-02],
          [-4.1889e-02, -3.4969e-02, -7.0309e-02],
          [-1.3035e-03, -1.0156e-02,  3.5389e-02]],

         [[-5.4118e-02, -2.2645e-02, -4.6540e-02],
          [ 2.1215e-02, -5.2648e-02,  2.4486e-02],
          [ 1.1740e-01,  1.2886e-02,  1.4253e-01]]]], requires_grad=True)

encoder.embed.conv.2.bias-torch.Size([32])-torch.float32
tensor([ 0.0181, -0.0162,  0.0613,  0.0213,  0.0261, -0.0328, -0.0034, -0.0497,
         0.0496,  0.0083,  0.0346,  0.0412,  0.0039, -0.0222,  0.0314, -0.0734,
         0.0220, -0.0246,  0.0559, -0.0034, -0.0028, -0.0334,  0.0394, -0.0166,
        -0.0574, -0.0316,  0.0568,  0.0078, -0.0119,  0.0097, -0.0253,  0.0375],
       requires_grad=True)

encoder.embed.out.0.weight-torch.Size([1280, 608])-torch.float32
tensor([[-1.9076e-02, -1.1854e-01, -1.1678e-01,  ..., -6.0192e-02,
          8.5767e-02,  1.1013e-01],
        [ 1.7268e-02, -3.0861e-02, -2.6437e-02,  ...,  1.1654e-02,
          4.9727e-02,  2.7499e-02],
        [-4.3208e-02,  7.9016e-02, -7.3907e-02,  ..., -7.4144e-03,
         -5.2365e-02,  4.5270e-02],
        ...,
        [-7.5653e-02, -4.6413e-02, -4.2725e-02,  ...,  4.4384e-02,
          4.8182e-02, -5.9737e-03],
        [ 8.7144e-02,  4.2777e-02, -1.0328e-01,  ...,  1.5133e-02,
          9.7764e-03,  7.9517e-02],
        [ 4.0778e-03,  8.2760e-02, -1.4450e-02,  ..., -9.2484e-03,
         -4.9798e-05,  3.6978e-02]], requires_grad=True)

encoder.embed.out.0.bias-torch.Size([1280])-torch.float32
tensor([-0.0185, -0.0731, -0.0571,  ..., -0.0372,  0.0148,  0.0129],
       requires_grad=True)

encoder.encoders.0.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.7978, 0.8321, 0.8183,  ..., 0.8867, 0.9822, 0.8301],
       requires_grad=True)

encoder.encoders.0.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.0524,  0.0238,  0.0813,  ...,  0.0048,  0.1505,  0.0437],
       requires_grad=True)

encoder.encoders.0.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0039,  0.0218, -0.0704,  ...,  0.0742, -0.0140, -0.0394],
        [ 0.0625, -0.0180, -0.0400,  ...,  0.0098,  0.0076,  0.0073],
        [ 0.0036,  0.0321,  0.0459,  ...,  0.0715,  0.0018, -0.0236],
        ...,
        [ 0.0112, -0.0296, -0.0627,  ...,  0.0621, -0.0274, -0.0867],
        [ 0.0118,  0.0089, -0.0226,  ...,  0.0483, -0.0673,  0.0587],
        [-0.0101,  0.0549, -0.0760,  ..., -0.0126,  0.0391, -0.0277]],
       requires_grad=True)

encoder.encoders.0.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0322, -0.0061, -0.0394,  ..., -0.0376,  0.0003, -0.0513],
       requires_grad=True)

encoder.encoders.0.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0106, -0.0265,  0.0727,  ..., -0.0095, -0.0312,  0.0215],
        [ 0.0247,  0.0745,  0.0500,  ..., -0.0866, -0.0667,  0.0403],
        [ 0.0229, -0.0145, -0.0121,  ...,  0.0232, -0.0042, -0.0142],
        ...,
        [ 0.0343, -0.0170, -0.0411,  ..., -0.0172,  0.0216, -0.0215],
        [-0.0437,  0.0328, -0.0588,  ...,  0.0198,  0.0250, -0.0076],
        [-0.0118, -0.0440,  0.0408,  ..., -0.0335,  0.0524, -0.0306]],
       requires_grad=True)

encoder.encoders.0.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.1003,  0.0371,  0.0157,  ...,  0.0178,  0.0776, -0.0269],
       requires_grad=True)

encoder.encoders.0.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.0280,  0.0855, -0.1191,  ...,  0.0856,  0.2689,  0.1109],
        [-0.1491,  0.0644,  0.0655,  ...,  0.3202, -0.1302, -0.0756],
        [ 0.2431,  0.0845,  0.1974,  ..., -0.2450,  0.0689, -0.2949],
        ...,
        [-0.0733,  0.0431, -0.1403,  ...,  0.2047,  0.1575, -0.2656],
        [ 0.0693,  0.3105,  0.3337,  ...,  0.0086, -0.0441,  0.2172],
        [ 0.2790, -0.1262,  0.1271,  ..., -0.0306, -0.2197,  0.1210]],
       requires_grad=True)

encoder.encoders.0.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 0.0907, -0.0650, -0.0315,  ...,  0.0897,  0.1281,  0.1405],
        [ 0.3353,  0.0148,  0.0188,  ...,  0.0649, -0.2202,  0.3754],
        [-0.0508, -0.0227,  0.1885,  ...,  0.1253, -0.2569,  0.2946],
        ...,
        [-0.1028, -0.0576,  0.2420,  ..., -0.0831,  0.0263,  0.3224],
        [ 0.3756, -0.0055,  0.2608,  ...,  0.0434, -0.1858,  0.1051],
        [-0.1069,  0.1762,  0.0143,  ...,  0.0297, -0.3720,  0.0052]],
       requires_grad=True)

encoder.encoders.0.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0322,  0.0256,  0.0006,  ...,  0.0638,  0.0083, -0.0413],
        [-0.0178,  0.0273, -0.0132,  ..., -0.0074,  0.0186, -0.0418],
        [-0.0213, -0.0137,  0.0197,  ...,  0.0778, -0.0209, -0.0196],
        ...,
        [-0.0686,  0.0293, -0.0069,  ..., -0.0400, -0.0013,  0.0499],
        [ 0.0232, -0.0347,  0.0614,  ...,  0.0263,  0.0568,  0.0324],
        [ 0.0481, -0.0135, -0.0216,  ..., -0.0129, -0.0359,  0.0684]],
       requires_grad=True)

encoder.encoders.0.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0077, -0.0805, -0.0556,  ..., -0.0420, -0.0038,  0.0080],
        [-0.0599, -0.0449, -0.0391,  ..., -0.0235, -0.0061, -0.0277],
        [-0.0089, -0.0445,  0.0374,  ...,  0.0520,  0.0262,  0.0238],
        ...,
        [-0.0325,  0.0038, -0.0558,  ..., -0.0206,  0.0174, -0.0368],
        [ 0.0570, -0.1027, -0.1240,  ..., -0.0188,  0.0853, -0.0265],
        [-0.0221,  0.0405,  0.0175,  ...,  0.0637,  0.0014,  0.0663]],
       requires_grad=True)

encoder.encoders.0.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0277,  0.0700, -0.0609,  ..., -0.0683,  0.1286, -0.1129],
        [-0.0010, -0.0648,  0.0147,  ...,  0.0437, -0.0318,  0.0312],
        [ 0.0107, -0.0786, -0.0669,  ...,  0.0432,  0.0243,  0.0347],
        ...,
        [-0.0562, -0.0146,  0.0379,  ..., -0.0046,  0.0058, -0.0013],
        [ 0.1587,  0.0384, -0.0813,  ...,  0.0119,  0.0512, -0.0268],
        [ 0.0384,  0.0278,  0.0602,  ..., -0.0306,  0.0126,  0.0486]],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.3860, 0.2878, 0.3624,  ..., 0.4368, 0.4475, 0.3944],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0411, -0.0327,  0.0195,  ..., -0.0019,  0.0327,  0.0067],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.6319, 0.5122, 0.7641,  ..., 0.7765, 0.7220, 0.7098],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0013, -0.0544, -0.0321,  ...,  0.0071, -0.0268,  0.0031],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6084, 0.5610, 0.7003,  ..., 0.6364, 0.7914, 0.7070],
       requires_grad=True)

encoder.encoders.0.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0448,  0.0306, -0.0119,  ..., -0.0094,  0.0133,  0.0149],
       requires_grad=True)

encoder.encoders.0.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0719,  0.0491,  0.0330,  ...,  0.0232,  0.0027, -0.0138],
        [-0.0655,  0.0129,  0.0647,  ..., -0.0371, -0.0299, -0.0671],
        [ 0.0569, -0.0158,  0.0008,  ...,  0.0709, -0.0404, -0.0366],
        ...,
        [-0.0332, -0.0317, -0.0732,  ...,  0.0670,  0.0123,  0.0365],
        [-0.0406, -0.1014, -0.0028,  ..., -0.0662,  0.0070, -0.0472],
        [ 0.0153, -0.0643,  0.0221,  ..., -0.0369, -0.0587,  0.0250]],
       requires_grad=True)

encoder.encoders.0.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0418, -0.0624, -0.0029,  ...,  0.0055,  0.0540, -0.0277],
        [-0.0263,  0.0110,  0.0268,  ..., -0.0268, -0.0317,  0.0764],
        [-0.0188, -0.0611, -0.0215,  ...,  0.0278,  0.0140,  0.0428],
        ...,
        [-0.0257,  0.0352, -0.0304,  ...,  0.0049, -0.0224, -0.0653],
        [ 0.0147,  0.0226, -0.0060,  ..., -0.0377,  0.0169,  0.0144],
        [-0.0274, -0.0358, -0.0012,  ...,  0.0501,  0.0272, -0.0306]],
       requires_grad=True)

encoder.encoders.0.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([0.9499, 0.9007, 1.0512,  ..., 1.0377, 1.1112, 1.0602],
       requires_grad=True)

encoder.encoders.0.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0345,  0.1877,  0.0285,  ..., -0.0498,  0.0117,  0.0303],
       requires_grad=True)

encoder.encoders.0.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0406],
         [ 0.0078],
         [ 0.0714],
         ...,
         [-0.0577],
         [-0.0324],
         [-0.0084]],

        [[-0.0456],
         [ 0.0039],
         [ 0.0278],
         ...,
         [-0.0148],
         [-0.0492],
         [-0.0067]],

        [[ 0.0213],
         [-0.0279],
         [ 0.0474],
         ...,
         [-0.0621],
         [-0.0322],
         [-0.0383]],

        ...,

        [[-0.0056],
         [-0.0065],
         [-0.0106],
         ...,
         [ 0.0599],
         [ 0.0363],
         [-0.0506]],

        [[ 0.0317],
         [ 0.0303],
         [ 0.0003],
         ...,
         [-0.0377],
         [-0.0165],
         [-0.0135]],

        [[-0.0511],
         [ 0.0626],
         [-0.0009],
         ...,
         [ 0.0621],
         [ 0.1036],
         [-0.0262]]], requires_grad=True)

encoder.encoders.0.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 0.0031,  0.0024,  0.0030,  ...,  0.0010, -0.0011,  0.0037]],

        [[-0.0084, -0.0053,  0.0012,  ...,  0.0039, -0.0017,  0.0051]],

        [[ 0.0040,  0.0045,  0.0070,  ..., -0.0007, -0.0069,  0.0124]],

        ...,

        [[ 0.0088,  0.0072, -0.0033,  ...,  0.0067,  0.0002,  0.0090]],

        [[ 0.0038, -0.0031, -0.0037,  ..., -0.0031, -0.0084,  0.0093]],

        [[ 0.0222,  0.0067,  0.0020,  ..., -0.0028, -0.0133, -0.0183]]],
       requires_grad=True)

encoder.encoders.0.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0941, 1.0583, 1.0744,  ..., 1.0519, 1.0031, 1.0969],
       requires_grad=True)

encoder.encoders.0.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0473, -0.0629, -0.0790,  ..., -0.1410,  0.0371, -0.0915],
       requires_grad=True)

encoder.encoders.0.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0083],
         [-0.0874],
         [-0.1027],
         ...,
         [-0.0019],
         [-0.0264],
         [ 0.0708]],

        [[-0.0403],
         [ 0.0617],
         [-0.0899],
         ...,
         [ 0.0473],
         [ 0.0087],
         [-0.0256]],

        [[-0.0328],
         [ 0.0312],
         [ 0.0341],
         ...,
         [ 0.0105],
         [-0.0325],
         [-0.1468]],

        ...,

        [[-0.0372],
         [ 0.0447],
         [ 0.0012],
         ...,
         [-0.1252],
         [ 0.0658],
         [ 0.0269]],

        [[ 0.0115],
         [ 0.0472],
         [ 0.0302],
         ...,
         [-0.0023],
         [-0.0661],
         [ 0.0056]],

        [[-0.0674],
         [-0.2129],
         [-0.0196],
         ...,
         [ 0.0758],
         [ 0.0013],
         [ 0.1173]]], requires_grad=True)

encoder.encoders.0.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.9505, 0.8514, 1.0366,  ..., 1.0300, 1.1326, 1.0101],
       requires_grad=True)

encoder.encoders.0.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.0416,  0.1763,  0.1129,  ..., -0.1151,  0.1197,  0.0958],
       requires_grad=True)

encoder.encoders.0.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0818,  0.0180,  0.0029,  ...,  0.0238,  0.0583,  0.0382],
        [ 0.0386,  0.0175,  0.0723,  ..., -0.0715,  0.0169,  0.0815],
        [ 0.0198, -0.1005,  0.0753,  ..., -0.0101, -0.0741, -0.1054],
        ...,
        [ 0.0277,  0.0029,  0.0471,  ..., -0.0171,  0.0651, -0.0191],
        [ 0.0606, -0.0586, -0.0492,  ..., -0.0040,  0.0222, -0.0148],
        [ 0.0040,  0.0668,  0.0626,  ...,  0.0482, -0.0166, -0.0647]],
       requires_grad=True)

encoder.encoders.0.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0024, -0.0368, -0.0302,  ..., -0.0129, -0.0223, -0.0291],
       requires_grad=True)

encoder.encoders.0.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0061, -0.0746, -0.0449,  ..., -0.0065, -0.0634,  0.0055],
        [-0.0503,  0.0458,  0.0443,  ..., -0.0599,  0.0657,  0.0280],
        [ 0.0398, -0.0511, -0.1163,  ...,  0.0238,  0.1445, -0.1074],
        ...,
        [ 0.0190, -0.0353, -0.0192,  ..., -0.0236,  0.0110, -0.0741],
        [-0.0683, -0.0372,  0.0136,  ..., -0.0305, -0.0372,  0.1001],
        [ 0.0176, -0.0687,  0.1464,  ..., -0.0328,  0.0470,  0.0634]],
       requires_grad=True)

encoder.encoders.0.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0686, -0.0594, -0.0220,  ..., -0.0289,  0.0111, -0.0712],
       requires_grad=True)

encoder.encoders.0.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2683, 1.3269, 1.2448,  ..., 1.2045, 1.2751, 1.1687],
       requires_grad=True)

encoder.encoders.0.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.0395, -0.0304,  0.0731,  ..., -0.0541,  0.1104, -0.0582],
       requires_grad=True)

encoder.encoders.1.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.8795, 0.8159, 1.0190,  ..., 0.9768, 1.0666, 1.0227],
       requires_grad=True)

encoder.encoders.1.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.0291,  0.1003,  0.0687,  ..., -0.0379,  0.1167,  0.0205],
       requires_grad=True)

encoder.encoders.1.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0876, -0.0359, -0.0485,  ..., -0.0244, -0.0110, -0.0116],
        [ 0.0265,  0.0497,  0.0492,  ..., -0.0739,  0.0432, -0.0125],
        [-0.0403,  0.0774,  0.0034,  ..., -0.0512, -0.0470, -0.0076],
        ...,
        [-0.0497, -0.1132, -0.0722,  ...,  0.0593, -0.0245,  0.0929],
        [-0.0595, -0.0320, -0.0192,  ...,  0.0394, -0.0315, -0.0314],
        [-0.0251, -0.0085, -0.0234,  ..., -0.0649,  0.0126,  0.0033]],
       requires_grad=True)

encoder.encoders.1.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0454, -0.0481, -0.0210,  ..., -0.0486,  0.0021, -0.0548],
       requires_grad=True)

encoder.encoders.1.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0216, -0.0016, -0.0387,  ...,  0.0349,  0.0498,  0.0130],
        [-0.0047,  0.0259, -0.0088,  ..., -0.0069,  0.0225, -0.0579],
        [ 0.0033, -0.0197, -0.0218,  ..., -0.0072, -0.0131,  0.0917],
        ...,
        [-0.0329,  0.0430, -0.0047,  ...,  0.0209,  0.0152,  0.0331],
        [-0.0278,  0.0715, -0.0225,  ..., -0.0559, -0.0833,  0.0193],
        [-0.0933, -0.0416, -0.0009,  ...,  0.0614, -0.0378, -0.0147]],
       requires_grad=True)

encoder.encoders.1.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0132, -0.0561,  0.0638,  ..., -0.0197,  0.0215, -0.0030],
       requires_grad=True)

encoder.encoders.1.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.2233, -0.0425, -0.1206,  ..., -0.1057,  0.0754, -0.0481],
        [-0.0111,  0.0357, -0.1205,  ..., -0.0259,  0.0429, -0.1595],
        [ 0.0343, -0.1466, -0.1429,  ..., -0.0177,  0.1849, -0.1139],
        ...,
        [ 0.1939, -0.2174,  0.3079,  ..., -0.0972,  0.0815,  0.0184],
        [ 0.2392,  0.0505,  0.0283,  ..., -0.0699, -0.2192, -0.1892],
        [ 0.0984,  0.0739, -0.0010,  ...,  0.1913, -0.2002,  0.1455]],
       requires_grad=True)

encoder.encoders.1.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.1636, -0.0947, -0.3589,  ..., -0.0648,  0.2456,  0.2124],
        [ 0.1982,  0.0690, -0.0171,  ..., -0.0767,  0.2541, -0.0888],
        [-0.0143,  0.2593, -0.1014,  ..., -0.0290,  0.1454, -0.0874],
        ...,
        [ 0.0475, -0.2165, -0.3309,  ...,  0.1180,  0.2003,  0.0488],
        [ 0.0327, -0.1123, -0.1018,  ..., -0.2713,  0.1492,  0.1192],
        [ 0.0400,  0.2603,  0.1863,  ...,  0.0678, -0.0334,  0.1508]],
       requires_grad=True)

encoder.encoders.1.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0520, -0.0325,  0.0454,  ...,  0.0387, -0.0181, -0.0128],
        [-0.0263,  0.0594, -0.0514,  ...,  0.0007, -0.0168, -0.0036],
        [ 0.0099, -0.0267,  0.0404,  ..., -0.0130,  0.0807,  0.0064],
        ...,
        [ 0.0265,  0.0350,  0.0115,  ..., -0.0118,  0.0039,  0.0100],
        [-0.0102, -0.0009,  0.0162,  ..., -0.0468,  0.0725, -0.0276],
        [ 0.0193, -0.0469,  0.0387,  ..., -0.0151,  0.0152, -0.0011]],
       requires_grad=True)

encoder.encoders.1.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0118,  0.0045,  0.0231,  ...,  0.0665, -0.0386,  0.1032],
        [ 0.0282, -0.0111,  0.0592,  ...,  0.0264, -0.0149, -0.0179],
        [ 0.0589, -0.0091, -0.0262,  ...,  0.0737, -0.0529,  0.0245],
        ...,
        [ 0.0204,  0.1113, -0.0130,  ...,  0.0411,  0.0259, -0.1106],
        [ 0.0351, -0.0117,  0.0011,  ...,  0.0654,  0.0953, -0.0127],
        [-0.0190, -0.0309,  0.0371,  ...,  0.0248,  0.0681,  0.0449]],
       requires_grad=True)

encoder.encoders.1.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0351,  0.0163, -0.0718,  ..., -0.0205, -0.0382,  0.0335],
        [ 0.0175,  0.0166, -0.0691,  ..., -0.0334,  0.0050,  0.0041],
        [-0.0227,  0.0087, -0.0906,  ...,  0.0238, -0.0247,  0.0128],
        ...,
        [ 0.0166, -0.0541, -0.0356,  ..., -0.0381, -0.0411, -0.0153],
        [-0.0308, -0.0179, -0.0694,  ..., -0.0111,  0.0480,  0.0205],
        [ 0.0128, -0.0249, -0.0030,  ...,  0.0037, -0.0015, -0.0405]],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.4109, 0.3025, 0.3826,  ..., 0.4892, 0.4276, 0.5312],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([ 0.0655,  0.0334,  0.0298,  ...,  0.0363, -0.0302,  0.0555],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.7598, 0.6175, 0.7435,  ..., 0.8413, 0.7261, 0.8327],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0614,  0.0003, -0.0059,  ..., -0.0600, -0.0078, -0.0315],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6353, 0.5612, 0.7059,  ..., 0.6687, 0.6789, 0.6715],
       requires_grad=True)

encoder.encoders.1.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.1108,  0.0496, -0.0157,  ...,  0.0474, -0.0691,  0.0726],
       requires_grad=True)

encoder.encoders.1.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0481,  0.0224,  0.0270,  ..., -0.0430, -0.0249, -0.0627],
        [ 0.0078, -0.0418, -0.0059,  ...,  0.0207, -0.0097,  0.0023],
        [-0.0343,  0.0272,  0.0269,  ..., -0.0020,  0.0054,  0.0395],
        ...,
        [ 0.0470,  0.0038,  0.0120,  ...,  0.0304, -0.0064, -0.0880],
        [ 0.0102, -0.0904,  0.0534,  ..., -0.0286, -0.0240, -0.0646],
        [ 0.0163, -0.0143, -0.0468,  ...,  0.0063,  0.1104, -0.1074]],
       requires_grad=True)

encoder.encoders.1.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0853, -0.0614, -0.0593,  ..., -0.0322, -0.0026, -0.0424],
        [ 0.0947,  0.0488,  0.0674,  ..., -0.0035,  0.0203,  0.0196],
        [-0.0366,  0.0362, -0.0125,  ...,  0.0124,  0.0409,  0.0353],
        ...,
        [ 0.1120,  0.0688,  0.0126,  ...,  0.0053,  0.0236,  0.0424],
        [ 0.0359, -0.0706, -0.0114,  ...,  0.0214,  0.0443,  0.0618],
        [-0.0214, -0.0207, -0.0107,  ..., -0.0074, -0.0259,  0.0535]],
       requires_grad=True)

encoder.encoders.1.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.0227, 1.0142, 1.0491,  ..., 1.1001, 1.0781, 1.0531],
       requires_grad=True)

encoder.encoders.1.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0129,  0.0383,  0.0818,  ..., -0.0786, -0.0061, -0.0625],
       requires_grad=True)

encoder.encoders.1.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 6.6271e-02],
         [-8.1321e-02],
         [ 3.5724e-02],
         ...,
         [-6.6951e-02],
         [ 7.3143e-02],
         [-2.5076e-02]],

        [[-3.1505e-02],
         [-1.3858e-02],
         [ 2.6690e-02],
         ...,
         [ 1.6216e-02],
         [-2.9602e-02],
         [ 2.5855e-02]],

        [[-4.8504e-03],
         [-2.4903e-03],
         [-6.6688e-02],
         ...,
         [ 1.9260e-03],
         [ 1.3080e-02],
         [ 4.5899e-03]],

        ...,

        [[-2.7657e-02],
         [-5.0695e-03],
         [ 4.5058e-02],
         ...,
         [ 2.4498e-02],
         [ 2.1302e-03],
         [-3.5519e-03]],

        [[ 4.8205e-02],
         [-4.2128e-04],
         [-6.5873e-02],
         ...,
         [-2.9215e-02],
         [-2.9702e-02],
         [ 4.3726e-02]],

        [[-2.0917e-03],
         [ 3.6375e-02],
         [-7.7727e-03],
         ...,
         [ 7.0498e-02],
         [ 2.4353e-05],
         [ 6.7154e-02]]], requires_grad=True)

encoder.encoders.1.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0007,  0.0040,  0.0052,  ..., -0.0027,  0.0040,  0.0028]],

        [[-0.0260, -0.0101, -0.0071,  ..., -0.0098, -0.0079, -0.0198]],

        [[-0.0070, -0.0014,  0.0053,  ...,  0.0093,  0.0034, -0.0010]],

        ...,

        [[-0.0027, -0.0072,  0.0036,  ..., -0.0047,  0.0040, -0.0042]],

        [[ 0.0027,  0.0050, -0.0061,  ...,  0.0032,  0.0023, -0.0093]],

        [[ 0.0235,  0.0187,  0.0160,  ...,  0.0180,  0.0167, -0.0005]]],
       requires_grad=True)

encoder.encoders.1.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.1422, 1.1478, 1.0030,  ..., 1.0091, 1.0142, 1.0607],
       requires_grad=True)

encoder.encoders.1.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0987, -0.0774, -0.1061,  ..., -0.0767, -0.0955, -0.0657],
       requires_grad=True)

encoder.encoders.1.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.1018],
         [-0.0269],
         [-0.1128],
         ...,
         [-0.0244],
         [ 0.0102],
         [ 0.0127]],

        [[ 0.0298],
         [ 0.0086],
         [ 0.0044],
         ...,
         [ 0.0284],
         [-0.0403],
         [ 0.0917]],

        [[-0.0946],
         [-0.0272],
         [ 0.0508],
         ...,
         [ 0.0134],
         [ 0.0131],
         [ 0.0284]],

        ...,

        [[ 0.0463],
         [-0.0369],
         [-0.0419],
         ...,
         [ 0.0880],
         [-0.0073],
         [ 0.0393]],

        [[ 0.0321],
         [ 0.0588],
         [-0.0189],
         ...,
         [-0.0221],
         [-0.0363],
         [ 0.0459]],

        [[-0.0428],
         [-0.0110],
         [ 0.0010],
         ...,
         [ 0.0287],
         [-0.0267],
         [ 0.0176]]], requires_grad=True)

encoder.encoders.1.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.9755, 0.9004, 0.9273,  ..., 0.9687, 0.9967, 1.0307],
       requires_grad=True)

encoder.encoders.1.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.1743, -0.1871,  0.1853,  ...,  0.0125,  0.2426, -0.2346],
       requires_grad=True)

encoder.encoders.1.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0318, -0.0169,  0.0248,  ..., -0.0236, -0.0299, -0.0080],
        [ 0.0367,  0.0946, -0.0523,  ..., -0.0034,  0.0071, -0.0134],
        [ 0.1054,  0.0209, -0.0182,  ...,  0.0405, -0.0175, -0.0104],
        ...,
        [ 0.0087,  0.0565, -0.0211,  ..., -0.0077, -0.0140,  0.0702],
        [-0.0290,  0.1137, -0.0223,  ...,  0.0942, -0.0319, -0.0041],
        [ 0.0265,  0.0401, -0.0366,  ...,  0.0617, -0.0102,  0.0511]],
       requires_grad=True)

encoder.encoders.1.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0233,  0.0078, -0.0025,  ..., -0.0364, -0.0174, -0.0326],
       requires_grad=True)

encoder.encoders.1.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0878,  0.0409, -0.0919,  ...,  0.0742,  0.0704, -0.0044],
        [-0.0440, -0.0009,  0.0201,  ..., -0.0031,  0.0347, -0.0166],
        [-0.0038, -0.0018, -0.0246,  ...,  0.0194, -0.0509,  0.0070],
        ...,
        [-0.0171,  0.0532,  0.0058,  ..., -0.0102, -0.0312, -0.0667],
        [-0.0121,  0.0262,  0.0369,  ...,  0.0019,  0.0634, -0.0256],
        [-0.0436,  0.0242,  0.0646,  ...,  0.0410,  0.0164, -0.0457]],
       requires_grad=True)

encoder.encoders.1.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0340, -0.0759,  0.0197,  ..., -0.0239,  0.0389, -0.0649],
       requires_grad=True)

encoder.encoders.1.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2570, 1.2996, 1.2216,  ..., 1.2034, 1.2130, 1.1727],
       requires_grad=True)

encoder.encoders.1.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.0020, -0.1435,  0.0576,  ..., -0.0583,  0.0468, -0.1026],
       requires_grad=True)

encoder.encoders.2.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.0131, 0.9933, 1.0113,  ..., 1.0285, 1.0221, 1.0353],
       requires_grad=True)

encoder.encoders.2.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.1001, -0.2032,  0.0719,  ..., -0.0092,  0.1395, -0.0741],
       requires_grad=True)

encoder.encoders.2.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0480,  0.0211, -0.0263,  ...,  0.0313, -0.0650, -0.0175],
        [ 0.1057,  0.1297,  0.0502,  ...,  0.0406, -0.0475, -0.0507],
        [-0.0218,  0.0240, -0.0246,  ..., -0.0160,  0.0107,  0.0677],
        ...,
        [-0.0138,  0.0726, -0.0449,  ...,  0.0244, -0.0624,  0.0211],
        [ 0.0236,  0.0579, -0.0209,  ..., -0.0178,  0.0236,  0.0289],
        [ 0.0078,  0.0032,  0.0799,  ...,  0.0605,  0.0273, -0.0537]],
       requires_grad=True)

encoder.encoders.2.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0137, -0.0412, -0.0296,  ..., -0.0369, -0.0449, -0.0170],
       requires_grad=True)

encoder.encoders.2.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0257, -0.0208, -0.0044,  ..., -0.0141, -0.0138,  0.0545],
        [ 0.0213, -0.0289,  0.0248,  ..., -0.0224,  0.0816,  0.0333],
        [-0.0285, -0.0753,  0.0477,  ..., -0.0194, -0.0655, -0.0076],
        ...,
        [ 0.0262, -0.0076,  0.0220,  ...,  0.0349, -0.0061,  0.0896],
        [ 0.0224,  0.0144,  0.0450,  ...,  0.0124, -0.0307,  0.0860],
        [ 0.0088, -0.0676, -0.0333,  ..., -0.0027,  0.0398, -0.0243]],
       requires_grad=True)

encoder.encoders.2.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0577, -0.0288,  0.0430,  ..., -0.0606,  0.0196, -0.0491],
       requires_grad=True)

encoder.encoders.2.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.0632, -0.0261, -0.2142,  ...,  0.0033, -0.1584,  0.0187],
        [ 0.1407, -0.2260, -0.0621,  ..., -0.0663, -0.2071, -0.3868],
        [ 0.0417, -0.1475,  0.0931,  ..., -0.0602,  0.1570,  0.2920],
        ...,
        [-0.0252,  0.2368, -0.1390,  ...,  0.1155, -0.0512,  0.0183],
        [ 0.2199,  0.1756, -0.0789,  ...,  0.0313, -0.0605,  0.0137],
        [-0.1224, -0.1310, -0.1074,  ..., -0.0116,  0.2705, -0.0607]],
       requires_grad=True)

encoder.encoders.2.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.2889,  0.1180, -0.1702,  ...,  0.1844, -0.1908,  0.0231],
        [-0.3000, -0.0459,  0.0315,  ..., -0.1926,  0.0331,  0.0838],
        [-0.0014, -0.0527,  0.0684,  ..., -0.1346,  0.2246, -0.2980],
        ...,
        [ 0.2095,  0.0481, -0.1760,  ...,  0.0362, -0.0179, -0.0182],
        [-0.1456, -0.0340,  0.0835,  ...,  0.0681,  0.1112,  0.0178],
        [ 0.2157,  0.0198,  0.0213,  ..., -0.1014, -0.0185, -0.1182]],
       requires_grad=True)

encoder.encoders.2.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0135, -0.0321,  0.0533,  ..., -0.0125, -0.0383, -0.0236],
        [-0.0133, -0.0006, -0.0371,  ...,  0.0054,  0.0114,  0.0143],
        [ 0.0003, -0.0469, -0.0356,  ...,  0.0010,  0.0254, -0.0300],
        ...,
        [ 0.0284, -0.0632, -0.0634,  ...,  0.0655, -0.0718, -0.0489],
        [ 0.0597, -0.0534, -0.0465,  ...,  0.0364,  0.0322, -0.0193],
        [-0.0017, -0.0744,  0.0008,  ..., -0.0430,  0.0060, -0.0184]],
       requires_grad=True)

encoder.encoders.2.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0514,  0.0093,  0.0633,  ...,  0.0306,  0.0159,  0.0189],
        [-0.0291, -0.0745, -0.0808,  ...,  0.0771, -0.0066,  0.1029],
        [ 0.0435, -0.0802, -0.0414,  ..., -0.0039,  0.0355, -0.0151],
        ...,
        [ 0.0220,  0.0820,  0.0999,  ...,  0.0158, -0.0248, -0.0298],
        [ 0.0746,  0.0323,  0.0322,  ...,  0.0182,  0.0267,  0.0332],
        [-0.0510, -0.0669, -0.0375,  ..., -0.0157, -0.0112, -0.0430]],
       requires_grad=True)

encoder.encoders.2.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0011,  0.0127, -0.0304,  ...,  0.0006, -0.0480,  0.0569],
        [ 0.0082, -0.0419, -0.0486,  ..., -0.0423, -0.0154,  0.0309],
        [-0.0095,  0.0015, -0.0031,  ...,  0.0354,  0.1095, -0.0265],
        ...,
        [-0.0094, -0.0101, -0.0186,  ...,  0.0461,  0.0368,  0.0261],
        [ 0.0859,  0.0269, -0.0282,  ..., -0.0095,  0.0227,  0.0269],
        [-0.0502, -0.0140,  0.0127,  ...,  0.0229,  0.0460, -0.0268]],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.4190, 0.3878, 0.3918,  ..., 0.4635, 0.4025, 0.4600],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([ 0.0789,  0.0700, -0.0048,  ..., -0.0282,  0.0020,  0.0580],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.7654, 0.7537, 0.6976,  ..., 0.7812, 0.6843, 0.7987],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0066, -0.0392,  0.0078,  ...,  0.0168,  0.0379, -0.0300],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6112, 0.6310, 0.5866,  ..., 0.6277, 0.6741, 0.6482],
       requires_grad=True)

encoder.encoders.2.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0780,  0.1359, -0.0170,  ...,  0.0320, -0.0278,  0.1161],
       requires_grad=True)

encoder.encoders.2.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 7.3610e-02, -1.8906e-02,  8.9180e-02,  ..., -5.1647e-02,
         -1.1826e-02, -8.8065e-03],
        [ 9.5857e-05,  1.7025e-02, -6.2213e-02,  ...,  3.1020e-02,
         -4.0570e-03,  5.6013e-02],
        [-4.5452e-02, -2.3200e-02,  4.9800e-02,  ..., -5.5276e-02,
          5.7344e-02, -4.4274e-02],
        ...,
        [ 9.5890e-03,  3.6971e-02, -5.7168e-02,  ...,  2.1337e-02,
          1.5907e-02, -6.0010e-02],
        [-4.9115e-02, -7.7338e-02,  1.4668e-02,  ...,  8.1497e-03,
         -1.8906e-02, -1.7252e-02],
        [ 3.4370e-02,  1.6670e-02, -2.8260e-02,  ...,  9.3547e-03,
         -4.5759e-02,  1.6315e-02]], requires_grad=True)

encoder.encoders.2.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0592,  0.0200,  0.0376,  ..., -0.0078,  0.0521,  0.0033],
        [ 0.1260,  0.0057,  0.0368,  ..., -0.0017,  0.0318, -0.0250],
        [ 0.1259,  0.0923,  0.0569,  ...,  0.0145, -0.0156,  0.0441],
        ...,
        [ 0.0406,  0.1573,  0.0029,  ..., -0.0095,  0.0476,  0.0326],
        [ 0.0184,  0.0847,  0.0039,  ..., -0.0295, -0.0377,  0.0123],
        [ 0.0111, -0.0644,  0.0063,  ...,  0.0156, -0.0173,  0.0456]],
       requires_grad=True)

encoder.encoders.2.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.0179, 1.0602, 1.0600,  ..., 1.0556, 1.0837, 1.0340],
       requires_grad=True)

encoder.encoders.2.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0116, -0.0753,  0.0738,  ..., -0.0587,  0.0270, -0.1749],
       requires_grad=True)

encoder.encoders.2.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0629],
         [ 0.0156],
         [ 0.0344],
         ...,
         [ 0.1167],
         [-0.0652],
         [-0.0313]],

        [[-0.0639],
         [ 0.0003],
         [ 0.0684],
         ...,
         [-0.0083],
         [ 0.0565],
         [ 0.0164]],

        [[ 0.1028],
         [-0.0174],
         [-0.0149],
         ...,
         [-0.0977],
         [ 0.1012],
         [-0.0389]],

        ...,

        [[-0.0303],
         [-0.0291],
         [-0.0460],
         ...,
         [-0.0242],
         [ 0.0009],
         [-0.0565]],

        [[ 0.0392],
         [-0.0640],
         [ 0.0056],
         ...,
         [ 0.0021],
         [-0.0167],
         [-0.0907]],

        [[-0.0222],
         [-0.0632],
         [ 0.0379],
         ...,
         [-0.0518],
         [ 0.0213],
         [-0.0101]]], requires_grad=True)

encoder.encoders.2.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 0.0028,  0.0009, -0.0107,  ...,  0.0008, -0.0148, -0.0055]],

        [[-0.0088, -0.0119, -0.0068,  ...,  0.0005,  0.0005,  0.0042]],

        [[-0.0412, -0.0149, -0.0194,  ..., -0.0235, -0.0237, -0.0528]],

        ...,

        [[ 0.0072, -0.0056, -0.0048,  ...,  0.0056,  0.0051, -0.0038]],

        [[ 0.0013, -0.0049,  0.0050,  ...,  0.0055, -0.0021, -0.0048]],

        [[-0.0119, -0.0155, -0.0069,  ...,  0.0055, -0.0055,  0.0067]]],
       requires_grad=True)

encoder.encoders.2.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([0.9865, 0.9660, 1.0682,  ..., 0.9744, 1.0171, 0.9943],
       requires_grad=True)

encoder.encoders.2.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0890, -0.0888, -0.0521,  ..., -0.1108, -0.0735, -0.0883],
       requires_grad=True)

encoder.encoders.2.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0185],
         [-0.0762],
         [ 0.0925],
         ...,
         [ 0.1007],
         [-0.0132],
         [ 0.0889]],

        [[-0.0427],
         [-0.0710],
         [ 0.0105],
         ...,
         [-0.0513],
         [-0.0006],
         [-0.0306]],

        [[ 0.0626],
         [ 0.0935],
         [ 0.0916],
         ...,
         [-0.0106],
         [ 0.0743],
         [ 0.0339]],

        ...,

        [[ 0.0363],
         [-0.0262],
         [ 0.0316],
         ...,
         [-0.1003],
         [-0.0463],
         [-0.0903]],

        [[ 0.0125],
         [-0.0408],
         [-0.0327],
         ...,
         [ 0.0251],
         [-0.0525],
         [ 0.0439]],

        [[ 0.0367],
         [-0.0313],
         [ 0.0408],
         ...,
         [-0.0070],
         [ 0.0069],
         [-0.0685]]], requires_grad=True)

encoder.encoders.2.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.9699, 0.9220, 0.9997,  ..., 0.9671, 1.0037, 1.0212],
       requires_grad=True)

encoder.encoders.2.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.2027, -0.0505,  0.0685,  ..., -0.0407, -0.0390, -0.2155],
       requires_grad=True)

encoder.encoders.2.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0349,  0.0301, -0.0272,  ..., -0.0545,  0.0069,  0.0009],
        [-0.0204,  0.0274, -0.0616,  ...,  0.0543,  0.1284,  0.0131],
        [-0.0681,  0.0261, -0.0491,  ..., -0.0085,  0.0442, -0.0311],
        ...,
        [-0.0079,  0.0256, -0.0453,  ...,  0.0564,  0.0310,  0.0697],
        [ 0.0058, -0.0163,  0.1101,  ..., -0.0081,  0.0168,  0.0520],
        [ 0.0556,  0.0540,  0.0456,  ...,  0.0622,  0.0151,  0.0850]],
       requires_grad=True)

encoder.encoders.2.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0011, -0.0392, -0.0197,  ...,  0.0009,  0.0180, -0.0043],
       requires_grad=True)

encoder.encoders.2.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-1.3345e-03, -5.1226e-02,  8.2752e-02,  ..., -5.5625e-02,
         -8.6229e-03, -5.5645e-02],
        [ 6.6731e-03, -8.3395e-03, -5.9115e-03,  ..., -7.7307e-02,
          5.5390e-02, -1.0309e-01],
        [-2.6547e-02,  5.0127e-02,  1.9082e-02,  ...,  1.1515e-03,
          3.3767e-03, -5.9610e-02],
        ...,
        [-1.0783e-02, -4.8774e-02,  9.0031e-02,  ...,  7.4978e-05,
         -3.2420e-02, -3.6717e-02],
        [ 2.7085e-02,  1.5440e-02,  2.9958e-03,  ...,  2.7549e-02,
          1.8056e-02, -5.6238e-02],
        [ 4.1936e-03, -3.4451e-02,  5.6637e-02,  ..., -4.9646e-02,
         -1.7774e-02,  1.1088e-02]], requires_grad=True)

encoder.encoders.2.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0431, -0.0458,  0.0203,  ..., -0.0193, -0.0067, -0.0493],
       requires_grad=True)

encoder.encoders.2.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2831, 1.2299, 1.1950,  ..., 1.2381, 1.1881, 1.2530],
       requires_grad=True)

encoder.encoders.2.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.1131, -0.0449,  0.0266,  ..., -0.0920, -0.0476, -0.1248],
       requires_grad=True)

encoder.encoders.3.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.0175, 0.9146, 1.0195,  ..., 1.0002, 1.0310, 0.9864],
       requires_grad=True)

encoder.encoders.3.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.1556, -0.0614,  0.0728,  ..., -0.0401,  0.0235, -0.1075],
       requires_grad=True)

encoder.encoders.3.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0552,  0.0790, -0.0207,  ...,  0.0859, -0.0695,  0.0115],
        [-0.0330,  0.0600, -0.0173,  ..., -0.0185, -0.0184, -0.0282],
        [-0.0686,  0.0078,  0.0241,  ...,  0.0308, -0.0698, -0.0639],
        ...,
        [ 0.0549, -0.0614,  0.0553,  ..., -0.0625,  0.0244,  0.0015],
        [-0.1313, -0.1035, -0.0774,  ..., -0.0837,  0.0553,  0.0164],
        [ 0.0381, -0.0293, -0.0405,  ..., -0.0480,  0.0208,  0.0172]],
       requires_grad=True)

encoder.encoders.3.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0194, -0.0285, -0.0020,  ..., -0.0045,  0.0025, -0.0490],
       requires_grad=True)

encoder.encoders.3.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0513,  0.0057, -0.0441,  ..., -0.0438, -0.0377,  0.0443],
        [ 0.0013,  0.0049,  0.0501,  ..., -0.0411,  0.0237,  0.0577],
        [ 0.0426,  0.0116,  0.0189,  ..., -0.0460,  0.0044,  0.0008],
        ...,
        [-0.0584, -0.1276,  0.0250,  ..., -0.0059, -0.0494, -0.0341],
        [-0.0170,  0.0458,  0.0223,  ...,  0.0021, -0.0135,  0.0479],
        [ 0.0076,  0.0789, -0.0241,  ..., -0.0052, -0.0180,  0.0180]],
       requires_grad=True)

encoder.encoders.3.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0397, -0.0164,  0.0065,  ..., -0.0548, -0.0187, -0.0335],
       requires_grad=True)

encoder.encoders.3.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.1010, -0.1498, -0.1622,  ..., -0.0256,  0.1864,  0.1765],
        [ 0.1800, -0.0765, -0.0071,  ...,  0.3054, -0.1986,  0.2681],
        [-0.0977,  0.0209, -0.0667,  ..., -0.1627,  0.1002, -0.0373],
        ...,
        [-0.1810,  0.0728,  0.0526,  ..., -0.1359, -0.1867, -0.0913],
        [ 0.2668,  0.0227, -0.1639,  ...,  0.1358,  0.0010, -0.2593],
        [ 0.1218, -0.2796, -0.3011,  ...,  0.0556,  0.2139,  0.0286]],
       requires_grad=True)

encoder.encoders.3.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 0.1981, -0.0827,  0.0287,  ...,  0.1402, -0.0291, -0.1125],
        [ 0.0932,  0.0620,  0.2450,  ...,  0.0825,  0.0667, -0.3551],
        [-0.1211,  0.0101,  0.0744,  ..., -0.1136,  0.1250, -0.1366],
        ...,
        [ 0.1954,  0.0564, -0.0822,  ..., -0.4012,  0.0866, -0.1481],
        [-0.1863, -0.1325, -0.0845,  ..., -0.0372, -0.0313,  0.2201],
        [ 0.2215,  0.4111,  0.3674,  ...,  0.3668,  0.2390,  0.0387]],
       requires_grad=True)

encoder.encoders.3.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0061, -0.0223,  0.0073,  ..., -0.0653,  0.0194,  0.0172],
        [ 0.0069,  0.0106, -0.0313,  ...,  0.0398,  0.0043,  0.0678],
        [ 0.0466, -0.0063,  0.0424,  ..., -0.0532, -0.0188, -0.0142],
        ...,
        [-0.0472, -0.0151,  0.0283,  ..., -0.0102, -0.0773,  0.0732],
        [-0.0428,  0.0123, -0.0103,  ..., -0.0325, -0.0486,  0.0124],
        [-0.0181, -0.0051, -0.0755,  ...,  0.0062,  0.0037, -0.0139]],
       requires_grad=True)

encoder.encoders.3.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0333,  0.0031, -0.0067,  ...,  0.0199, -0.0322,  0.0214],
        [-0.0116,  0.0715, -0.0099,  ..., -0.0308, -0.0854, -0.0741],
        [ 0.0679, -0.0661, -0.0682,  ...,  0.0168,  0.0262, -0.0189],
        ...,
        [ 0.0077, -0.0625, -0.0533,  ...,  0.0101,  0.0142, -0.0859],
        [ 0.0086, -0.0309,  0.0780,  ...,  0.0289, -0.0550, -0.1019],
        [-0.0148, -0.0073,  0.0371,  ..., -0.0089, -0.0543, -0.0324]],
       requires_grad=True)

encoder.encoders.3.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0654,  0.0024, -0.0031,  ...,  0.0212,  0.1001,  0.0712],
        [ 0.0062, -0.0541,  0.0111,  ...,  0.0368,  0.0438,  0.0521],
        [-0.0493, -0.0022,  0.0419,  ..., -0.0009,  0.0095, -0.0393],
        ...,
        [-0.0058, -0.0127,  0.0531,  ..., -0.0459,  0.0413, -0.0273],
        [-0.0151, -0.0463, -0.0578,  ...,  0.0602, -0.0733, -0.0112],
        [ 0.0848, -0.0075,  0.0600,  ..., -0.0507, -0.0016,  0.0636]],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.4045, 0.4224, 0.4122,  ..., 0.3870, 0.4481, 0.4074],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([0.0258, 0.0727, 0.0004,  ..., 0.0303, 0.0395, 0.1106],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.6584, 0.7467, 0.7078,  ..., 0.7198, 0.6687, 0.7318],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0037,  0.0053, -0.0096,  ..., -0.0318,  0.0271,  0.0240],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5410, 0.6280, 0.6135,  ..., 0.5948, 0.5991, 0.5766],
       requires_grad=True)

encoder.encoders.3.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0220,  0.1142, -0.0370,  ...,  0.0908,  0.0551,  0.1806],
       requires_grad=True)

encoder.encoders.3.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0321, -0.0432,  0.0413,  ..., -0.0195,  0.0551,  0.0069],
        [-0.0098, -0.0353, -0.0227,  ...,  0.0241,  0.0206, -0.0618],
        [-0.0786,  0.0184,  0.0057,  ...,  0.0548,  0.0354, -0.0137],
        ...,
        [ 0.0126, -0.0275, -0.0140,  ...,  0.0251, -0.0276,  0.0432],
        [-0.0506, -0.0419, -0.0428,  ..., -0.0255, -0.0272,  0.0349],
        [-0.0326,  0.0302, -0.0359,  ..., -0.0227,  0.0272, -0.0219]],
       requires_grad=True)

encoder.encoders.3.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0279, -0.0697,  0.0186,  ..., -0.0316,  0.0327, -0.0470],
        [ 0.0280,  0.0347,  0.0421,  ...,  0.0286, -0.0389,  0.0317],
        [ 0.0067,  0.0022,  0.0258,  ...,  0.0113, -0.0439,  0.0099],
        ...,
        [-0.0030,  0.0589,  0.0686,  ...,  0.0129,  0.0311,  0.0062],
        [ 0.0461,  0.1009,  0.0642,  ..., -0.0365,  0.0078, -0.0214],
        [ 0.0208,  0.0570, -0.0056,  ...,  0.0371, -0.0218,  0.0637]],
       requires_grad=True)

encoder.encoders.3.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.0189, 1.0326, 1.0623,  ..., 1.0735, 1.1217, 1.0149],
       requires_grad=True)

encoder.encoders.3.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.1153, -0.1529,  0.0277,  ..., -0.0744, -0.1537, -0.1745],
       requires_grad=True)

encoder.encoders.3.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.0386],
         [-0.1047],
         [-0.0003],
         ...,
         [-0.0097],
         [-0.0579],
         [-0.0111]],

        [[ 0.0311],
         [-0.0651],
         [ 0.0033],
         ...,
         [ 0.0354],
         [-0.0512],
         [ 0.0236]],

        [[-0.1059],
         [-0.0486],
         [-0.0624],
         ...,
         [-0.0261],
         [-0.0157],
         [-0.0200]],

        ...,

        [[ 0.0153],
         [ 0.0455],
         [-0.0396],
         ...,
         [ 0.1140],
         [-0.0332],
         [-0.0207]],

        [[-0.0253],
         [ 0.0385],
         [ 0.0079],
         ...,
         [ 0.0266],
         [-0.0118],
         [ 0.0360]],

        [[ 0.0292],
         [ 0.0798],
         [ 0.0055],
         ...,
         [ 0.1437],
         [ 0.0370],
         [ 0.0373]]], requires_grad=True)

encoder.encoders.3.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-4.2038e-02, -1.5815e-02, -3.6948e-02,  ...,  3.2023e-03,
           1.0967e-02, -2.9246e-03]],

        [[ 8.1775e-02,  3.5579e-02,  6.0533e-02,  ...,  4.0014e-02,
           5.0869e-02,  4.8693e-02]],

        [[-7.4076e-03, -3.2345e-02, -1.1618e-02,  ..., -2.4148e-04,
          -1.6054e-03, -9.5252e-03]],

        ...,

        [[-2.8248e-05, -1.0297e-02, -1.5272e-03,  ...,  4.9337e-03,
          -1.8899e-03,  1.4705e-03]],

        [[ 3.8124e-02, -3.4600e-03,  2.2240e-02,  ...,  3.1774e-02,
           2.5257e-02,  3.5376e-02]],

        [[-3.0502e-03, -1.5521e-03, -7.3439e-03,  ...,  1.0609e-03,
           9.8815e-04, -5.1526e-03]]], requires_grad=True)

encoder.encoders.3.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0540, 1.0657, 0.9569,  ..., 0.9935, 0.9879, 1.0167],
       requires_grad=True)

encoder.encoders.3.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.1336, -0.0381, -0.0857,  ..., -0.0714, -0.0320, -0.0644],
       requires_grad=True)

encoder.encoders.3.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0285],
         [ 0.0362],
         [ 0.0284],
         ...,
         [-0.0334],
         [ 0.0024],
         [ 0.0034]],

        [[ 0.0024],
         [ 0.0229],
         [-0.0252],
         ...,
         [-0.0685],
         [-0.0735],
         [-0.0231]],

        [[ 0.0427],
         [ 0.0303],
         [-0.0186],
         ...,
         [ 0.0399],
         [ 0.0451],
         [-0.0532]],

        ...,

        [[ 0.0581],
         [ 0.0377],
         [ 0.0440],
         ...,
         [-0.0345],
         [-0.0067],
         [ 0.0542]],

        [[ 0.0530],
         [ 0.0489],
         [ 0.0103],
         ...,
         [-0.0893],
         [-0.0341],
         [-0.0789]],

        [[-0.0437],
         [-0.0710],
         [ 0.0382],
         ...,
         [-0.0258],
         [ 0.0182],
         [-0.0485]]], requires_grad=True)

encoder.encoders.3.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.9173, 0.9687, 0.9269,  ..., 1.0471, 1.1044, 0.9652],
       requires_grad=True)

encoder.encoders.3.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.0695, -0.0284,  0.0393,  ..., -0.2637, -0.2849, -0.1814],
       requires_grad=True)

encoder.encoders.3.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0051, -0.0213, -0.0265,  ..., -0.0536, -0.0243,  0.0058],
        [-0.0541,  0.0649,  0.0094,  ...,  0.0640, -0.0258,  0.0984],
        [ 0.0671, -0.0300, -0.0377,  ..., -0.0401, -0.0099, -0.0383],
        ...,
        [-0.0060,  0.0044, -0.0356,  ...,  0.0801, -0.0148,  0.0704],
        [-0.0682, -0.0462, -0.0367,  ..., -0.0246,  0.0502, -0.0556],
        [ 0.1009, -0.0182, -0.1040,  ...,  0.0336, -0.0460, -0.0242]],
       requires_grad=True)

encoder.encoders.3.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0143, -0.0094,  0.0044,  ..., -0.0319, -0.0299,  0.0178],
       requires_grad=True)

encoder.encoders.3.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-3.3612e-02,  2.1440e-02,  2.3706e-02,  ..., -3.6867e-02,
         -4.6127e-03, -6.6302e-02],
        [ 1.7449e-02, -6.6478e-02,  6.0681e-03,  ..., -1.0064e-03,
          2.9532e-02,  2.0655e-02],
        [-2.0994e-02,  1.2230e-02, -3.1016e-02,  ...,  6.9320e-02,
         -9.0820e-02, -2.3535e-02],
        ...,
        [ 9.1786e-06,  1.5390e-03,  5.7624e-02,  ...,  5.5655e-02,
         -3.6314e-02, -3.0708e-02],
        [-2.2336e-03,  4.1572e-03,  5.5476e-02,  ...,  2.7787e-02,
          2.4348e-02,  4.5742e-02],
        [ 7.0037e-02, -5.8279e-02,  7.0575e-03,  ..., -6.6567e-02,
         -5.3157e-02,  8.7667e-02]], requires_grad=True)

encoder.encoders.3.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0157,  0.0009,  0.0035,  ..., -0.0367, -0.0486, -0.0147],
       requires_grad=True)

encoder.encoders.3.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3967, 1.2477, 1.2342,  ..., 1.3011, 1.2307, 1.3351],
       requires_grad=True)

encoder.encoders.3.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0521, -0.0196,  0.0422,  ..., -0.1820, -0.0795, -0.1355],
       requires_grad=True)

encoder.encoders.4.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.8447, 0.9564, 0.9513,  ..., 1.1055, 1.0195, 0.9153],
       requires_grad=True)

encoder.encoders.4.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.0636, -0.0480,  0.1009,  ..., -0.2449, -0.1429, -0.0904],
       requires_grad=True)

encoder.encoders.4.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0234, -0.1032,  0.0204,  ...,  0.0424,  0.0307,  0.0354],
        [-0.0557, -0.0394, -0.0675,  ...,  0.0436, -0.0121, -0.0543],
        [-0.0924, -0.0517,  0.0079,  ...,  0.0517, -0.0198,  0.0758],
        ...,
        [ 0.0158, -0.0289,  0.0332,  ...,  0.0207, -0.0108, -0.0344],
        [ 0.0119,  0.0676, -0.0091,  ..., -0.0186,  0.0415,  0.0133],
        [ 0.0143,  0.0091,  0.0186,  ...,  0.0145, -0.0281,  0.0434]],
       requires_grad=True)

encoder.encoders.4.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0111, -0.0022, -0.0058,  ..., -0.0378, -0.0204, -0.0149],
       requires_grad=True)

encoder.encoders.4.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0175,  0.0150, -0.0334,  ...,  0.0195, -0.0226,  0.0743],
        [-0.0399, -0.0708,  0.0769,  ...,  0.0304,  0.0207,  0.0046],
        [-0.0313,  0.0583,  0.0054,  ..., -0.0032, -0.0017, -0.0147],
        ...,
        [-0.0040,  0.0023,  0.0287,  ...,  0.0236, -0.0780, -0.0115],
        [ 0.0642,  0.0061,  0.0536,  ..., -0.0604,  0.0017, -0.0035],
        [ 0.0310, -0.0174,  0.0121,  ..., -0.0066, -0.0152,  0.0338]],
       requires_grad=True)

encoder.encoders.4.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0287, -0.0144, -0.0024,  ..., -0.0643, -0.0265, -0.0341],
       requires_grad=True)

encoder.encoders.4.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.1246,  0.1110, -0.0251,  ..., -0.2574,  0.2213, -0.1251],
        [-0.0594, -0.0235,  0.0192,  ...,  0.1818,  0.2199, -0.0487],
        [-0.1530,  0.1871,  0.2539,  ...,  0.1766, -0.1106,  0.0557],
        ...,
        [ 0.0597,  0.1722, -0.1239,  ...,  0.2450, -0.0565, -0.0402],
        [ 0.0942,  0.0419,  0.0790,  ..., -0.1949,  0.0993,  0.0066],
        [-0.2370,  0.0235,  0.0410,  ...,  0.2872, -0.1436, -0.2455]],
       requires_grad=True)

encoder.encoders.4.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.0942, -0.2785,  0.1971,  ..., -0.0317,  0.0932, -0.2032],
        [-0.0621,  0.0154,  0.0085,  ...,  0.0995,  0.1714, -0.0792],
        [ 0.2443, -0.2369,  0.2462,  ...,  0.2548,  0.1130,  0.2206],
        ...,
        [ 0.0356,  0.1395,  0.1207,  ..., -0.2266, -0.0674,  0.0603],
        [-0.2110, -0.0749,  0.1516,  ...,  0.2192,  0.2750,  0.1941],
        [ 0.0969, -0.3149, -0.2249,  ...,  0.0159,  0.0391, -0.0731]],
       requires_grad=True)

encoder.encoders.4.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-4.8144e-02,  7.1130e-02,  1.1305e-02,  ...,  6.9272e-05,
         -2.7959e-02,  3.9879e-02],
        [ 2.4948e-03,  2.0409e-02, -2.7741e-02,  ...,  1.1439e-02,
         -2.3331e-02, -5.9986e-03],
        [-6.6972e-04, -6.8414e-02,  1.4489e-02,  ...,  1.1544e-02,
         -2.9906e-03,  1.2450e-03],
        ...,
        [ 4.9123e-02,  4.4579e-02,  4.1092e-02,  ...,  4.1027e-02,
         -1.7969e-02,  1.0715e-02],
        [ 2.7682e-02, -1.1098e-01,  7.1311e-03,  ..., -9.3237e-04,
         -1.0077e-01,  4.1289e-03],
        [-3.6523e-02, -2.1837e-02,  3.3072e-02,  ...,  1.4093e-02,
          4.4023e-02, -6.2216e-02]], requires_grad=True)

encoder.encoders.4.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0135,  0.0253,  0.0983,  ...,  0.0495,  0.0075,  0.0337],
        [-0.0089,  0.0255,  0.0077,  ..., -0.0461,  0.0036, -0.0524],
        [-0.1020, -0.0241,  0.0012,  ...,  0.0735, -0.0076, -0.0106],
        ...,
        [-0.0010, -0.0357, -0.0389,  ..., -0.0156,  0.0937, -0.0378],
        [-0.0211,  0.0355, -0.0199,  ..., -0.0997,  0.0333,  0.0105],
        [ 0.0539, -0.0070, -0.0241,  ..., -0.1030, -0.0942, -0.0818]],
       requires_grad=True)

encoder.encoders.4.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0221, -0.0121,  0.0427,  ..., -0.0033,  0.0987,  0.0244],
        [-0.0012,  0.0344,  0.0288,  ...,  0.0332,  0.0095, -0.0248],
        [-0.0374,  0.0854,  0.0014,  ..., -0.0732,  0.0136,  0.0216],
        ...,
        [ 0.0049,  0.0332, -0.0514,  ...,  0.0142,  0.0192, -0.0207],
        [ 0.0004, -0.0154, -0.0085,  ...,  0.0068,  0.0483,  0.0374],
        [-0.0528, -0.0458, -0.0181,  ...,  0.0294, -0.0299, -0.0015]],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.3526, 0.3561, 0.3949,  ..., 0.4588, 0.3917, 0.3815],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0118,  0.0293, -0.0249,  ...,  0.0720, -0.0088,  0.1689],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.5475, 0.6338, 0.5610,  ..., 0.6258, 0.6340, 0.6224],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0219, -0.0429, -0.0092,  ..., -0.0067,  0.0169, -0.0148],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.4991, 0.6241, 0.5790,  ..., 0.5945, 0.5694, 0.5390],
       requires_grad=True)

encoder.encoders.4.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0516,  0.0296, -0.0681,  ...,  0.1565,  0.0585,  0.2286],
       requires_grad=True)

encoder.encoders.4.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0513,  0.0446, -0.0151,  ..., -0.0063, -0.0281,  0.0124],
        [-0.0528,  0.0051,  0.0057,  ...,  0.0164,  0.0449, -0.0077],
        [-0.0170, -0.0026, -0.0068,  ...,  0.0117,  0.0400, -0.0166],
        ...,
        [ 0.0271,  0.0239, -0.0074,  ...,  0.0383,  0.0195,  0.0142],
        [-0.0440, -0.0309, -0.0354,  ...,  0.0130, -0.0015,  0.0415],
        [-0.0463, -0.0111,  0.0453,  ...,  0.0155, -0.0939, -0.0378]],
       requires_grad=True)

encoder.encoders.4.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0462, -0.0038,  0.0240,  ...,  0.0104, -0.0359, -0.0049],
        [ 0.0610,  0.0755,  0.0817,  ...,  0.0103, -0.0215, -0.0297],
        [ 0.0536,  0.0740,  0.0050,  ..., -0.0404,  0.0248, -0.0052],
        ...,
        [-0.0655, -0.0359, -0.0485,  ..., -0.0317,  0.0447, -0.0075],
        [ 0.0915,  0.0326,  0.0690,  ..., -0.0187, -0.0342,  0.0289],
        [ 0.0142,  0.0208,  0.0096,  ..., -0.0046, -0.0300, -0.0214]],
       requires_grad=True)

encoder.encoders.4.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([0.8659, 1.0695, 1.0186,  ..., 1.0806, 1.0655, 0.9950],
       requires_grad=True)

encoder.encoders.4.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0990, -0.0753,  0.0211,  ..., -0.0834, -0.1545, -0.1118],
       requires_grad=True)

encoder.encoders.4.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0597],
         [ 0.0137],
         [-0.0688],
         ...,
         [-0.0339],
         [-0.0443],
         [-0.0032]],

        [[-0.0988],
         [-0.0233],
         [ 0.0139],
         ...,
         [ 0.0595],
         [-0.0408],
         [ 0.0349]],

        [[-0.0745],
         [-0.0078],
         [-0.0514],
         ...,
         [-0.0471],
         [ 0.0802],
         [ 0.0834]],

        ...,

        [[ 0.1359],
         [ 0.0338],
         [-0.0285],
         ...,
         [ 0.0028],
         [ 0.0329],
         [ 0.0450]],

        [[ 0.0374],
         [ 0.0253],
         [ 0.0239],
         ...,
         [-0.0226],
         [-0.0546],
         [-0.0010]],

        [[-0.0236],
         [ 0.0693],
         [ 0.0509],
         ...,
         [-0.0016],
         [ 0.0362],
         [ 0.0250]]], requires_grad=True)

encoder.encoders.4.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 0.0395,  0.0260,  0.0223,  ..., -0.0025, -0.0068, -0.0196]],

        [[ 0.1274,  0.0969,  0.0852,  ...,  0.0611,  0.0700,  0.1095]],

        [[ 0.0829,  0.0346,  0.0545,  ...,  0.0549,  0.0486,  0.0847]],

        ...,

        [[ 0.0052, -0.0121, -0.0015,  ..., -0.0034, -0.0049, -0.0073]],

        [[-0.0059,  0.0062, -0.0087,  ...,  0.0101, -0.0035,  0.0067]],

        [[-0.0231, -0.0384, -0.0010,  ...,  0.0255,  0.0216,  0.0577]]],
       requires_grad=True)

encoder.encoders.4.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0198, 1.0882, 1.0286,  ..., 1.0525, 1.0188, 0.9578],
       requires_grad=True)

encoder.encoders.4.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0576, -0.0324, -0.0346,  ..., -0.0630, -0.0869, -0.0531],
       requires_grad=True)

encoder.encoders.4.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0107],
         [-0.1046],
         [ 0.0024],
         ...,
         [-0.0457],
         [-0.0096],
         [-0.0667]],

        [[ 0.0590],
         [-0.0107],
         [ 0.0456],
         ...,
         [ 0.0366],
         [-0.0007],
         [-0.0286]],

        [[-0.0002],
         [-0.0485],
         [-0.0289],
         ...,
         [-0.0195],
         [ 0.0451],
         [ 0.1047]],

        ...,

        [[-0.0203],
         [ 0.0130],
         [-0.0192],
         ...,
         [-0.0286],
         [ 0.0979],
         [ 0.0247]],

        [[ 0.0610],
         [ 0.0689],
         [-0.0924],
         ...,
         [-0.0529],
         [-0.0466],
         [ 0.0024]],

        [[ 0.0212],
         [ 0.0413],
         [ 0.1119],
         ...,
         [-0.0166],
         [-0.0456],
         [ 0.0164]]], requires_grad=True)

encoder.encoders.4.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.8105, 0.9432, 0.9347,  ..., 1.1014, 0.9712, 1.0245],
       requires_grad=True)

encoder.encoders.4.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.1682,  0.0188,  0.1335,  ..., -0.2498, -0.0964, -0.2129],
       requires_grad=True)

encoder.encoders.4.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0635,  0.0128,  0.0158,  ..., -0.0361, -0.0946,  0.0415],
        [-0.0545,  0.0875,  0.0378,  ..., -0.0608,  0.0103,  0.0216],
        [ 0.0250, -0.0611, -0.0281,  ..., -0.0064,  0.0494, -0.0003],
        ...,
        [-0.0513, -0.0707,  0.0108,  ..., -0.0188, -0.0742,  0.0676],
        [ 0.0143, -0.0127, -0.0111,  ...,  0.0403, -0.0125,  0.0358],
        [ 0.0231, -0.0126, -0.0520,  ..., -0.0312,  0.1022,  0.0218]],
       requires_grad=True)

encoder.encoders.4.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0050, -0.0097, -0.0222,  ...,  0.0137, -0.0113, -0.0406],
       requires_grad=True)

encoder.encoders.4.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0438, -0.0113,  0.0839,  ...,  0.1086, -0.0124,  0.0211],
        [ 0.0050,  0.0269, -0.0158,  ...,  0.0110, -0.0122,  0.0553],
        [ 0.0398, -0.0342, -0.0208,  ...,  0.0334, -0.0180, -0.0081],
        ...,
        [-0.0476,  0.0701,  0.0304,  ..., -0.0187,  0.0016,  0.0099],
        [ 0.0547,  0.0215, -0.0045,  ...,  0.0499,  0.0340, -0.0189],
        [ 0.1181, -0.0544, -0.0945,  ..., -0.0594, -0.0239,  0.0073]],
       requires_grad=True)

encoder.encoders.4.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0081, -0.0050,  0.0134,  ..., -0.0702, -0.0131, -0.0164],
       requires_grad=True)

encoder.encoders.4.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3805, 1.2672, 1.2233,  ..., 1.3044, 1.2448, 1.2455],
       requires_grad=True)

encoder.encoders.4.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0560, -0.0141,  0.0564,  ..., -0.2319, -0.0607, -0.0542],
       requires_grad=True)

encoder.encoders.5.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.7034, 0.8899, 0.8951,  ..., 1.0659, 0.9349, 0.9433],
       requires_grad=True)

encoder.encoders.5.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.1092,  0.0020,  0.0804,  ..., -0.2465, -0.1083, -0.1654],
       requires_grad=True)

encoder.encoders.5.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-1.2205e-02, -7.0109e-02,  3.4512e-02,  ...,  1.2375e-03,
         -3.4559e-02,  2.6807e-02],
        [ 2.6943e-02,  1.3581e-02,  2.4263e-03,  ...,  3.4035e-02,
          6.4367e-02,  6.4497e-02],
        [-1.1088e-02, -8.2016e-02,  6.7622e-02,  ..., -2.7228e-02,
          2.0171e-02,  1.2771e-02],
        ...,
        [-2.2296e-03,  7.8287e-02, -6.6517e-02,  ...,  9.2770e-02,
         -2.6002e-02,  8.6361e-02],
        [ 5.0213e-02,  1.2361e-02, -2.3314e-02,  ..., -8.5673e-04,
         -3.6500e-02, -5.1121e-03],
        [ 3.2760e-03,  7.8602e-02, -1.6397e-01,  ..., -7.0500e-02,
          1.1878e-02, -6.3480e-05]], requires_grad=True)

encoder.encoders.5.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0587, -0.0280, -0.0022,  ..., -0.0181, -0.0511,  0.0015],
       requires_grad=True)

encoder.encoders.5.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0590,  0.0118,  0.0131,  ..., -0.0182, -0.0096, -0.0256],
        [ 0.0550, -0.0459, -0.0190,  ...,  0.0005, -0.0148,  0.0682],
        [-0.0234, -0.0389,  0.0115,  ..., -0.0401,  0.0104, -0.0143],
        ...,
        [ 0.0311,  0.0574, -0.0221,  ...,  0.0044, -0.0011, -0.0331],
        [-0.0184,  0.0712,  0.0676,  ...,  0.0643, -0.0196,  0.0139],
        [-0.0614,  0.0139, -0.0130,  ..., -0.0754,  0.0491,  0.0218]],
       requires_grad=True)

encoder.encoders.5.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0013, -0.0151,  0.0280,  ..., -0.0801, -0.0319, -0.0139],
       requires_grad=True)

encoder.encoders.5.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 1.4916e-01,  7.9902e-02,  5.4409e-05,  ..., -2.4824e-01,
          2.0559e-01,  1.0363e-01],
        [-3.3817e-01, -1.7686e-01,  2.0932e-02,  ..., -6.2848e-03,
         -1.4766e-01, -8.3028e-02],
        [ 1.7736e-01, -2.1702e-01, -1.7083e-01,  ...,  1.4651e-01,
          5.9234e-03,  4.4594e-02],
        ...,
        [ 1.5784e-01,  9.4733e-02, -2.7006e-01,  ...,  1.2773e-01,
         -5.3201e-02,  1.1929e-01],
        [ 2.2981e-01, -1.0486e-01, -1.6498e-01,  ...,  1.3418e-01,
         -1.6286e-01, -2.0702e-01],
        [ 2.6109e-01, -9.7622e-02, -5.9776e-04,  ..., -2.5111e-01,
         -3.8664e-02, -2.1269e-01]], requires_grad=True)

encoder.encoders.5.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 0.0943, -0.4294,  0.2911,  ...,  0.1117, -0.3233, -0.5141],
        [ 0.0488,  0.1591, -0.0930,  ...,  0.1234,  0.0526,  0.2369],
        [ 0.0531,  0.0470, -0.2825,  ..., -0.0060, -0.0216, -0.3752],
        ...,
        [-0.4397, -0.2175, -0.0245,  ...,  0.2723, -0.1483, -0.0089],
        [-0.2810,  0.2240,  0.2306,  ...,  0.1352,  0.2343, -0.3003],
        [ 0.0978,  0.2696, -0.2259,  ...,  0.3104, -0.1461,  0.2452]],
       requires_grad=True)

encoder.encoders.5.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0685, -0.0405,  0.0428,  ...,  0.0221,  0.0256,  0.0972],
        [ 0.0011, -0.0373, -0.0610,  ...,  0.0400, -0.0710,  0.0157],
        [-0.0556, -0.0083, -0.0582,  ...,  0.0005, -0.0423,  0.0529],
        ...,
        [-0.0763,  0.0101, -0.0427,  ...,  0.0427, -0.0847,  0.0211],
        [-0.0044, -0.0821, -0.0083,  ...,  0.0351, -0.0258,  0.0422],
        [-0.0095,  0.0281, -0.1075,  ..., -0.0262, -0.0666, -0.0531]],
       requires_grad=True)

encoder.encoders.5.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0191, -0.0295,  0.0627,  ..., -0.0139, -0.0187,  0.0184],
        [-0.1071,  0.0700,  0.0692,  ..., -0.0312,  0.0409,  0.0017],
        [ 0.0053, -0.0028,  0.0510,  ..., -0.0429, -0.0056,  0.0160],
        ...,
        [-0.0216, -0.0185,  0.0035,  ...,  0.0535,  0.0256,  0.0323],
        [ 0.0006, -0.0458, -0.0212,  ...,  0.0281, -0.0192,  0.0004],
        [ 0.0134,  0.0516,  0.0782,  ..., -0.0475, -0.0478,  0.0274]],
       requires_grad=True)

encoder.encoders.5.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0663, -0.0625,  0.0211,  ..., -0.0235,  0.0505, -0.0443],
        [ 0.0088,  0.0324,  0.0036,  ..., -0.0246, -0.0285, -0.0069],
        [ 0.0334,  0.0476, -0.0482,  ..., -0.0230,  0.0279, -0.0630],
        ...,
        [ 0.0140,  0.0896, -0.0093,  ...,  0.0187,  0.0236, -0.0045],
        [ 0.0162,  0.0628, -0.0375,  ..., -0.0120, -0.0327,  0.0541],
        [-0.0110, -0.0244,  0.0098,  ...,  0.0087,  0.0467, -0.0159]],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.6378, 0.7791, 0.6775,  ..., 0.6529, 0.6745, 0.7084],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0665,  0.0077, -0.0573,  ...,  0.0754,  0.0250,  0.0339],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.6789, 0.7560, 0.7479,  ..., 0.7662, 0.6869, 0.8319],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0150,  0.0542,  0.0014,  ...,  0.0531, -0.0139,  0.0580],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6034, 0.6163, 0.6125,  ..., 0.5819, 0.5932, 0.6461],
       requires_grad=True)

encoder.encoders.5.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0747,  0.0145, -0.0611,  ...,  0.1415,  0.0313,  0.0478],
       requires_grad=True)

encoder.encoders.5.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0223, -0.0138, -0.0159,  ..., -0.0005,  0.0130, -0.0238],
        [-0.0050,  0.0272, -0.0007,  ...,  0.0385,  0.0195,  0.0173],
        [ 0.0043, -0.0055, -0.0138,  ...,  0.0174, -0.0093, -0.0421],
        ...,
        [ 0.0517, -0.0275, -0.0389,  ..., -0.0196, -0.0453, -0.0102],
        [ 0.0146, -0.0490,  0.0410,  ...,  0.0745,  0.0464,  0.0301],
        [ 0.0404, -0.0468,  0.0342,  ..., -0.0132, -0.0150,  0.0284]],
       requires_grad=True)

encoder.encoders.5.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0167,  0.0041,  0.0314,  ...,  0.0079,  0.0131,  0.0537],
        [ 0.0894, -0.0340,  0.1202,  ..., -0.0026, -0.0144, -0.0137],
        [ 0.0262,  0.1350, -0.0691,  ...,  0.0452, -0.0219,  0.0161],
        ...,
        [-0.0444,  0.0239, -0.0944,  ..., -0.0105,  0.0371, -0.0185],
        [-0.0595,  0.0178, -0.0070,  ...,  0.0164, -0.0100,  0.0397],
        [ 0.0052,  0.0347, -0.0123,  ...,  0.0089, -0.0179, -0.0007]],
       requires_grad=True)

encoder.encoders.5.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([0.8015, 1.1225, 1.1691,  ..., 1.1727, 1.0473, 1.1460],
       requires_grad=True)

encoder.encoders.5.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0029, -0.0653,  0.0965,  ..., -0.1377, -0.1050,  0.0236],
       requires_grad=True)

encoder.encoders.5.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.1418],
         [ 0.0739],
         [-0.0012],
         ...,
         [-0.0021],
         [-0.0901],
         [ 0.0566]],

        [[ 0.0475],
         [ 0.0366],
         [-0.0257],
         ...,
         [ 0.0237],
         [ 0.0630],
         [ 0.0181]],

        [[-0.0180],
         [-0.0568],
         [-0.0363],
         ...,
         [-0.0665],
         [-0.0038],
         [ 0.0595]],

        ...,

        [[ 0.0100],
         [ 0.0236],
         [ 0.0566],
         ...,
         [ 0.1158],
         [-0.0353],
         [ 0.0015]],

        [[-0.0363],
         [-0.0765],
         [-0.0352],
         ...,
         [-0.0006],
         [ 0.0404],
         [ 0.0802]],

        [[-0.0040],
         [ 0.0008],
         [-0.0545],
         ...,
         [ 0.0584],
         [-0.0255],
         [ 0.0463]]], requires_grad=True)

encoder.encoders.5.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0361,  0.0036, -0.0121,  ..., -0.0123, -0.0098, -0.0029]],

        [[-0.0289, -0.0011,  0.0130,  ...,  0.0177,  0.0085,  0.0172]],

        [[-0.0015,  0.0083, -0.0065,  ..., -0.0094,  0.0153, -0.0007]],

        ...,

        [[-0.0028, -0.0032,  0.0021,  ...,  0.0012, -0.0174,  0.0151]],

        [[-0.0105, -0.0018,  0.0178,  ..., -0.0166, -0.0122, -0.0050]],

        [[-0.0086,  0.0018,  0.0024,  ...,  0.0044, -0.0008,  0.0107]]],
       requires_grad=True)

encoder.encoders.5.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.1776, 1.0164, 1.0939,  ..., 1.0462, 1.0063, 1.0055],
       requires_grad=True)

encoder.encoders.5.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0607, -0.0762, -0.0621,  ..., -0.0619, -0.0756, -0.0893],
       requires_grad=True)

encoder.encoders.5.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[ 0.0184],
         [ 0.0070],
         [ 0.0372],
         ...,
         [ 0.0189],
         [ 0.0841],
         [ 0.0067]],

        [[-0.1435],
         [-0.0225],
         [-0.0406],
         ...,
         [ 0.0708],
         [ 0.0056],
         [-0.0217]],

        [[-0.0319],
         [ 0.0004],
         [ 0.0286],
         ...,
         [ 0.0462],
         [ 0.0315],
         [ 0.0467]],

        ...,

        [[ 0.0996],
         [ 0.0387],
         [ 0.0129],
         ...,
         [-0.0249],
         [-0.0395],
         [-0.0134]],

        [[ 0.0191],
         [-0.1037],
         [-0.0809],
         ...,
         [ 0.0015],
         [-0.0269],
         [ 0.0141]],

        [[ 0.0971],
         [-0.0106],
         [ 0.0217],
         ...,
         [ 0.0290],
         [ 0.0215],
         [-0.0192]]], requires_grad=True)

encoder.encoders.5.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.8495, 0.9976, 1.0196,  ..., 1.2646, 0.9822, 1.1243],
       requires_grad=True)

encoder.encoders.5.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.1780, -0.0165,  0.0455,  ..., -0.3698,  0.0022,  0.2537],
       requires_grad=True)

encoder.encoders.5.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0097,  0.0871,  0.0504,  ...,  0.0173,  0.0676,  0.0959],
        [-0.0259, -0.0252,  0.1060,  ..., -0.0231, -0.0798, -0.0374],
        [-0.0415, -0.0282, -0.0212,  ..., -0.0024, -0.0692,  0.0080],
        ...,
        [-0.0351, -0.0147,  0.0472,  ...,  0.0090, -0.0041, -0.0177],
        [-0.0420, -0.0580,  0.0146,  ...,  0.0508,  0.0828, -0.0188],
        [ 0.0040, -0.0566, -0.1094,  ..., -0.0517,  0.1026, -0.0445]],
       requires_grad=True)

encoder.encoders.5.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0289, -0.0099, -0.0026,  ..., -0.0208, -0.0292, -0.0328],
       requires_grad=True)

encoder.encoders.5.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0319,  0.0147, -0.0685,  ..., -0.0505,  0.0129,  0.0339],
        [-0.0554,  0.0025,  0.0263,  ..., -0.0135,  0.0084,  0.0172],
        [ 0.0208,  0.1263, -0.0105,  ..., -0.0071,  0.0125,  0.0020],
        ...,
        [ 0.0207, -0.0054,  0.0204,  ...,  0.0371, -0.0220, -0.0098],
        [-0.0455,  0.0101, -0.0240,  ...,  0.0380,  0.0474, -0.0136],
        [ 0.0351,  0.0342,  0.0287,  ..., -0.0661, -0.0048, -0.0496]],
       requires_grad=True)

encoder.encoders.5.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0059, -0.0121, -0.0057,  ..., -0.0434,  0.0018,  0.0229],
       requires_grad=True)

encoder.encoders.5.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3615, 1.2988, 1.2716,  ..., 1.3306, 1.2980, 1.2839],
       requires_grad=True)

encoder.encoders.5.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0172, -0.0192,  0.0327,  ..., -0.1555, -0.0220,  0.0770],
       requires_grad=True)

encoder.encoders.6.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.7567, 0.9076, 0.9745,  ..., 1.1360, 0.9636, 0.9992],
       requires_grad=True)

encoder.encoders.6.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.0861, -0.0243,  0.1217,  ..., -0.2828, -0.0640,  0.1387],
       requires_grad=True)

encoder.encoders.6.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0034, -0.1316, -0.0437,  ...,  0.0412,  0.0194,  0.0256],
        [-0.0043,  0.0492,  0.0013,  ...,  0.0110, -0.0858, -0.0118],
        [-0.0329,  0.0247, -0.0278,  ...,  0.0210,  0.0714,  0.0026],
        ...,
        [ 0.0154,  0.0521,  0.0112,  ...,  0.0466,  0.0602,  0.0306],
        [ 0.0571, -0.0799, -0.0171,  ...,  0.0988, -0.0744, -0.0953],
        [-0.0586,  0.0495, -0.1399,  ...,  0.0462,  0.0139, -0.1243]],
       requires_grad=True)

encoder.encoders.6.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0162, -0.0278, -0.0082,  ..., -0.0168, -0.0018, -0.0355],
       requires_grad=True)

encoder.encoders.6.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0211,  0.0094,  0.0238,  ...,  0.0472,  0.0715,  0.0032],
        [-0.0024, -0.0063, -0.0115,  ..., -0.0233, -0.0227,  0.0573],
        [-0.0194, -0.0523,  0.0347,  ...,  0.0290,  0.0186,  0.0417],
        ...,
        [-0.0692, -0.0145, -0.0220,  ...,  0.0574,  0.0238,  0.0058],
        [-0.0423, -0.0499,  0.0171,  ..., -0.0384,  0.0412,  0.0780],
        [ 0.0576,  0.0006,  0.0907,  ..., -0.0484,  0.0542, -0.0908]],
       requires_grad=True)

encoder.encoders.6.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0275, -0.0194, -0.0027,  ..., -0.0366, -0.0160,  0.0194],
       requires_grad=True)

encoder.encoders.6.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.1960, -0.1364,  0.0906,  ...,  0.0464,  0.1023,  0.2171],
        [ 0.2215, -0.1564, -0.1166,  ...,  0.0908,  0.2041,  0.2038],
        [-0.2173, -0.0973, -0.0331,  ...,  0.0349,  0.2273, -0.2146],
        ...,
        [-0.1451,  0.0402,  0.1561,  ...,  0.2124,  0.3020, -0.2398],
        [-0.1882,  0.2250, -0.3197,  ...,  0.1280, -0.0264, -0.1437],
        [ 0.0523,  0.0534,  0.2477,  ...,  0.0252, -0.1920,  0.1603]],
       requires_grad=True)

encoder.encoders.6.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.2961, -0.2722, -0.0614,  ...,  0.1612, -0.0256,  0.0977],
        [ 0.0501, -0.1756,  0.2936,  ...,  0.0178,  0.1963, -0.1418],
        [-0.1169, -0.2146,  0.2068,  ..., -0.0503,  0.0377, -0.3558],
        ...,
        [ 0.1323,  0.1819, -0.0098,  ..., -0.2043, -0.1472,  0.2114],
        [ 0.1386,  0.1372, -0.1065,  ...,  0.0218, -0.0372, -0.1201],
        [ 0.0342,  0.1006, -0.2139,  ...,  0.2318,  0.3462, -0.0818]],
       requires_grad=True)

encoder.encoders.6.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0970, -0.0128, -0.0188,  ..., -0.0309,  0.0918,  0.0039],
        [ 0.0629, -0.0016,  0.0034,  ..., -0.0475,  0.0066, -0.0055],
        [ 0.0640,  0.0083, -0.0685,  ..., -0.0296, -0.0388,  0.0330],
        ...,
        [ 0.0283, -0.0332, -0.0343,  ..., -0.0025, -0.0214,  0.0339],
        [-0.0844,  0.0116,  0.0620,  ...,  0.0099,  0.0285,  0.0015],
        [-0.0268, -0.0597, -0.0228,  ..., -0.0138,  0.0111,  0.0324]],
       requires_grad=True)

encoder.encoders.6.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0271, -0.0054, -0.0274,  ...,  0.0318, -0.0046, -0.0591],
        [-0.0071, -0.0063, -0.0024,  ..., -0.0423,  0.0133, -0.0269],
        [-0.0208,  0.0377, -0.0149,  ..., -0.0213, -0.0220,  0.0749],
        ...,
        [ 0.0691,  0.0009,  0.0102,  ...,  0.0422, -0.0265,  0.0296],
        [ 0.0505,  0.0431, -0.0338,  ...,  0.0167, -0.0290,  0.0482],
        [ 0.0276,  0.0333,  0.0576,  ...,  0.0016, -0.0354,  0.0880]],
       requires_grad=True)

encoder.encoders.6.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0618, -0.0796,  0.0450,  ...,  0.0068,  0.0294, -0.0106],
        [-0.0624, -0.0335,  0.0423,  ..., -0.0482,  0.0383, -0.0084],
        [-0.0148,  0.1457, -0.0376,  ...,  0.0319,  0.0731, -0.0722],
        ...,
        [ 0.0411,  0.0141, -0.0099,  ..., -0.0227,  0.0396, -0.0506],
        [ 0.0203, -0.0391, -0.0309,  ...,  0.0370, -0.0583, -0.0220],
        [-0.0286, -0.0231, -0.0304,  ..., -0.0630,  0.0643, -0.0361]],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.6783, 0.6661, 0.6689,  ..., 0.6006, 0.6146, 0.6214],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0833, -0.0381, -0.0216,  ...,  0.0397,  0.0269, -0.0347],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.7592, 0.7869, 0.7561,  ..., 0.8088, 0.7807, 0.7776],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0729, -0.0020,  0.0278,  ...,  0.0342, -0.0354,  0.0489],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6678, 0.6721, 0.6323,  ..., 0.5982, 0.5903, 0.6650],
       requires_grad=True)

encoder.encoders.6.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0609, -0.0210, -0.0398,  ...,  0.1471,  0.0247, -0.0598],
       requires_grad=True)

encoder.encoders.6.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0128,  0.0311,  0.0698,  ..., -0.0556,  0.0013,  0.0384],
        [ 0.0616, -0.0770, -0.0466,  ..., -0.0010, -0.0350,  0.0385],
        [-0.0538,  0.0314, -0.0269,  ...,  0.0093, -0.0257,  0.0404],
        ...,
        [-0.0699, -0.0274, -0.0447,  ...,  0.0250,  0.0487,  0.0201],
        [ 0.0032,  0.0654,  0.0432,  ...,  0.0010,  0.0544,  0.0314],
        [-0.0269,  0.0309,  0.1122,  ..., -0.0327,  0.0036, -0.0188]],
       requires_grad=True)

encoder.encoders.6.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0320, -0.0338, -0.0765,  ..., -0.0328, -0.0347,  0.0386],
        [-0.0362,  0.0492, -0.0260,  ...,  0.0440, -0.0434, -0.0213],
        [ 0.0288,  0.0338,  0.0114,  ..., -0.0399, -0.0044, -0.0240],
        ...,
        [-0.0894, -0.0651, -0.0421,  ...,  0.0058,  0.0622,  0.0262],
        [-0.1186, -0.0067, -0.1207,  ...,  0.0055, -0.0208,  0.0190],
        [ 0.0453,  0.0421,  0.0338,  ...,  0.0203, -0.0281, -0.0023]],
       requires_grad=True)

encoder.encoders.6.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([0.9325, 1.1421, 1.0880,  ..., 1.1522, 1.0302, 1.1231],
       requires_grad=True)

encoder.encoders.6.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0551,  0.0624, -0.0686,  ..., -0.0734,  0.0098,  0.1091],
       requires_grad=True)

encoder.encoders.6.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0684],
         [-0.1375],
         [-0.0734],
         ...,
         [-0.0635],
         [ 0.0256],
         [ 0.0343]],

        [[ 0.0494],
         [ 0.1350],
         [ 0.0656],
         ...,
         [-0.0607],
         [-0.0425],
         [ 0.0849]],

        [[ 0.0657],
         [ 0.0576],
         [-0.0003],
         ...,
         [ 0.0134],
         [-0.0113],
         [ 0.0612]],

        ...,

        [[-0.0333],
         [ 0.0815],
         [-0.0430],
         ...,
         [ 0.0621],
         [-0.1145],
         [-0.0013]],

        [[-0.0609],
         [ 0.0187],
         [ 0.0069],
         ...,
         [-0.0705],
         [ 0.0235],
         [ 0.0653]],

        [[ 0.0260],
         [ 0.0193],
         [ 0.0651],
         ...,
         [-0.0399],
         [ 0.1397],
         [-0.0573]]], requires_grad=True)

encoder.encoders.6.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 1.2257e-02,  2.3786e-02,  1.6498e-03,  ..., -8.0673e-03,
           2.0628e-02,  1.2943e-02]],

        [[ 2.7953e-03, -1.7737e-02, -1.1161e-04,  ...,  2.8125e-03,
           4.6054e-05,  1.6219e-02]],

        [[ 7.6365e-03, -1.0226e-03, -3.6504e-02,  ..., -3.5330e-03,
           1.5611e-02,  3.6166e-02]],

        ...,

        [[-1.2341e-02,  1.5649e-03, -5.8392e-03,  ..., -2.0267e-02,
          -6.6154e-03, -3.5864e-02]],

        [[ 8.7836e-02,  4.8983e-02,  4.4197e-02,  ...,  4.9808e-04,
          -5.6957e-04,  2.2717e-02]],

        [[ 1.0906e-02,  7.3283e-03,  2.0472e-03,  ...,  3.0727e-02,
           8.3535e-03,  3.8833e-02]]], requires_grad=True)

encoder.encoders.6.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0476, 1.0158, 1.0115,  ..., 0.9803, 1.0013, 0.9732],
       requires_grad=True)

encoder.encoders.6.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0603, -0.0682, -0.0312,  ..., -0.0641, -0.0573, -0.0650],
       requires_grad=True)

encoder.encoders.6.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0114],
         [-0.0194],
         [ 0.0762],
         ...,
         [-0.0888],
         [-0.0786],
         [ 0.0354]],

        [[ 0.0209],
         [-0.1065],
         [ 0.0295],
         ...,
         [-0.0832],
         [ 0.0041],
         [ 0.0019]],

        [[-0.0510],
         [ 0.0784],
         [-0.0145],
         ...,
         [-0.0202],
         [-0.0148],
         [ 0.0280]],

        ...,

        [[ 0.0241],
         [-0.0217],
         [ 0.0251],
         ...,
         [ 0.0503],
         [ 0.0056],
         [-0.0340]],

        [[ 0.0463],
         [ 0.0660],
         [ 0.0312],
         ...,
         [ 0.0505],
         [ 0.0124],
         [ 0.0543]],

        [[-0.0119],
         [-0.0275],
         [ 0.1075],
         ...,
         [-0.0312],
         [-0.1319],
         [-0.0149]]], requires_grad=True)

encoder.encoders.6.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([0.9712, 0.9112, 1.0164,  ..., 0.9585, 0.9671, 1.1792],
       requires_grad=True)

encoder.encoders.6.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.2485, -0.0329,  0.1071,  ..., -0.1257, -0.0872,  0.2117],
       requires_grad=True)

encoder.encoders.6.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0513,  0.0190, -0.0661,  ...,  0.0281, -0.0737,  0.0216],
        [-0.0718,  0.0216,  0.0002,  ..., -0.0258,  0.1094,  0.0171],
        [-0.0678, -0.0253,  0.0163,  ..., -0.0735, -0.0961, -0.0595],
        ...,
        [-0.0183, -0.0467,  0.0206,  ...,  0.0078,  0.0126,  0.0808],
        [-0.0706, -0.0011, -0.0231,  ...,  0.0826,  0.0026, -0.0235],
        [-0.0428, -0.0266,  0.0200,  ...,  0.0488, -0.0569, -0.0162]],
       requires_grad=True)

encoder.encoders.6.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0286,  0.0037, -0.0138,  ..., -0.0338, -0.0233, -0.0415],
       requires_grad=True)

encoder.encoders.6.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0329, -0.0243,  0.0116,  ..., -0.0832,  0.0375,  0.0411],
        [ 0.0750,  0.0048,  0.0480,  ...,  0.0316,  0.0109, -0.0428],
        [-0.0466,  0.0407, -0.1163,  ...,  0.0629,  0.0149,  0.0207],
        ...,
        [ 0.0341, -0.0445, -0.0099,  ..., -0.0065, -0.0412,  0.0229],
        [ 0.0341,  0.0336,  0.0207,  ..., -0.0095,  0.0059, -0.0306],
        [ 0.0157,  0.0908,  0.0246,  ...,  0.0010, -0.0379,  0.0696]],
       requires_grad=True)

encoder.encoders.6.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0118, -0.0200, -0.0052,  ..., -0.0133, -0.0150,  0.0041],
       requires_grad=True)

encoder.encoders.6.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2866, 1.2857, 1.2543,  ..., 1.2989, 1.2914, 1.2695],
       requires_grad=True)

encoder.encoders.6.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0548, -0.0062,  0.0428,  ..., -0.0709, -0.0299,  0.0930],
       requires_grad=True)

encoder.encoders.7.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.9312, 0.9352, 0.9327,  ..., 0.9222, 0.8809, 1.0734],
       requires_grad=True)

encoder.encoders.7.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.1771, -0.0191,  0.0819,  ..., -0.0673, -0.0217,  0.1822],
       requires_grad=True)

encoder.encoders.7.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0009, -0.0443,  0.0386,  ...,  0.0355,  0.0739, -0.0375],
        [ 0.0037,  0.0797,  0.0743,  ...,  0.0051,  0.0108,  0.0481],
        [-0.0859, -0.0597, -0.0012,  ...,  0.0096,  0.0063, -0.0559],
        ...,
        [ 0.0132, -0.0681, -0.0658,  ...,  0.0499,  0.0292, -0.0225],
        [ 0.0399, -0.0765, -0.0037,  ..., -0.0187, -0.0175,  0.0183],
        [-0.0008, -0.0560, -0.0725,  ...,  0.1135, -0.0196, -0.0412]],
       requires_grad=True)

encoder.encoders.7.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0208, -0.0528, -0.0112,  ..., -0.0034, -0.0241, -0.0042],
       requires_grad=True)

encoder.encoders.7.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0211, -0.0086,  0.0136,  ...,  0.0151,  0.0215,  0.0826],
        [-0.0069, -0.0354, -0.0305,  ..., -0.0192,  0.0541, -0.0491],
        [-0.0268,  0.0199, -0.0502,  ..., -0.0431, -0.0015, -0.0587],
        ...,
        [ 0.0190, -0.0190, -0.0496,  ..., -0.0035,  0.0287,  0.0622],
        [-0.0171,  0.0292, -0.0594,  ..., -0.0112,  0.0120, -0.0607],
        [ 0.0434, -0.0766, -0.0155,  ..., -0.0474,  0.0281, -0.0244]],
       requires_grad=True)

encoder.encoders.7.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0148,  0.0173,  0.0306,  ..., -0.0339, -0.0277,  0.0050],
       requires_grad=True)

encoder.encoders.7.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.0572,  0.0948, -0.1351,  ...,  0.1504,  0.1220, -0.0893],
        [ 0.0949,  0.1468, -0.1946,  ..., -0.2441,  0.2101, -0.3710],
        [-0.2783, -0.2349,  0.1307,  ..., -0.0352,  0.1736,  0.0614],
        ...,
        [ 0.0310,  0.2195, -0.0050,  ...,  0.1510,  0.2315,  0.1002],
        [ 0.1788,  0.1799,  0.1755,  ...,  0.2520, -0.1568, -0.2130],
        [ 0.0719, -0.1602,  0.1959,  ..., -0.0039,  0.1723,  0.0503]],
       requires_grad=True)

encoder.encoders.7.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.4060,  0.0120, -0.0594,  ..., -0.0544,  0.0867,  0.1029],
        [-0.0743, -0.3454,  0.1164,  ..., -0.0623, -0.0153,  0.2575],
        [ 0.3241, -0.0879,  0.3952,  ...,  0.1756, -0.2108, -0.0822],
        ...,
        [-0.0593,  0.0241, -0.1780,  ..., -0.3349, -0.1497,  0.2076],
        [-0.3256, -0.0536,  0.0064,  ...,  0.0315, -0.1753,  0.1604],
        [ 0.0144,  0.1332,  0.0733,  ..., -0.1948, -0.0759, -0.1252]],
       requires_grad=True)

encoder.encoders.7.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0173, -0.0457, -0.0350,  ..., -0.0781,  0.0613, -0.0063],
        [-0.0191,  0.0073, -0.0156,  ...,  0.0018,  0.0061,  0.0190],
        [-0.0644, -0.0313, -0.0640,  ..., -0.0158,  0.0371,  0.0577],
        ...,
        [-0.0200, -0.0056, -0.0156,  ..., -0.0142, -0.0517,  0.0124],
        [ 0.0161, -0.0111, -0.0102,  ...,  0.0173, -0.0295, -0.0495],
        [-0.0643, -0.0331, -0.0250,  ..., -0.0284, -0.0344,  0.0597]],
       requires_grad=True)

encoder.encoders.7.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0565, -0.0370, -0.0236,  ...,  0.0660,  0.0107,  0.0620],
        [-0.0718, -0.0493, -0.1112,  ..., -0.0351,  0.0397,  0.0327],
        [ 0.0165, -0.1150, -0.0301,  ..., -0.0746,  0.0142,  0.0980],
        ...,
        [-0.0452, -0.1453, -0.0091,  ..., -0.0031, -0.0267, -0.0347],
        [ 0.0651, -0.0351,  0.0134,  ...,  0.0181, -0.0496, -0.0367],
        [-0.0640, -0.0402,  0.0181,  ..., -0.0122, -0.0104,  0.0747]],
       requires_grad=True)

encoder.encoders.7.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0103,  0.0340,  0.0040,  ..., -0.0331,  0.0003, -0.0665],
        [ 0.0072, -0.0625,  0.0216,  ..., -0.0368, -0.0128, -0.0633],
        [-0.0873,  0.0577, -0.0336,  ..., -0.0293,  0.0213,  0.0556],
        ...,
        [-0.0547,  0.0010,  0.0140,  ..., -0.0310, -0.0325,  0.1024],
        [ 0.0290,  0.0431, -0.0101,  ...,  0.0035, -0.0696,  0.0192],
        [-0.0301, -0.0284,  0.0138,  ..., -0.0454,  0.0498,  0.0049]],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.6953, 0.6778, 0.6753,  ..., 0.7308, 0.6473, 0.6958],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0311, -0.0014, -0.0251,  ...,  0.0589,  0.0419, -0.0450],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8068, 0.8481, 0.7908,  ..., 0.7827, 0.7529, 0.7714],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0252,  0.0029, -0.0313,  ...,  0.0258, -0.0376, -0.0078],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6691, 0.6596, 0.6345,  ..., 0.6276, 0.6362, 0.6682],
       requires_grad=True)

encoder.encoders.7.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0217, -0.0107, -0.0341,  ...,  0.0814,  0.0449, -0.0907],
       requires_grad=True)

encoder.encoders.7.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0443, -0.0456,  0.0500,  ...,  0.0133, -0.0355, -0.0801],
        [ 0.0050, -0.0238, -0.0040,  ..., -0.0983, -0.0127,  0.0526],
        [-0.0056,  0.0521,  0.0294,  ..., -0.1025,  0.0263,  0.0593],
        ...,
        [ 0.0124, -0.0396,  0.0155,  ..., -0.0573,  0.0084,  0.0277],
        [ 0.0196, -0.0068, -0.0291,  ..., -0.0791,  0.0470, -0.0389],
        [-0.0231, -0.0386, -0.0248,  ..., -0.0997,  0.0138,  0.0094]],
       requires_grad=True)

encoder.encoders.7.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0831,  0.0510,  0.0332,  ..., -0.0339, -0.0160,  0.0231],
        [-0.0606, -0.0139, -0.0552,  ..., -0.0495,  0.0237, -0.0068],
        [ 0.0236,  0.0105, -0.0118,  ...,  0.0777,  0.0067,  0.0052],
        ...,
        [-0.0045,  0.0131, -0.0299,  ..., -0.0088,  0.0190, -0.0301],
        [-0.0167,  0.0063, -0.0008,  ..., -0.0199,  0.0037, -0.0326],
        [-0.0102, -0.0336,  0.0340,  ..., -0.0330,  0.0079,  0.0854]],
       requires_grad=True)

encoder.encoders.7.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.0830, 1.1425, 1.1091,  ..., 1.1854, 1.1175, 1.1771],
       requires_grad=True)

encoder.encoders.7.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0376,  0.0849,  0.0785,  ..., -0.0810, -0.0470,  0.1146],
       requires_grad=True)

encoder.encoders.7.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0423],
         [ 0.0139],
         [ 0.0015],
         ...,
         [ 0.0119],
         [-0.0336],
         [ 0.0243]],

        [[ 0.0666],
         [ 0.0146],
         [-0.0056],
         ...,
         [ 0.0137],
         [-0.0488],
         [ 0.0451]],

        [[ 0.0201],
         [-0.0353],
         [-0.0428],
         ...,
         [-0.0542],
         [-0.0484],
         [ 0.0050]],

        ...,

        [[ 0.0678],
         [ 0.0561],
         [-0.0075],
         ...,
         [-0.0111],
         [-0.0446],
         [ 0.0135]],

        [[-0.0136],
         [-0.1124],
         [-0.1040],
         ...,
         [ 0.0184],
         [-0.0094],
         [-0.0559]],

        [[ 0.0533],
         [ 0.0255],
         [-0.0218],
         ...,
         [ 0.0421],
         [ 0.0028],
         [-0.0223]]], requires_grad=True)

encoder.encoders.7.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0439, -0.0112, -0.0105,  ..., -0.0341, -0.0135, -0.0204]],

        [[-0.0377, -0.0180, -0.0256,  ...,  0.0076, -0.0101, -0.0293]],

        [[-0.0446, -0.0783, -0.0112,  ..., -0.0323,  0.0077,  0.0364]],

        ...,

        [[ 0.0454, -0.0057, -0.0069,  ...,  0.0449,  0.0193,  0.0644]],

        [[ 0.0131,  0.0036, -0.0133,  ...,  0.0102,  0.0085,  0.0307]],

        [[ 0.0439,  0.0246,  0.0253,  ..., -0.0024,  0.0021, -0.0049]]],
       requires_grad=True)

encoder.encoders.7.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([0.9939, 1.0022, 1.0051,  ..., 1.0390, 1.0194, 1.0165],
       requires_grad=True)

encoder.encoders.7.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0242, -0.0182,  0.0030,  ..., -0.0195, -0.0607, -0.0321],
       requires_grad=True)

encoder.encoders.7.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[ 0.1179],
         [-0.0213],
         [ 0.0001],
         ...,
         [-0.0476],
         [-0.0615],
         [ 0.0458]],

        [[ 0.0504],
         [-0.0003],
         [-0.0584],
         ...,
         [ 0.0235],
         [-0.0339],
         [ 0.0514]],

        [[-0.0585],
         [ 0.0838],
         [-0.0375],
         ...,
         [-0.0363],
         [-0.0452],
         [ 0.0609]],

        ...,

        [[-0.0207],
         [-0.0534],
         [-0.0435],
         ...,
         [-0.0340],
         [ 0.0628],
         [-0.0169]],

        [[-0.0007],
         [-0.0289],
         [-0.0030],
         ...,
         [-0.0922],
         [ 0.0007],
         [-0.0090]],

        [[ 0.0166],
         [ 0.0501],
         [ 0.0144],
         ...,
         [-0.0217],
         [-0.0246],
         [ 0.0634]]], requires_grad=True)

encoder.encoders.7.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.0305, 0.9904, 1.0030,  ..., 1.1509, 0.9807, 1.1076],
       requires_grad=True)

encoder.encoders.7.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.0614,  0.0087,  0.0569,  ..., -0.2591, -0.1370,  0.1785],
       requires_grad=True)

encoder.encoders.7.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0318,  0.0101,  0.0140,  ...,  0.0013,  0.0100,  0.0308],
        [ 0.0409, -0.0563,  0.0017,  ...,  0.0543,  0.0471, -0.0714],
        [-0.0896,  0.0561,  0.0540,  ...,  0.0217,  0.0238, -0.0991],
        ...,
        [ 0.0069, -0.0089,  0.0070,  ...,  0.0003, -0.0044,  0.0116],
        [-0.0130,  0.0504,  0.0991,  ...,  0.0178, -0.0404, -0.0185],
        [-0.0295,  0.0640,  0.1156,  ...,  0.0438,  0.0183,  0.0399]],
       requires_grad=True)

encoder.encoders.7.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0327, -0.0005,  0.0115,  ..., -0.0023,  0.0021,  0.0124],
       requires_grad=True)

encoder.encoders.7.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0216, -0.0186, -0.0253,  ...,  0.0911, -0.0984, -0.0087],
        [ 0.0033, -0.0484, -0.0078,  ...,  0.0694, -0.0606, -0.0061],
        [ 0.0401, -0.0318, -0.0638,  ...,  0.0079,  0.0368,  0.0269],
        ...,
        [-0.0319, -0.0535, -0.0786,  ...,  0.0608, -0.0239, -0.0106],
        [ 0.0248,  0.0054,  0.0455,  ...,  0.0018, -0.0166, -0.0741],
        [-0.0170, -0.0017, -0.0163,  ..., -0.0225, -0.0539, -0.0452]],
       requires_grad=True)

encoder.encoders.7.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0145,  0.0037,  0.0034,  ...,  0.0024, -0.0227,  0.0011],
       requires_grad=True)

encoder.encoders.7.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2834, 1.2890, 1.3371,  ..., 1.3175, 1.3532, 1.2808],
       requires_grad=True)

encoder.encoders.7.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0188,  0.0558,  0.1235,  ..., -0.1143, -0.1100,  0.0756],
       requires_grad=True)

encoder.encoders.8.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.9335, 0.9085, 0.9445,  ..., 1.0021, 0.8417, 0.9644],
       requires_grad=True)

encoder.encoders.8.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.0370,  0.1319, -0.0031,  ..., -0.2096, -0.0856,  0.1253],
       requires_grad=True)

encoder.encoders.8.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 2.6792e-02, -5.1396e-02, -1.6896e-02,  ...,  3.4971e-02,
          1.6453e-03, -6.9827e-02],
        [-3.5691e-02,  2.3466e-02,  4.2275e-02,  ...,  4.8958e-02,
          9.3461e-02, -2.5318e-02],
        [-4.6792e-02, -6.3594e-02, -6.1981e-02,  ..., -5.0822e-02,
          4.0003e-05,  5.4069e-02],
        ...,
        [-1.0037e-01, -6.2878e-02,  9.2963e-03,  ..., -6.4345e-02,
          5.8843e-02, -4.7236e-03],
        [-8.0708e-02,  1.4355e-02,  3.5653e-02,  ...,  5.5767e-02,
         -2.6713e-02, -3.2637e-02],
        [-1.8611e-02,  1.6133e-02, -4.6198e-03,  ..., -4.4177e-02,
         -3.8728e-02,  1.7692e-02]], requires_grad=True)

encoder.encoders.8.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0420, -0.0084,  0.0110,  ..., -0.0052, -0.0086, -0.0458],
       requires_grad=True)

encoder.encoders.8.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.1057, -0.0060, -0.0159,  ...,  0.0402, -0.0272, -0.0607],
        [-0.0442,  0.0240, -0.0711,  ..., -0.0050, -0.0800,  0.0012],
        [ 0.0141,  0.0146,  0.0378,  ..., -0.0050,  0.0244, -0.0139],
        ...,
        [-0.0149,  0.0505,  0.0567,  ...,  0.0171,  0.0252, -0.0527],
        [ 0.0203,  0.0358,  0.0401,  ...,  0.0582,  0.0352,  0.0380],
        [-0.0166,  0.0359, -0.0054,  ...,  0.0338,  0.0167,  0.0329]],
       requires_grad=True)

encoder.encoders.8.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0086,  0.0233,  0.0490,  ..., -0.0222, -0.0525,  0.0421],
       requires_grad=True)

encoder.encoders.8.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.0594, -0.0683,  0.1292,  ...,  0.2048,  0.2765,  0.0597],
        [ 0.1731, -0.0321, -0.2246,  ..., -0.0785, -0.1020, -0.0892],
        [-0.2126, -0.1641, -0.1715,  ..., -0.0474, -0.0035, -0.1657],
        ...,
        [ 0.0596,  0.1387, -0.2820,  ..., -0.3250,  0.1054, -0.1111],
        [ 0.2890, -0.1855, -0.0323,  ...,  0.0674,  0.1544,  0.1910],
        [ 0.0003, -0.0613, -0.0383,  ...,  0.0494, -0.1498, -0.0705]],
       requires_grad=True)

encoder.encoders.8.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.1488, -0.0365, -0.1307,  ..., -0.1192,  0.1185, -0.2711],
        [-0.2230, -0.1299, -0.2002,  ...,  0.3338,  0.2138,  0.0455],
        [ 0.0915, -0.1310, -0.3113,  ..., -0.2657, -0.1179,  0.1195],
        ...,
        [ 0.0934,  0.2005, -0.1145,  ...,  0.3491,  0.3591,  0.3133],
        [ 0.1895,  0.0251, -0.1225,  ...,  0.2849,  0.1377, -0.1316],
        [ 0.2071, -0.1813, -0.2290,  ..., -0.0820, -0.3114, -0.2797]],
       requires_grad=True)

encoder.encoders.8.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0315, -0.0029,  0.0369,  ..., -0.0204,  0.1183,  0.0679],
        [ 0.0028,  0.0202,  0.1066,  ..., -0.0602, -0.0181, -0.0189],
        [ 0.0550, -0.0841,  0.1127,  ..., -0.0256,  0.0123, -0.0502],
        ...,
        [-0.0180,  0.0307,  0.0231,  ...,  0.1048,  0.0368,  0.0103],
        [ 0.0728,  0.0646,  0.0517,  ...,  0.1132, -0.0321,  0.0238],
        [ 0.0760,  0.1058,  0.0834,  ..., -0.0043, -0.0456, -0.0543]],
       requires_grad=True)

encoder.encoders.8.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 1.0770e-01, -1.1761e-02, -1.4959e-01,  ..., -3.2893e-02,
          4.3655e-02, -6.2789e-03],
        [ 2.9300e-02, -9.3104e-02, -3.5269e-03,  ..., -6.5115e-03,
         -2.0981e-02, -7.4469e-02],
        [ 3.4379e-02,  7.0729e-02, -5.0849e-02,  ..., -1.2830e-01,
         -2.0024e-02,  8.6626e-02],
        ...,
        [-2.1361e-02,  6.0377e-02, -1.0563e-02,  ..., -9.9854e-02,
          2.7179e-02, -3.0815e-02],
        [-2.4831e-02,  4.8150e-02, -1.1823e-02,  ..., -2.5109e-02,
         -3.9858e-02,  8.8870e-04],
        [-2.6579e-02,  5.7970e-02, -3.8944e-05,  ...,  3.3292e-02,
          4.2788e-02, -5.8401e-02]], requires_grad=True)

encoder.encoders.8.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0049, -0.0054,  0.0371,  ..., -0.0684,  0.0060,  0.0050],
        [-0.0418,  0.0589,  0.0406,  ...,  0.0244, -0.0012,  0.0306],
        [-0.0253,  0.0771,  0.0637,  ..., -0.0464, -0.0212,  0.0394],
        ...,
        [ 0.0404,  0.0311, -0.0088,  ..., -0.0653, -0.0198,  0.0528],
        [-0.0498,  0.0597,  0.0298,  ...,  0.0296, -0.0449, -0.0050],
        [ 0.0482, -0.0006, -0.0104,  ..., -0.0079, -0.0285,  0.0039]],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.8074, 0.7687, 0.7222,  ..., 0.8304, 0.7949, 0.8231],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0254, -0.0462, -0.1768,  ...,  0.0225,  0.0641,  0.0006],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8980, 0.8697, 0.8274,  ..., 0.8783, 0.8575, 0.8606],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0049, -0.0169,  0.0462,  ...,  0.0287,  0.0397,  0.0226],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5349, 0.5162, 0.4801,  ..., 0.4775, 0.4932, 0.5257],
       requires_grad=True)

encoder.encoders.8.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([-0.0109, -0.0159, -0.1561,  ...,  0.0816,  0.0903, -0.0767],
       requires_grad=True)

encoder.encoders.8.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0356,  0.0553,  0.0379,  ...,  0.0107, -0.0288, -0.0833],
        [-0.0322,  0.0030, -0.0190,  ...,  0.0338, -0.0465, -0.0090],
        [-0.0787, -0.0095,  0.0566,  ..., -0.0479,  0.0032, -0.0901],
        ...,
        [ 0.0331,  0.0379,  0.0198,  ..., -0.0457,  0.0257,  0.0139],
        [-0.0856,  0.0383,  0.0043,  ...,  0.0152, -0.0359, -0.0030],
        [-0.0151, -0.0504,  0.0270,  ..., -0.0005, -0.0319,  0.0225]],
       requires_grad=True)

encoder.encoders.8.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-8.1301e-02, -3.5025e-02, -6.6265e-02,  ..., -7.5924e-03,
          2.5228e-03,  3.4724e-02],
        [-2.9173e-02,  3.9984e-02, -4.5188e-02,  ...,  1.3227e-02,
         -3.2008e-02,  1.9464e-03],
        [-1.9014e-02, -2.7207e-07,  8.8417e-03,  ..., -6.0468e-03,
          4.0801e-02, -2.2590e-02],
        ...,
        [-1.4065e-02, -8.8223e-02, -5.8405e-02,  ..., -1.7699e-02,
         -2.6443e-02,  1.2079e-02],
        [-1.2280e-01, -1.3305e-02, -1.3720e-01,  ...,  2.4816e-02,
          2.3673e-02, -1.7090e-02],
        [-7.8804e-02, -1.7723e-01,  1.1372e-02,  ...,  1.4644e-02,
         -4.6433e-03,  4.9293e-03]], requires_grad=True)

encoder.encoders.8.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.2956, 1.0823, 1.0444,  ..., 1.1859, 1.1218, 1.1561],
       requires_grad=True)

encoder.encoders.8.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0695,  0.0652, -0.0299,  ...,  0.0096, -0.1134, -0.0154],
       requires_grad=True)

encoder.encoders.8.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.0842],
         [ 0.0081],
         [ 0.0489],
         ...,
         [-0.0360],
         [-0.0230],
         [ 0.0328]],

        [[ 0.0077],
         [-0.0393],
         [-0.0080],
         ...,
         [-0.0069],
         [ 0.0095],
         [-0.0249]],

        [[-0.0359],
         [-0.1066],
         [-0.0071],
         ...,
         [ 0.0390],
         [ 0.0180],
         [ 0.0349]],

        ...,

        [[ 0.0579],
         [ 0.0057],
         [-0.0028],
         ...,
         [ 0.0356],
         [ 0.1074],
         [ 0.0420]],

        [[ 0.0527],
         [-0.0216],
         [-0.0078],
         ...,
         [ 0.0162],
         [ 0.0562],
         [ 0.0142]],

        [[-0.0464],
         [-0.0238],
         [ 0.0024],
         ...,
         [-0.0589],
         [-0.0152],
         [-0.0081]]], requires_grad=True)

encoder.encoders.8.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 0.0154, -0.0092,  0.0094,  ..., -0.0206,  0.0127,  0.0135]],

        [[ 0.0195, -0.0087,  0.0018,  ..., -0.0044, -0.0411,  0.0082]],

        [[-0.0171,  0.0288,  0.0177,  ...,  0.0173, -0.0024,  0.0081]],

        ...,

        [[ 0.0345,  0.0173,  0.0078,  ...,  0.0024, -0.0059,  0.0232]],

        [[-0.0038, -0.0279, -0.0172,  ...,  0.0106, -0.0009, -0.0603]],

        [[ 0.0245, -0.0077,  0.0035,  ...,  0.0160, -0.0013, -0.0218]]],
       requires_grad=True)

encoder.encoders.8.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0001, 1.0500, 1.0467,  ..., 1.0451, 0.9802, 1.0253],
       requires_grad=True)

encoder.encoders.8.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0226, -0.0165, -0.0272,  ..., -0.0462, -0.0286, -0.0174],
       requires_grad=True)

encoder.encoders.8.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[ 0.0423],
         [-0.0321],
         [ 0.0621],
         ...,
         [-0.0416],
         [ 0.0530],
         [-0.0447]],

        [[ 0.0603],
         [ 0.0046],
         [ 0.0294],
         ...,
         [ 0.0694],
         [ 0.0126],
         [-0.0256]],

        [[-0.0165],
         [ 0.0918],
         [-0.0492],
         ...,
         [ 0.0186],
         [-0.0260],
         [-0.0334]],

        ...,

        [[-0.0740],
         [ 0.0577],
         [ 0.0163],
         ...,
         [ 0.0171],
         [ 0.0356],
         [-0.1161]],

        [[ 0.0178],
         [ 0.0495],
         [ 0.0039],
         ...,
         [ 0.0671],
         [ 0.0023],
         [ 0.0381]],

        [[ 0.0587],
         [ 0.0010],
         [ 0.0283],
         ...,
         [-0.0474],
         [-0.0068],
         [-0.0805]]], requires_grad=True)

encoder.encoders.8.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.0802, 1.0044, 1.5298,  ..., 1.0335, 1.2772, 1.1716],
       requires_grad=True)

encoder.encoders.8.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([ 0.2427, -0.1091,  0.6379,  ..., -0.1173, -0.4729,  0.3516],
       requires_grad=True)

encoder.encoders.8.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0077,  0.0052,  0.0204,  ...,  0.0858,  0.0996,  0.0531],
        [-0.0012,  0.0278, -0.0145,  ..., -0.0445,  0.0462, -0.0776],
        [-0.0250,  0.0160,  0.0037,  ...,  0.0503, -0.0173, -0.0281],
        ...,
        [-0.0524, -0.0636,  0.0155,  ...,  0.0133,  0.0180,  0.0004],
        [ 0.0597, -0.0210, -0.0537,  ...,  0.0789,  0.0283, -0.0818],
        [-0.0672,  0.0326, -0.0465,  ...,  0.0685,  0.0372,  0.0028]],
       requires_grad=True)

encoder.encoders.8.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0111, -0.0361, -0.0052,  ..., -0.0253,  0.0176,  0.0091],
       requires_grad=True)

encoder.encoders.8.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0432, -0.0398, -0.0240,  ...,  0.0320,  0.0079,  0.0036],
        [ 0.0123, -0.0042, -0.0555,  ...,  0.0307,  0.0037, -0.0067],
        [ 0.0145,  0.0478,  0.0077,  ..., -0.0816,  0.0289,  0.0338],
        ...,
        [-0.0343, -0.0252,  0.0062,  ...,  0.0369,  0.1259,  0.0266],
        [ 0.0063, -0.0297, -0.0021,  ..., -0.0220,  0.0131,  0.0056],
        [ 0.0201, -0.0471,  0.0017,  ...,  0.0358, -0.0538,  0.0021]],
       requires_grad=True)

encoder.encoders.8.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0258,  0.0117,  0.0359,  ...,  0.0009, -0.0049,  0.0014],
       requires_grad=True)

encoder.encoders.8.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.1784, 1.2880, 1.4707,  ..., 1.3006, 1.3392, 1.2619],
       requires_grad=True)

encoder.encoders.8.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.0056,  0.0583,  0.4165,  ..., -0.1086, -0.1686,  0.0627],
       requires_grad=True)

encoder.encoders.9.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.0368, 0.8666, 1.1983,  ..., 1.0503, 1.0320, 0.9420],
       requires_grad=True)

encoder.encoders.9.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.1692,  0.0277,  0.4107,  ..., -0.2702, -0.3117,  0.1677],
       requires_grad=True)

encoder.encoders.9.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0462,  0.0173, -0.0888,  ...,  0.0449, -0.0420, -0.0718],
        [ 0.0892,  0.0215, -0.0170,  ...,  0.0394,  0.0275, -0.0005],
        [-0.0062,  0.0240, -0.0359,  ...,  0.0558,  0.0368,  0.0034],
        ...,
        [-0.0376, -0.0117,  0.0852,  ...,  0.0401, -0.0468,  0.0171],
        [-0.1036, -0.0219, -0.0633,  ..., -0.0322,  0.0649,  0.0119],
        [ 0.0448, -0.0447, -0.0021,  ...,  0.0567, -0.0657,  0.0586]],
       requires_grad=True)

encoder.encoders.9.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0334, -0.0125, -0.0187,  ..., -0.0059, -0.0001,  0.0090],
       requires_grad=True)

encoder.encoders.9.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0379, -0.0774,  0.0149,  ...,  0.0441, -0.0293, -0.0146],
        [-0.0083,  0.0073,  0.0413,  ...,  0.0242, -0.0090,  0.0162],
        [ 0.0004, -0.0146, -0.0494,  ...,  0.0055,  0.0048,  0.0450],
        ...,
        [-0.0145, -0.1013, -0.0506,  ...,  0.0480, -0.0355, -0.0719],
        [ 0.0002,  0.0173, -0.0253,  ..., -0.0411, -0.0384, -0.0226],
        [ 0.0225,  0.0185,  0.0060,  ...,  0.0574,  0.0058,  0.0442]],
       requires_grad=True)

encoder.encoders.9.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0442,  0.0478,  0.0854,  ..., -0.0431, -0.0391,  0.0196],
       requires_grad=True)

encoder.encoders.9.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.2477, -0.0402,  0.1097,  ..., -0.0631,  0.0140,  0.0793],
        [ 0.1503, -0.1035,  0.1520,  ...,  0.0304, -0.0933, -0.2738],
        [-0.2461, -0.3283,  0.2258,  ..., -0.1420, -0.0220, -0.2613],
        ...,
        [-0.1589, -0.2526,  0.1721,  ..., -0.2795, -0.1540, -0.1244],
        [ 0.0721, -0.2023, -0.1094,  ...,  0.1544,  0.0729, -0.0139],
        [ 0.0551,  0.0908, -0.1142,  ...,  0.0179, -0.1501,  0.1360]],
       requires_grad=True)

encoder.encoders.9.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 0.1816, -0.0675,  0.0208,  ..., -0.0726, -0.0239,  0.1369],
        [ 0.1090,  0.1295, -0.0292,  ...,  0.2376,  0.2983,  0.2399],
        [ 0.0712,  0.2862, -0.2081,  ..., -0.2103,  0.0723,  0.1730],
        ...,
        [-0.0852,  0.2708, -0.2129,  ...,  0.4031, -0.0040,  0.0906],
        [-0.0259, -0.0352, -0.1799,  ...,  0.0952, -0.0913,  0.2364],
        [ 0.1245,  0.1566,  0.0512,  ..., -0.2199,  0.1042,  0.0136]],
       requires_grad=True)

encoder.encoders.9.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0068, -0.0893, -0.0003,  ...,  0.0493,  0.0587,  0.0409],
        [-0.0449,  0.0293,  0.0134,  ..., -0.0106, -0.0062, -0.0392],
        [-0.1245,  0.0571,  0.0318,  ...,  0.0219,  0.0376, -0.0371],
        ...,
        [ 0.0244, -0.0167,  0.0221,  ..., -0.0357, -0.0297, -0.0283],
        [-0.0215,  0.0122,  0.0350,  ...,  0.0008, -0.0179,  0.0539],
        [ 0.0459,  0.0095, -0.0488,  ..., -0.0180,  0.0498, -0.0027]],
       requires_grad=True)

encoder.encoders.9.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0329, -0.0249, -0.0576,  ...,  0.0180,  0.0172, -0.0115],
        [ 0.0361,  0.0146,  0.0109,  ..., -0.0724, -0.0221, -0.0375],
        [ 0.0451,  0.0495,  0.0162,  ..., -0.0409,  0.0082,  0.0196],
        ...,
        [-0.0019, -0.0280, -0.0229,  ..., -0.0026,  0.0680, -0.0314],
        [ 0.0501,  0.0517, -0.0604,  ...,  0.0198, -0.0763, -0.0413],
        [ 0.0755, -0.0059,  0.0224,  ...,  0.0960, -0.0269,  0.0191]],
       requires_grad=True)

encoder.encoders.9.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0045,  0.0611, -0.0161,  ..., -0.0410,  0.0609,  0.0406],
        [ 0.0025,  0.0158,  0.0130,  ...,  0.0437, -0.0090, -0.0314],
        [-0.0133,  0.0503,  0.0067,  ...,  0.0524, -0.0555, -0.0044],
        ...,
        [-0.0417, -0.0135,  0.0146,  ..., -0.0005,  0.0123,  0.0334],
        [ 0.0406,  0.0403,  0.0115,  ...,  0.0016, -0.0348, -0.0362],
        [-0.0028, -0.0425, -0.0135,  ...,  0.0540, -0.0384, -0.0165]],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.7588, 0.7090, 0.6524,  ..., 0.8548, 0.7498, 0.7836],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0252, -0.0253, -0.2910,  ...,  0.0718,  0.0913, -0.0054],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8695, 0.8681, 0.7151,  ..., 0.8778, 0.8612, 0.8415],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0147, -0.0239, -0.0196,  ..., -0.0016,  0.0346, -0.0392],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5313, 0.4508, 0.4355,  ..., 0.4752, 0.4505, 0.4116],
       requires_grad=True)

encoder.encoders.9.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0128, -0.0301, -0.3042,  ...,  0.0405,  0.1126, -0.0422],
       requires_grad=True)

encoder.encoders.9.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0174, -0.0436, -0.0492,  ..., -0.0251, -0.0519,  0.0619],
        [-0.0312,  0.0215,  0.0161,  ..., -0.0319,  0.0225, -0.0259],
        [-0.0227,  0.0110,  0.0414,  ...,  0.0022, -0.0474,  0.0074],
        ...,
        [ 0.0099, -0.0240,  0.0072,  ...,  0.0453, -0.0076, -0.0198],
        [-0.0283, -0.0433, -0.0138,  ..., -0.0081,  0.0271,  0.0309],
        [-0.0170, -0.0417,  0.0019,  ..., -0.0239, -0.0103,  0.0272]],
       requires_grad=True)

encoder.encoders.9.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0752,  0.0017,  0.0270,  ...,  0.0141,  0.0395,  0.0235],
        [-0.1023,  0.1244, -0.1032,  ...,  0.0479,  0.0013,  0.0278],
        [ 0.0019,  0.0816,  0.0106,  ..., -0.0243, -0.0215, -0.0126],
        ...,
        [ 0.0387,  0.0035,  0.0094,  ..., -0.0188, -0.0254, -0.0353],
        [ 0.0247, -0.0251, -0.0448,  ..., -0.0022, -0.0074,  0.0020],
        [-0.1262, -0.1280, -0.0378,  ..., -0.0609, -0.0255, -0.0117]],
       requires_grad=True)

encoder.encoders.9.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.2819, 1.1154, 1.0225,  ..., 1.2839, 1.0827, 1.0473],
       requires_grad=True)

encoder.encoders.9.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0679,  0.0324, -0.0565,  ..., -0.0223, -0.0539,  0.0070],
       requires_grad=True)

encoder.encoders.9.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0060],
         [-0.0132],
         [-0.0068],
         ...,
         [-0.0075],
         [ 0.0394],
         [-0.0038]],

        [[-0.0277],
         [ 0.0138],
         [-0.0079],
         ...,
         [-0.0236],
         [-0.0195],
         [ 0.0442]],

        [[ 0.0005],
         [ 0.0348],
         [-0.0059],
         ...,
         [-0.0082],
         [-0.0719],
         [ 0.0547]],

        ...,

        [[ 0.0378],
         [ 0.0396],
         [ 0.0456],
         ...,
         [ 0.1513],
         [-0.0412],
         [-0.0164]],

        [[ 0.0090],
         [-0.0655],
         [-0.0632],
         ...,
         [ 0.0088],
         [-0.0202],
         [-0.0582]],

        [[ 0.0454],
         [-0.0261],
         [-0.0745],
         ...,
         [ 0.1104],
         [-0.0747],
         [ 0.0008]]], requires_grad=True)

encoder.encoders.9.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0169, -0.0022, -0.0040,  ...,  0.0147,  0.0024,  0.0318]],

        [[-0.0225, -0.0166, -0.0144,  ..., -0.0272,  0.0064, -0.0377]],

        [[-0.0310, -0.0051, -0.0278,  ..., -0.0190, -0.0088, -0.0417]],

        ...,

        [[-0.0242, -0.0122, -0.0289,  ..., -0.0085,  0.0040, -0.0091]],

        [[-0.0390, -0.0035, -0.0278,  ..., -0.0188,  0.0011, -0.0060]],

        [[-0.0398, -0.0101, -0.0085,  ...,  0.0245, -0.0397, -0.0179]]],
       requires_grad=True)

encoder.encoders.9.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0253, 1.0002, 1.0116,  ..., 0.9816, 1.0279, 1.0115],
       requires_grad=True)

encoder.encoders.9.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0728, -0.0174, -0.0440,  ..., -0.0335, -0.0343, -0.0755],
       requires_grad=True)

encoder.encoders.9.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[ 0.0802],
         [ 0.0168],
         [-0.0607],
         ...,
         [ 0.0334],
         [ 0.0383],
         [ 0.0422]],

        [[-0.0338],
         [ 0.0168],
         [-0.0384],
         ...,
         [ 0.0527],
         [ 0.0053],
         [ 0.0191]],

        [[ 0.0170],
         [ 0.0090],
         [-0.0852],
         ...,
         [-0.0157],
         [-0.0251],
         [-0.0257]],

        ...,

        [[-0.0859],
         [-0.0061],
         [ 0.0383],
         ...,
         [-0.0241],
         [ 0.0190],
         [ 0.1255]],

        [[-0.0508],
         [-0.0359],
         [ 0.0341],
         ...,
         [-0.0253],
         [-0.0867],
         [-0.0618]],

        [[ 0.0069],
         [ 0.0746],
         [-0.0236],
         ...,
         [-0.1057],
         [ 0.0356],
         [ 0.0480]]], requires_grad=True)

encoder.encoders.9.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.2731, 1.1004, 1.2174,  ..., 1.0444, 1.2335, 1.0153],
       requires_grad=True)

encoder.encoders.9.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.2665,  0.1487,  0.2769,  ..., -0.0319, -0.4689,  0.0500],
       requires_grad=True)

encoder.encoders.9.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0555, -0.0355,  0.0604,  ...,  0.0549, -0.0478, -0.0199],
        [ 0.0618,  0.0277, -0.1037,  ...,  0.0403,  0.0765, -0.0398],
        [ 0.0172,  0.1343, -0.0655,  ...,  0.0944,  0.0437,  0.0254],
        ...,
        [-0.0614, -0.0711, -0.0014,  ...,  0.0071,  0.0590,  0.0107],
        [-0.0156, -0.0413, -0.0317,  ..., -0.0105,  0.0138,  0.0547],
        [ 0.0780, -0.0121,  0.0341,  ...,  0.0365,  0.0239, -0.0272]],
       requires_grad=True)

encoder.encoders.9.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0051, -0.0176, -0.0258,  ..., -0.0396, -0.0126, -0.0129],
       requires_grad=True)

encoder.encoders.9.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0903,  0.0403, -0.0450,  ...,  0.0284, -0.0810,  0.0157],
        [-0.0369, -0.0420, -0.0517,  ...,  0.0280, -0.0170,  0.0088],
        [-0.0016, -0.0392,  0.0109,  ...,  0.0322, -0.0034,  0.0696],
        ...,
        [-0.0014,  0.0932,  0.0303,  ..., -0.0115, -0.0092, -0.0199],
        [ 0.0192, -0.0052,  0.0271,  ...,  0.0197, -0.0302, -0.0305],
        [-0.0261, -0.0026,  0.0097,  ..., -0.0804,  0.0152,  0.0650]],
       requires_grad=True)

encoder.encoders.9.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0552,  0.0182,  0.0592,  ..., -0.0122,  0.0025, -0.0024],
       requires_grad=True)

encoder.encoders.9.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.1863, 1.2252, 1.2391,  ..., 1.2174, 1.2759, 1.2431],
       requires_grad=True)

encoder.encoders.9.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.1577,  0.1011,  0.1743,  ..., -0.0040, -0.0966, -0.0452],
       requires_grad=True)

encoder.encoders.10.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.2288, 0.9722, 1.0906,  ..., 1.0215, 1.0140, 0.8663],
       requires_grad=True)

encoder.encoders.10.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.3225,  0.1140,  0.3233,  ..., -0.1698, -0.2433, -0.0813],
       requires_grad=True)

encoder.encoders.10.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0390, -0.0534,  0.0309,  ...,  0.0298,  0.0784,  0.0418],
        [ 0.0753,  0.0513, -0.0180,  ...,  0.0112, -0.0072, -0.0425],
        [-0.0601,  0.0233,  0.0262,  ..., -0.0090,  0.0799, -0.0439],
        ...,
        [ 0.0358, -0.0287, -0.0543,  ...,  0.0839,  0.0385, -0.0421],
        [ 0.0514,  0.0195,  0.0297,  ..., -0.0596, -0.0046, -0.0455],
        [-0.0132, -0.0904,  0.0184,  ...,  0.0934,  0.0619,  0.1101]],
       requires_grad=True)

encoder.encoders.10.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0512, -0.0209,  0.0006,  ..., -0.0269, -0.0371, -0.0016],
       requires_grad=True)

encoder.encoders.10.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0214,  0.0784,  0.0269,  ...,  0.0404,  0.0470,  0.0934],
        [-0.0270,  0.0214,  0.0211,  ...,  0.0160, -0.0100, -0.0075],
        [ 0.0603, -0.0035,  0.0410,  ...,  0.0075, -0.0180, -0.0169],
        ...,
        [ 0.0570,  0.0396,  0.0459,  ..., -0.0027, -0.0180, -0.0095],
        [ 0.0262,  0.0567,  0.0077,  ...,  0.0171, -0.0247,  0.0264],
        [-0.0051, -0.0033, -0.0084,  ..., -0.0139,  0.0193,  0.0055]],
       requires_grad=True)

encoder.encoders.10.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0304,  0.0344,  0.0589,  ...,  0.0227, -0.0254, -0.0213],
       requires_grad=True)

encoder.encoders.10.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.0451, -0.0841,  0.1533,  ...,  0.1209,  0.1396, -0.2546],
        [-0.1646,  0.2855, -0.2212,  ...,  0.0343, -0.0396, -0.0971],
        [-0.1073, -0.1808, -0.2573,  ..., -0.0877, -0.0630,  0.0411],
        ...,
        [-0.2286,  0.1131,  0.1212,  ..., -0.1943, -0.0921,  0.0730],
        [ 0.0709,  0.1718,  0.2786,  ..., -0.1484, -0.2108,  0.0683],
        [ 0.0655,  0.0299,  0.2925,  ..., -0.0902, -0.0491,  0.0778]],
       requires_grad=True)

encoder.encoders.10.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 2.3196e-04, -4.7444e-02,  7.9353e-03,  ..., -2.8626e-01,
          3.3940e-01,  1.7077e-01],
        [ 1.3339e-01,  1.2146e-01,  1.9339e-01,  ..., -1.8535e-01,
         -1.8620e-01, -3.3459e-02],
        [-1.2643e-01, -2.9321e-01,  2.4969e-01,  ...,  3.5625e-01,
         -1.9418e-01, -3.6147e-04],
        ...,
        [-2.2655e-01,  1.1806e-01, -1.5169e-01,  ..., -2.7812e-01,
          1.7286e-01,  9.9863e-02],
        [-1.1922e-01, -6.3926e-02,  9.4816e-03,  ..., -3.3968e-01,
          1.0202e-01, -2.7710e-02],
        [ 2.4564e-01,  2.2202e-01, -2.7181e-01,  ...,  2.0464e-01,
         -1.4221e-02, -2.6208e-02]], requires_grad=True)

encoder.encoders.10.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0067, -0.0154,  0.0242,  ..., -0.0191, -0.0583,  0.0370],
        [ 0.0125, -0.0500, -0.0025,  ..., -0.1299,  0.0155, -0.0335],
        [ 0.0561, -0.0727,  0.0170,  ...,  0.0667, -0.0387,  0.0190],
        ...,
        [-0.0156,  0.0134, -0.0575,  ..., -0.0431,  0.0016, -0.0548],
        [ 0.0552, -0.0498,  0.0341,  ...,  0.0233,  0.0551, -0.0118],
        [ 0.0675, -0.0598,  0.0316,  ...,  0.0366,  0.0629, -0.0463]],
       requires_grad=True)

encoder.encoders.10.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0264, -0.0063,  0.0107,  ..., -0.0280, -0.0186,  0.0628],
        [-0.0919, -0.0228, -0.0257,  ...,  0.0405,  0.0143,  0.0004],
        [-0.0897, -0.0462, -0.0720,  ..., -0.0524, -0.0485, -0.0106],
        ...,
        [-0.0203,  0.0116,  0.0606,  ...,  0.0872,  0.0218, -0.0322],
        [ 0.1091, -0.0483,  0.0747,  ...,  0.0417,  0.1045,  0.0692],
        [-0.0006,  0.0193, -0.0204,  ...,  0.0157,  0.1051, -0.0207]],
       requires_grad=True)

encoder.encoders.10.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0551, -0.0838, -0.0102,  ..., -0.0185, -0.0434,  0.0369],
        [-0.0080,  0.0052,  0.0360,  ..., -0.0463, -0.0394, -0.0319],
        [-0.0357,  0.0443,  0.0481,  ...,  0.0056, -0.0775,  0.0345],
        ...,
        [ 0.0175, -0.0110, -0.0263,  ...,  0.0264, -0.0216, -0.0355],
        [ 0.0167,  0.0317, -0.0056,  ...,  0.0627,  0.0250, -0.0183],
        [ 0.0132,  0.0448, -0.0450,  ...,  0.0375, -0.0504, -0.0356]],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.7613, 0.7487, 0.6955,  ..., 0.7960, 0.7861, 0.7629],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([ 0.0442, -0.1228, -0.1722,  ..., -0.0359,  0.0455, -0.0138],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8911, 0.8589, 0.8707,  ..., 0.8777, 0.8760, 0.8646],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0217, -0.0170,  0.0112,  ...,  0.0038, -0.0312, -0.0225],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.4894, 0.5050, 0.4500,  ..., 0.4930, 0.5219, 0.4873],
       requires_grad=True)

encoder.encoders.10.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0636, -0.0993, -0.1652,  ..., -0.0522,  0.0570, -0.0041],
       requires_grad=True)

encoder.encoders.10.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0022, -0.0085, -0.0364,  ...,  0.0480, -0.0577,  0.0302],
        [-0.0057,  0.0492, -0.0159,  ..., -0.0054, -0.0011, -0.0116],
        [ 0.0456, -0.0405, -0.0027,  ...,  0.0628,  0.0173, -0.0343],
        ...,
        [ 0.0986, -0.0079, -0.0316,  ...,  0.0476, -0.0497,  0.0237],
        [ 0.0970,  0.0407, -0.0618,  ..., -0.0543,  0.0193,  0.0325],
        [ 0.0403,  0.0594, -0.0755,  ..., -0.0280, -0.0040,  0.0095]],
       requires_grad=True)

encoder.encoders.10.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0105, -0.0720, -0.0228,  ..., -0.0054, -0.0025,  0.0603],
        [-0.0003, -0.0003,  0.0153,  ...,  0.0189, -0.0290,  0.0159],
        [ 0.0366, -0.0092,  0.0628,  ..., -0.0417,  0.0243,  0.0243],
        ...,
        [-0.0200,  0.0779, -0.0683,  ..., -0.0316, -0.0369,  0.0123],
        [-0.0737, -0.0844, -0.0886,  ...,  0.0059, -0.0616, -0.0410],
        [-0.0909, -0.1226, -0.0833,  ..., -0.0142, -0.0395,  0.0032]],
       requires_grad=True)

encoder.encoders.10.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.1906, 1.1425, 1.1164,  ..., 1.1797, 1.0836, 1.1597],
       requires_grad=True)

encoder.encoders.10.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0280,  0.0908,  0.0395,  ...,  0.1493,  0.0284, -0.0905],
       requires_grad=True)

encoder.encoders.10.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.0095],
         [ 0.0170],
         [-0.1020],
         ...,
         [ 0.0151],
         [ 0.0246],
         [-0.0190]],

        [[ 0.0724],
         [ 0.0642],
         [-0.0236],
         ...,
         [-0.0430],
         [-0.0506],
         [ 0.0091]],

        [[-0.0241],
         [-0.0046],
         [-0.0423],
         ...,
         [ 0.0603],
         [ 0.1083],
         [-0.0123]],

        ...,

        [[-0.0283],
         [-0.0532],
         [ 0.0434],
         ...,
         [ 0.0007],
         [-0.0298],
         [-0.0679]],

        [[-0.0241],
         [-0.0052],
         [-0.0315],
         ...,
         [ 0.0417],
         [-0.1020],
         [ 0.0015]],

        [[ 0.0442],
         [-0.0064],
         [ 0.0333],
         ...,
         [ 0.0997],
         [-0.0069],
         [ 0.0701]]], requires_grad=True)

encoder.encoders.10.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[ 0.0002, -0.0222,  0.0147,  ...,  0.0075, -0.0253, -0.0047]],

        [[ 0.0242, -0.0114,  0.0141,  ..., -0.0139, -0.0063,  0.0027]],

        [[ 0.0097,  0.0137, -0.0004,  ..., -0.0041,  0.0183,  0.0123]],

        ...,

        [[ 0.0103,  0.0018, -0.0149,  ..., -0.0029, -0.0042,  0.0085]],

        [[-0.0036,  0.0074, -0.0031,  ..., -0.0034,  0.0012, -0.0258]],

        [[ 0.0020,  0.0015, -0.0131,  ...,  0.0070, -0.0132, -0.0283]]],
       requires_grad=True)

encoder.encoders.10.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0283, 1.0257, 1.0639,  ..., 1.0438, 1.0546, 1.0731],
       requires_grad=True)

encoder.encoders.10.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([ 0.0330,  0.0158, -0.0173,  ..., -0.0215, -0.0645, -0.0517],
       requires_grad=True)

encoder.encoders.10.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0269],
         [-0.1120],
         [-0.0007],
         ...,
         [ 0.0401],
         [ 0.0280],
         [-0.0165]],

        [[-0.0654],
         [ 0.0687],
         [-0.0320],
         ...,
         [-0.0347],
         [-0.0054],
         [ 0.0048]],

        [[ 0.0977],
         [ 0.0032],
         [ 0.0491],
         ...,
         [-0.0233],
         [ 0.0188],
         [ 0.0334]],

        ...,

        [[-0.0022],
         [ 0.0379],
         [-0.0639],
         ...,
         [-0.0642],
         [-0.0618],
         [ 0.0752]],

        [[ 0.0026],
         [-0.0014],
         [ 0.0052],
         ...,
         [ 0.0058],
         [-0.0873],
         [-0.1144]],

        [[-0.0085],
         [ 0.0489],
         [ 0.0179],
         ...,
         [-0.0173],
         [-0.0253],
         [-0.0436]]], requires_grad=True)

encoder.encoders.10.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.3247, 1.2436, 1.2805,  ..., 1.2321, 1.1391, 1.1031],
       requires_grad=True)

encoder.encoders.10.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.2698,  0.2331,  0.4035,  ...,  0.3023, -0.2206, -0.1166],
       requires_grad=True)

encoder.encoders.10.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0403,  0.0606, -0.0222,  ..., -0.0563,  0.0161,  0.0177],
        [ 0.0051,  0.0224,  0.0152,  ..., -0.0198,  0.0863,  0.0213],
        [ 0.0461, -0.0318,  0.0073,  ...,  0.0125, -0.0245, -0.0470],
        ...,
        [ 0.0327, -0.0023, -0.0586,  ..., -0.0491, -0.0128, -0.0357],
        [-0.0064, -0.0110, -0.0921,  ..., -0.0744,  0.0172, -0.0288],
        [ 0.0056,  0.0249,  0.0565,  ..., -0.0801, -0.0302,  0.0593]],
       requires_grad=True)

encoder.encoders.10.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0001,  0.0240, -0.0314,  ...,  0.0049, -0.0166, -0.0395],
       requires_grad=True)

encoder.encoders.10.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0312, -0.0785,  0.0284,  ..., -0.0264, -0.0078, -0.0377],
        [-0.0037, -0.0325,  0.0144,  ...,  0.0544, -0.0131, -0.0058],
        [-0.0378,  0.0499, -0.0242,  ..., -0.0113,  0.0038,  0.0176],
        ...,
        [ 0.1034,  0.0490, -0.0238,  ...,  0.0463, -0.0210,  0.0283],
        [-0.0071, -0.0868,  0.0018,  ..., -0.0443,  0.1539,  0.0077],
        [-0.0504, -0.0185, -0.0457,  ..., -0.0099, -0.1475,  0.0126]],
       requires_grad=True)

encoder.encoders.10.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0332,  0.0089, -0.0051,  ..., -0.0181, -0.0175,  0.0067],
       requires_grad=True)

encoder.encoders.10.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2410, 1.2960, 1.3266,  ..., 1.2903, 1.2694, 1.2971],
       requires_grad=True)

encoder.encoders.10.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.1118,  0.1615,  0.0777,  ...,  0.0703, -0.0427, -0.0166],
       requires_grad=True)

encoder.encoders.11.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.1768, 1.2162, 0.9682,  ..., 1.1199, 1.0232, 0.9553],
       requires_grad=True)

encoder.encoders.11.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.2837,  0.4813,  0.1566,  ...,  0.2918, -0.1989, -0.0901],
       requires_grad=True)

encoder.encoders.11.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0530, -0.0239, -0.0296,  ..., -0.0067,  0.0217, -0.0145],
        [-0.0440, -0.0101,  0.0294,  ..., -0.0557,  0.0460, -0.0808],
        [ 0.0716, -0.0591, -0.0112,  ..., -0.0615,  0.0335,  0.0650],
        ...,
        [-0.0029, -0.0989,  0.0271,  ...,  0.0655, -0.0405,  0.0409],
        [ 0.0339, -0.0020,  0.0435,  ..., -0.0342,  0.0526,  0.0176],
        [ 0.0295,  0.0224,  0.0337,  ..., -0.0091, -0.0365,  0.0652]],
       requires_grad=True)

encoder.encoders.11.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0530,  0.0102, -0.0070,  ..., -0.0305, -0.0212, -0.0378],
       requires_grad=True)

encoder.encoders.11.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0659, -0.0648, -0.1122,  ..., -0.0158,  0.0313, -0.0309],
        [ 0.0188,  0.0148,  0.0354,  ..., -0.0234,  0.0535,  0.0149],
        [ 0.0073,  0.0612,  0.0098,  ..., -0.0245, -0.0013, -0.0416],
        ...,
        [-0.0305,  0.0151,  0.0258,  ..., -0.0278, -0.0285, -0.0016],
        [ 0.0472, -0.0385, -0.0858,  ...,  0.0105,  0.0037,  0.0026],
        [-0.0039, -0.0320,  0.0568,  ...,  0.0560, -0.0317,  0.0753]],
       requires_grad=True)

encoder.encoders.11.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0476, -0.0097,  0.0163,  ..., -0.0181, -0.0206, -0.0022],
       requires_grad=True)

encoder.encoders.11.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 5.3027e-03, -1.7507e-01, -1.4948e-01,  ...,  4.2053e-02,
          1.7534e-01, -5.5207e-02],
        [ 1.7834e-01, -1.5694e-01, -1.0236e-01,  ..., -9.1147e-02,
          2.0463e-01,  3.3022e-01],
        [-5.5642e-02, -6.9605e-02,  2.6039e-01,  ..., -1.0457e-04,
          9.3818e-02,  2.8685e-01],
        ...,
        [-8.9862e-02,  2.1495e-01,  1.4706e-01,  ...,  1.3606e-01,
          1.8333e-01, -2.1516e-01],
        [ 8.8410e-02, -1.7785e-02, -4.3972e-02,  ..., -2.9867e-01,
         -1.9636e-01,  4.8122e-02],
        [-5.2172e-02, -1.0778e-01,  2.9408e-01,  ...,  2.1760e-01,
          4.2247e-01, -2.0095e-01]], requires_grad=True)

encoder.encoders.11.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.0946,  0.1601,  0.0759,  ..., -0.1782,  0.0755, -0.1792],
        [-0.2153, -0.0107,  0.0752,  ..., -0.2984, -0.2062, -0.0039],
        [ 0.0224,  0.2413, -0.2397,  ..., -0.0415, -0.1730, -0.0275],
        ...,
        [ 0.1684,  0.1158,  0.1098,  ...,  0.0294, -0.3486, -0.2614],
        [-0.0021,  0.2480, -0.2438,  ...,  0.1604, -0.2291, -0.1291],
        [ 0.0783, -0.4011, -0.3781,  ...,  0.1261, -0.0988,  0.2317]],
       requires_grad=True)

encoder.encoders.11.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0547, -0.0596,  0.0490,  ..., -0.0267,  0.0117,  0.0760],
        [-0.0297, -0.0234,  0.0756,  ..., -0.0328,  0.0219,  0.0946],
        [-0.0208,  0.0098,  0.0455,  ..., -0.0093, -0.0307,  0.0329],
        ...,
        [-0.0042,  0.0060,  0.0099,  ...,  0.0415,  0.0569, -0.0917],
        [ 0.0110, -0.1158, -0.0868,  ...,  0.0208,  0.1101, -0.0409],
        [ 0.0041, -0.0799,  0.0586,  ..., -0.0204, -0.0539,  0.0038]],
       requires_grad=True)

encoder.encoders.11.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0105, -0.0669, -0.0154,  ..., -0.0193,  0.0250,  0.0105],
        [-0.0059,  0.0259, -0.0441,  ...,  0.0344,  0.0040,  0.0268],
        [-0.0751,  0.0144, -0.0553,  ...,  0.0100,  0.0149,  0.0074],
        ...,
        [-0.0893,  0.0127, -0.0592,  ..., -0.0386, -0.0122,  0.0126],
        [-0.0210, -0.0485, -0.0558,  ...,  0.0113,  0.0396, -0.0469],
        [ 0.0577, -0.0291, -0.0025,  ..., -0.0283,  0.0227, -0.0689]],
       requires_grad=True)

encoder.encoders.11.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0372, -0.0061, -0.0442,  ..., -0.1004,  0.0406,  0.0402],
        [-0.0955, -0.0246, -0.0658,  ...,  0.0003,  0.0050, -0.1108],
        [-0.0599, -0.0236, -0.0361,  ...,  0.0241, -0.0118,  0.0197],
        ...,
        [-0.0244,  0.0067,  0.0002,  ...,  0.0002, -0.0049,  0.0109],
        [-0.0163,  0.0343,  0.0055,  ...,  0.0374, -0.0454, -0.0076],
        [ 0.0198,  0.0558,  0.0040,  ...,  0.0527, -0.0372,  0.0265]],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.9243, 0.8222, 0.8364,  ..., 0.8823, 0.8656, 0.8615],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0017, -0.1146, -0.0802,  ..., -0.0173, -0.0339, -0.0354],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([1.0063, 0.9710, 0.8242,  ..., 0.9063, 0.9117, 0.9559],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0045, -0.0224, -0.0215,  ..., -0.0009,  0.0173,  0.0038],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.4155, 0.4965, 0.4504,  ..., 0.4528, 0.4850, 0.4776],
       requires_grad=True)

encoder.encoders.11.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0409, -0.1396, -0.1262,  ..., -0.0537, -0.0010, -0.0318],
       requires_grad=True)

encoder.encoders.11.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0428,  0.0204,  0.0625,  ...,  0.0005,  0.0500,  0.0163],
        [ 0.0559,  0.0297, -0.0960,  ..., -0.0235,  0.0171,  0.0323],
        [-0.0030,  0.0125, -0.0592,  ..., -0.0355, -0.0151,  0.0481],
        ...,
        [ 0.0538, -0.0289, -0.0086,  ...,  0.0042,  0.0262, -0.0319],
        [-0.0519, -0.0026,  0.0736,  ..., -0.0182,  0.0084, -0.0453],
        [-0.0582,  0.0677, -0.0331,  ...,  0.0136,  0.0285, -0.0166]],
       requires_grad=True)

encoder.encoders.11.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0307,  0.0411, -0.0554,  ...,  0.0299, -0.0162,  0.0177],
        [ 0.0206,  0.0337, -0.0314,  ..., -0.0009, -0.0256, -0.0397],
        [-0.0191, -0.0098, -0.0450,  ...,  0.0200, -0.0270, -0.0197],
        ...,
        [ 0.0163, -0.0203, -0.0285,  ...,  0.0329, -0.0039, -0.0059],
        [-0.0448, -0.2872, -0.0270,  ..., -0.0075,  0.0330,  0.0070],
        [ 0.0463,  0.1307,  0.0310,  ..., -0.0660,  0.0054,  0.0958]],
       requires_grad=True)

encoder.encoders.11.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.1797, 1.1582, 1.1549,  ..., 1.2483, 1.1553, 1.1005],
       requires_grad=True)

encoder.encoders.11.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0419,  0.0364, -0.0105,  ..., -0.0960,  0.0921, -0.0744],
       requires_grad=True)

encoder.encoders.11.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.1269],
         [-0.0224],
         [-0.0020],
         ...,
         [-0.0201],
         [ 0.1750],
         [ 0.0385]],

        [[ 0.0354],
         [ 0.0070],
         [-0.0014],
         ...,
         [ 0.0073],
         [ 0.0062],
         [ 0.0058]],

        [[ 0.0165],
         [ 0.0432],
         [-0.0379],
         ...,
         [-0.0665],
         [-0.0219],
         [ 0.0671]],

        ...,

        [[-0.0334],
         [ 0.0412],
         [-0.0427],
         ...,
         [ 0.0454],
         [ 0.0760],
         [-0.0252]],

        [[-0.0854],
         [-0.0636],
         [ 0.0290],
         ...,
         [-0.0300],
         [-0.0585],
         [ 0.0261]],

        [[-0.1069],
         [ 0.0467],
         [ 0.0155],
         ...,
         [-0.0100],
         [ 0.0220],
         [-0.0117]]], requires_grad=True)

encoder.encoders.11.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0063, -0.0015, -0.0206,  ..., -0.0025,  0.0008, -0.0454]],

        [[ 0.0502,  0.0342,  0.0341,  ..., -0.0705, -0.0616, -0.1067]],

        [[ 0.0035,  0.0213, -0.0086,  ..., -0.0391, -0.0314, -0.0621]],

        ...,

        [[-0.0168, -0.0167, -0.0070,  ...,  0.0061,  0.0184,  0.0371]],

        [[-0.0405, -0.0511, -0.0395,  ..., -0.0106, -0.0010,  0.0196]],

        [[ 0.0393,  0.0087,  0.0275,  ...,  0.0348,  0.0172,  0.0466]]],
       requires_grad=True)

encoder.encoders.11.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0240, 1.0226, 1.0253,  ..., 1.0354, 1.0391, 1.0070],
       requires_grad=True)

encoder.encoders.11.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0567, -0.0250, -0.0409,  ..., -0.0394, -0.0662, -0.0614],
       requires_grad=True)

encoder.encoders.11.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0485],
         [-0.0275],
         [ 0.0500],
         ...,
         [-0.0239],
         [-0.0162],
         [-0.0613]],

        [[-0.0062],
         [ 0.0199],
         [ 0.0076],
         ...,
         [ 0.0079],
         [ 0.0091],
         [-0.0669]],

        [[-0.0017],
         [ 0.0197],
         [-0.0547],
         ...,
         [-0.0146],
         [-0.0330],
         [-0.0643]],

        ...,

        [[-0.0050],
         [-0.0094],
         [ 0.0313],
         ...,
         [ 0.0806],
         [-0.0972],
         [-0.0344]],

        [[-0.0006],
         [ 0.0184],
         [-0.0546],
         ...,
         [-0.0044],
         [-0.0200],
         [ 0.0393]],

        [[-0.0360],
         [-0.0270],
         [-0.0499],
         ...,
         [ 0.0560],
         [-0.0734],
         [ 0.0114]]], requires_grad=True)

encoder.encoders.11.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.2195, 1.1631, 1.2035,  ..., 1.0475, 1.0909, 1.0317],
       requires_grad=True)

encoder.encoders.11.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.2012,  0.2619,  0.3522,  ..., -0.1486,  0.0673,  0.0282],
       requires_grad=True)

encoder.encoders.11.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0632,  0.0920,  0.0264,  ..., -0.0334, -0.0868,  0.0494],
        [-0.0857,  0.0852,  0.0639,  ...,  0.0360, -0.0783,  0.0477],
        [-0.0606, -0.0114, -0.0085,  ..., -0.0126,  0.0227,  0.0316],
        ...,
        [ 0.0047, -0.0530, -0.0052,  ..., -0.0553, -0.0269,  0.0748],
        [-0.0919,  0.0152,  0.0414,  ...,  0.0210, -0.0479,  0.0300],
        [-0.0083, -0.0162,  0.0667,  ...,  0.0405,  0.0120, -0.0287]],
       requires_grad=True)

encoder.encoders.11.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0070, -0.0354, -0.0009,  ...,  0.0224, -0.0013, -0.0003],
       requires_grad=True)

encoder.encoders.11.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0576, -0.0446, -0.0927,  ..., -0.0643, -0.0125,  0.0035],
        [-0.0157,  0.0181,  0.0218,  ...,  0.0935, -0.0279,  0.1146],
        [-0.0101, -0.0006, -0.0092,  ...,  0.0352,  0.0700, -0.0635],
        ...,
        [-0.0894,  0.0333, -0.0275,  ..., -0.0018,  0.0405, -0.0613],
        [ 0.0659, -0.0002,  0.0986,  ...,  0.0090, -0.0130, -0.0206],
        [-0.0435, -0.1017,  0.0139,  ...,  0.0060,  0.0308, -0.0069]],
       requires_grad=True)

encoder.encoders.11.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0239, -0.0056, -0.0263,  ..., -0.0284, -0.0014,  0.0026],
       requires_grad=True)

encoder.encoders.11.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.2256, 1.3242, 1.3748,  ..., 1.2739, 1.2667, 1.3294],
       requires_grad=True)

encoder.encoders.11.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.1079,  0.0501,  0.0607,  ..., -0.0183,  0.0152,  0.0356],
       requires_grad=True)

encoder.encoders.12.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.0914, 1.0331, 0.9024,  ..., 0.9543, 0.9731, 0.9241],
       requires_grad=True)

encoder.encoders.12.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.2501,  0.1491,  0.0980,  ..., -0.2258,  0.0920,  0.1474],
       requires_grad=True)

encoder.encoders.12.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0327,  0.0430, -0.0112,  ...,  0.0224,  0.0306, -0.0055],
        [ 0.0991, -0.0025, -0.0616,  ...,  0.0724,  0.0799, -0.0951],
        [-0.0061,  0.0007,  0.0419,  ..., -0.0535,  0.0238, -0.0095],
        ...,
        [ 0.0686,  0.0015,  0.0050,  ...,  0.0094,  0.0384, -0.0152],
        [-0.0290, -0.0326, -0.0803,  ..., -0.0193,  0.0607, -0.0401],
        [ 0.0329,  0.0213, -0.0119,  ..., -0.0178,  0.0218, -0.0782]],
       requires_grad=True)

encoder.encoders.12.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0121, -0.0362,  0.0073,  ..., -0.0482, -0.0487,  0.0009],
       requires_grad=True)

encoder.encoders.12.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0275,  0.0267, -0.0438,  ..., -0.0118, -0.0394, -0.0531],
        [-0.0077,  0.0022,  0.0359,  ...,  0.0385, -0.0326,  0.0103],
        [ 0.0062,  0.0135, -0.0095,  ..., -0.0405, -0.0511,  0.0483],
        ...,
        [ 0.0029,  0.0420, -0.0073,  ..., -0.0171,  0.0796, -0.0320],
        [ 0.0010,  0.0180, -0.0570,  ...,  0.0490,  0.0662, -0.0640],
        [ 0.0008, -0.0439, -0.0189,  ..., -0.0871, -0.0048, -0.0386]],
       requires_grad=True)

encoder.encoders.12.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0426,  0.0092,  0.0374,  ...,  0.0129,  0.0203, -0.0071],
       requires_grad=True)

encoder.encoders.12.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.0802,  0.0692,  0.2054,  ...,  0.2116, -0.3946, -0.3337],
        [ 0.1129, -0.1937, -0.0988,  ...,  0.0534, -0.0175,  0.3229],
        [-0.1072, -0.2158, -0.2111,  ...,  0.2249,  0.0510, -0.0157],
        ...,
        [ 0.0489,  0.0427,  0.2333,  ..., -0.0645,  0.0025, -0.2285],
        [-0.1250, -0.2239, -0.2227,  ..., -0.2326,  0.0127,  0.1158],
        [ 0.1913, -0.2420, -0.3757,  ..., -0.1067,  0.1042,  0.0652]],
       requires_grad=True)

encoder.encoders.12.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.1468, -0.2969, -0.1696,  ..., -0.1844,  0.4958, -0.0459],
        [ 0.0699, -0.2560,  0.0601,  ...,  0.0997, -0.2079,  0.1098],
        [ 0.1945,  0.3556,  0.3665,  ...,  0.0127, -0.2122,  0.1934],
        ...,
        [ 0.0839,  0.1697, -0.4067,  ...,  0.3571,  0.2058,  0.1759],
        [-0.1453, -0.0509, -0.0578,  ...,  0.0067,  0.0082, -0.0957],
        [-0.1056,  0.4474,  0.4407,  ...,  0.1696, -0.1699,  0.0307]],
       requires_grad=True)

encoder.encoders.12.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 7.6243e-02, -4.8817e-02,  2.6692e-02,  ...,  7.5084e-02,
          5.8172e-02, -3.3152e-02],
        [ 4.3128e-02, -2.4666e-02,  3.3488e-04,  ...,  2.9929e-02,
          2.8263e-02,  3.7203e-03],
        [ 6.8008e-02, -5.1544e-02,  8.2867e-02,  ...,  3.3396e-02,
          7.4457e-02, -4.8800e-02],
        ...,
        [-7.9163e-02,  2.1211e-02, -1.9062e-02,  ..., -1.3504e-01,
          2.3023e-02, -1.6076e-02],
        [ 1.8215e-05, -7.1969e-03,  1.1984e-02,  ..., -3.0973e-02,
          6.1067e-02,  8.4545e-02],
        [ 4.8408e-05,  3.2424e-02, -5.3722e-02,  ...,  4.3791e-02,
         -5.5985e-02,  3.8780e-02]], requires_grad=True)

encoder.encoders.12.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0382,  0.0101,  0.0020,  ...,  0.0352, -0.0104,  0.0403],
        [-0.0506,  0.0128,  0.0628,  ..., -0.0033,  0.0430, -0.0708],
        [ 0.0481,  0.0072,  0.0237,  ...,  0.0550, -0.0094,  0.0010],
        ...,
        [ 0.0303, -0.0866,  0.0257,  ..., -0.0286,  0.0482,  0.0275],
        [ 0.0283,  0.0758,  0.0059,  ..., -0.0183,  0.0407, -0.0201],
        [-0.0165, -0.0032,  0.0096,  ..., -0.0156, -0.0212,  0.0390]],
       requires_grad=True)

encoder.encoders.12.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0118, -0.0222, -0.0324,  ..., -0.0004, -0.0199,  0.0320],
        [ 0.0522,  0.0618, -0.0263,  ..., -0.0216, -0.1002, -0.0564],
        [-0.0047,  0.0027,  0.0386,  ..., -0.0372,  0.0620, -0.0208],
        ...,
        [ 0.0263,  0.0011, -0.0303,  ...,  0.0517,  0.0676,  0.0264],
        [-0.0424,  0.0274, -0.0062,  ...,  0.0071, -0.0736, -0.0479],
        [-0.0372, -0.0024,  0.0312,  ..., -0.0378,  0.0377,  0.0112]],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.8695, 0.7625, 0.7987,  ..., 0.7675, 0.8065, 0.7598],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0134, -0.0611, -0.0633,  ..., -0.0404, -0.0358, -0.0551],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8718, 0.8499, 0.8109,  ..., 0.9015, 0.8644, 0.8302],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0110, -0.0003, -0.0046,  ..., -0.0058,  0.0122, -0.0069],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5162, 0.5458, 0.5319,  ..., 0.5574, 0.5714, 0.5502],
       requires_grad=True)

encoder.encoders.12.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0452, -0.0802, -0.1147,  ..., -0.0529, -0.0353, -0.0526],
       requires_grad=True)

encoder.encoders.12.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0662, -0.0488, -0.0152,  ...,  0.0172,  0.0127, -0.0438],
        [ 0.0096,  0.0182, -0.0132,  ...,  0.0189,  0.0128, -0.0086],
        [ 0.0629, -0.0628,  0.0134,  ...,  0.0177, -0.0337,  0.0235],
        ...,
        [-0.0132,  0.0020, -0.0297,  ...,  0.0030, -0.0296, -0.0693],
        [-0.0131,  0.0346, -0.1088,  ..., -0.0241, -0.0435,  0.0017],
        [ 0.0111, -0.0314,  0.0635,  ...,  0.0192,  0.0032, -0.0281]],
       requires_grad=True)

encoder.encoders.12.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0583, -0.1464,  0.0409,  ..., -0.0411, -0.0083, -0.0758],
        [ 0.0894, -0.0944,  0.0792,  ..., -0.0492,  0.0031, -0.0918],
        [ 0.0544, -0.0721, -0.0480,  ..., -0.0079, -0.0341,  0.0175],
        ...,
        [ 0.0116,  0.2302, -0.0618,  ...,  0.0023,  0.0401, -0.0284],
        [ 0.0377, -0.3094,  0.0435,  ..., -0.0163,  0.0498, -0.0139],
        [ 0.0450,  0.3294, -0.0287,  ..., -0.0426,  0.0275, -0.0215]],
       requires_grad=True)

encoder.encoders.12.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.1510, 1.1311, 1.0025,  ..., 1.1675, 1.2116, 1.0882],
       requires_grad=True)

encoder.encoders.12.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([ 0.0064, -0.0298,  0.0520,  ...,  0.0148,  0.0331, -0.1210],
       requires_grad=True)

encoder.encoders.12.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.0710],
         [-0.0294],
         [-0.0170],
         ...,
         [ 0.0019],
         [ 0.0840],
         [-0.0258]],

        [[ 0.0163],
         [-0.0662],
         [ 0.0306],
         ...,
         [ 0.0245],
         [-0.0687],
         [ 0.0081]],

        [[ 0.0027],
         [ 0.0101],
         [-0.0172],
         ...,
         [ 0.0211],
         [ 0.0603],
         [-0.0005]],

        ...,

        [[ 0.0627],
         [ 0.0808],
         [ 0.0550],
         ...,
         [-0.0065],
         [ 0.0507],
         [-0.0365]],

        [[-0.0351],
         [ 0.1149],
         [ 0.0839],
         ...,
         [ 0.0808],
         [-0.0005],
         [-0.0255]],

        [[ 0.0202],
         [-0.0023],
         [-0.0422],
         ...,
         [ 0.0726],
         [-0.1007],
         [-0.0412]]], requires_grad=True)

encoder.encoders.12.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0477, -0.0071, -0.0147,  ..., -0.0193, -0.0262, -0.0632]],

        [[-0.0124, -0.0005, -0.0021,  ...,  0.0054, -0.0010, -0.0136]],

        [[-0.0187, -0.0159, -0.0026,  ..., -0.0294, -0.0219, -0.0305]],

        ...,

        [[ 0.0312, -0.0075, -0.0167,  ..., -0.0042, -0.0110, -0.0378]],

        [[ 0.0102,  0.0064,  0.0066,  ..., -0.0308,  0.0058, -0.0817]],

        [[ 0.0066,  0.0117,  0.0213,  ..., -0.0095, -0.0100, -0.0385]]],
       requires_grad=True)

encoder.encoders.12.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0009, 1.0332, 1.0786,  ..., 1.0221, 1.0318, 1.0514],
       requires_grad=True)

encoder.encoders.12.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0685, -0.0481, -0.0344,  ..., -0.0660, -0.1002, -0.0505],
       requires_grad=True)

encoder.encoders.12.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0435],
         [ 0.0006],
         [ 0.0750],
         ...,
         [-0.1161],
         [-0.0759],
         [-0.0797]],

        [[-0.0094],
         [ 0.0072],
         [ 0.0397],
         ...,
         [ 0.0164],
         [ 0.0169],
         [-0.0762]],

        [[-0.0749],
         [ 0.0128],
         [ 0.0059],
         ...,
         [-0.0504],
         [ 0.0317],
         [-0.0359]],

        ...,

        [[ 0.0403],
         [-0.0257],
         [ 0.0499],
         ...,
         [-0.0465],
         [ 0.0176],
         [-0.0357]],

        [[ 0.0064],
         [ 0.0016],
         [-0.0192],
         ...,
         [-0.0469],
         [ 0.0028],
         [ 0.0163]],

        [[ 0.0777],
         [-0.0386],
         [ 0.0673],
         ...,
         [ 0.0142],
         [ 0.0611],
         [-0.0250]]], requires_grad=True)

encoder.encoders.12.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.0582, 1.0065, 0.9776,  ..., 1.1329, 1.0781, 1.0318],
       requires_grad=True)

encoder.encoders.12.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.1780,  0.0386,  0.1750,  ...,  0.2301,  0.0054,  0.2302],
       requires_grad=True)

encoder.encoders.12.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 3.5901e-02,  4.5855e-02,  1.5316e-02,  ...,  6.2524e-02,
         -1.2672e-02, -4.2123e-02],
        [-6.7794e-02, -3.3353e-02,  2.7967e-05,  ...,  3.9372e-02,
         -5.8239e-02,  5.4850e-02],
        [ 1.1218e-03, -3.6728e-02,  4.8152e-02,  ...,  6.4937e-02,
          7.4288e-02,  7.0959e-03],
        ...,
        [ 7.3811e-02,  5.6182e-03,  3.8436e-02,  ...,  5.6175e-02,
         -9.1392e-03, -7.7480e-02],
        [ 4.1943e-02,  3.4807e-02, -4.9710e-02,  ..., -3.8068e-02,
          3.3514e-02, -6.9210e-02],
        [ 1.2841e-02, -2.5337e-02, -1.3042e-02,  ...,  6.5232e-02,
         -1.6589e-02,  2.9233e-02]], requires_grad=True)

encoder.encoders.12.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0118,  0.0069,  0.0055,  ..., -0.0027, -0.0187, -0.0239],
       requires_grad=True)

encoder.encoders.12.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0134,  0.0225,  0.0735,  ...,  0.0409,  0.0093,  0.0471],
        [ 0.1254, -0.0273,  0.0082,  ...,  0.0020,  0.0179,  0.0051],
        [ 0.0088,  0.1115, -0.0762,  ..., -0.0516,  0.0015,  0.0748],
        ...,
        [-0.0464, -0.0087,  0.0288,  ...,  0.0757, -0.0165,  0.0206],
        [-0.0418,  0.0358, -0.0446,  ...,  0.0172,  0.0072,  0.0544],
        [-0.0143, -0.0478, -0.0384,  ..., -0.0623, -0.0565, -0.0244]],
       requires_grad=True)

encoder.encoders.12.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([ 0.0011, -0.0075, -0.0053,  ...,  0.0313,  0.0133,  0.0102],
       requires_grad=True)

encoder.encoders.12.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3146, 1.4014, 1.4733,  ..., 1.2979, 1.2895, 1.3557],
       requires_grad=True)

encoder.encoders.12.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.0886,  0.0096,  0.0816,  ...,  0.1468, -0.0323,  0.0633],
       requires_grad=True)

encoder.encoders.13.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([0.9267, 0.8806, 0.7852,  ..., 1.0289, 0.9407, 0.9483],
       requires_grad=True)

encoder.encoders.13.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([ 0.0068, -0.0265,  0.1536,  ...,  0.3101,  0.0364,  0.2533],
       requires_grad=True)

encoder.encoders.13.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0226,  0.0449,  0.0289,  ..., -0.0128, -0.0090,  0.0832],
        [ 0.0453,  0.0080,  0.0658,  ..., -0.0161,  0.0105, -0.0026],
        [-0.0632, -0.0958, -0.0050,  ..., -0.0038, -0.0005, -0.0116],
        ...,
        [-0.0373,  0.0941,  0.0331,  ..., -0.1481, -0.0302, -0.0635],
        [ 0.0801, -0.0693,  0.0494,  ..., -0.0818, -0.0251,  0.0373],
        [ 0.0299, -0.0180, -0.0077,  ...,  0.0233, -0.0102, -0.0157]],
       requires_grad=True)

encoder.encoders.13.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0249, -0.0149, -0.0221,  ..., -0.0373, -0.0321, -0.0326],
       requires_grad=True)

encoder.encoders.13.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0003,  0.0514, -0.0030,  ..., -0.0519,  0.0457, -0.1011],
        [ 0.0637, -0.0506, -0.1318,  ...,  0.0557,  0.0250, -0.0730],
        [-0.1033,  0.0111,  0.0102,  ..., -0.0176, -0.0674, -0.0355],
        ...,
        [ 0.0329,  0.0746,  0.0563,  ..., -0.0345, -0.0179, -0.0231],
        [ 0.0111,  0.0263,  0.0224,  ...,  0.0099,  0.0202, -0.0113],
        [ 0.1053, -0.0627,  0.0745,  ..., -0.0198,  0.0510,  0.0900]],
       requires_grad=True)

encoder.encoders.13.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0530,  0.0061,  0.0015,  ...,  0.0492, -0.0390, -0.0170],
       requires_grad=True)

encoder.encoders.13.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 3.5103e-01, -1.9401e-01, -2.3225e-01,  ...,  5.4396e-02,
          5.7708e-02,  2.4428e-01],
        [ 7.4495e-03,  8.8894e-02, -1.0643e-01,  ..., -7.3466e-02,
         -5.3155e-02, -6.1503e-02],
        [-3.4695e-01, -6.1503e-02,  3.4965e-01,  ...,  1.9633e-01,
         -8.8438e-02,  1.9019e-01],
        ...,
        [-7.4795e-02, -2.0808e-01,  2.7484e-01,  ..., -1.6671e-01,
          1.7007e-01,  1.6637e-01],
        [-2.5505e-02,  3.1732e-02,  1.5111e-01,  ..., -2.4717e-01,
          1.0237e-01,  6.7842e-03],
        [-3.2596e-01, -2.7741e-01,  2.6494e-05,  ...,  2.8740e-01,
          1.6925e-01, -2.7460e-01]], requires_grad=True)

encoder.encoders.13.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[ 0.1111,  0.1870,  0.0156,  ..., -0.1340, -0.1902, -0.2029],
        [-0.0119,  0.0881,  0.0249,  ...,  0.4007, -0.0174, -0.0167],
        [ 0.3667, -0.1805, -0.0336,  ..., -0.3332,  0.3529, -0.1219],
        ...,
        [-0.1821,  0.1491,  0.0209,  ..., -0.2720,  0.2655,  0.3101],
        [ 0.2130,  0.0504,  0.0982,  ..., -0.0284, -0.1180,  0.2160],
        [-0.0810,  0.3582, -0.3268,  ..., -0.0938, -0.2853,  0.4437]],
       requires_grad=True)

encoder.encoders.13.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0281, -0.0413,  0.0550,  ...,  0.0549,  0.0171,  0.0427],
        [ 0.0842,  0.0383,  0.0017,  ...,  0.0530,  0.0160,  0.0235],
        [-0.0851, -0.0269, -0.0180,  ...,  0.0227, -0.0239, -0.0767],
        ...,
        [ 0.0638, -0.0479,  0.0097,  ...,  0.0093,  0.0200, -0.0138],
        [ 0.0251, -0.0332, -0.0297,  ..., -0.0959,  0.0333, -0.1116],
        [-0.0043,  0.0388, -0.0522,  ...,  0.0160, -0.0931,  0.0749]],
       requires_grad=True)

encoder.encoders.13.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0684, -0.0005, -0.0050,  ..., -0.0152,  0.0215,  0.0249],
        [-0.0053,  0.0119, -0.0855,  ..., -0.0358,  0.0052, -0.0246],
        [-0.0445,  0.0601,  0.0213,  ..., -0.0040,  0.0411, -0.0205],
        ...,
        [-0.0275, -0.0641,  0.0142,  ...,  0.0304,  0.0411, -0.0308],
        [ 0.0098,  0.0645, -0.0269,  ...,  0.0551, -0.0002, -0.0472],
        [-0.0107, -0.0179,  0.0186,  ..., -0.0395,  0.0175, -0.0348]],
       requires_grad=True)

encoder.encoders.13.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0251,  0.0470,  0.0176,  ..., -0.0190, -0.0334,  0.0432],
        [-0.0530,  0.0471,  0.0272,  ...,  0.0132, -0.0521, -0.0309],
        [-0.0256, -0.0202,  0.0045,  ...,  0.0455,  0.0179, -0.0511],
        ...,
        [-0.1056, -0.0018, -0.0205,  ..., -0.0050,  0.0278,  0.0054],
        [ 0.0220, -0.0755, -0.0269,  ..., -0.0528,  0.0754,  0.0157],
        [ 0.0325,  0.0014, -0.0489,  ..., -0.0252,  0.0296, -0.0205]],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.8602, 0.6566, 0.6022,  ..., 0.7731, 0.7686, 0.6798],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([ 0.0024, -0.0662, -0.1507,  ..., -0.0592, -0.0362, -0.0216],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8534, 0.7837, 0.7547,  ..., 0.8152, 0.8140, 0.7578],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([ 0.0260, -0.0374,  0.0052,  ..., -0.0041, -0.0215,  0.0462],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5183, 0.4801, 0.4924,  ..., 0.5369, 0.5009, 0.5217],
       requires_grad=True)

encoder.encoders.13.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0852, -0.0714, -0.1110,  ..., -0.0978, -0.0298, -0.0304],
       requires_grad=True)

encoder.encoders.13.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 3.9941e-02, -1.2248e-02, -6.0961e-02,  ..., -2.9257e-02,
          3.3591e-02, -2.6007e-02],
        [-2.6581e-02,  4.1826e-02, -3.4616e-02,  ..., -3.1713e-03,
         -8.7520e-03,  1.6950e-02],
        [ 8.1424e-03,  1.5761e-02,  3.2182e-02,  ..., -5.6744e-02,
         -2.1092e-02, -5.8544e-02],
        ...,
        [ 6.2438e-02,  3.2126e-02, -1.2616e-02,  ..., -1.5531e-02,
         -6.8339e-03,  6.9802e-03],
        [ 1.9857e-03,  1.1001e-02,  1.7496e-02,  ...,  1.2504e-02,
          1.8827e-02,  3.4902e-02],
        [-4.6817e-02, -5.2144e-03,  2.0250e-02,  ...,  7.3805e-02,
         -4.5313e-06, -1.1734e-02]], requires_grad=True)

encoder.encoders.13.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0113, -0.1241,  0.0277,  ..., -0.0157, -0.0086,  0.0176],
        [-0.0230,  0.0140,  0.0346,  ..., -0.0089,  0.0390, -0.0900],
        [ 0.0457,  0.1179,  0.0137,  ..., -0.0425,  0.0325, -0.0188],
        ...,
        [-0.0006, -0.2832,  0.0170,  ..., -0.0228, -0.0549, -0.0693],
        [ 0.0044, -0.1269, -0.0159,  ..., -0.0492,  0.0171, -0.0545],
        [-0.0113,  0.3636,  0.0170,  ..., -0.0403,  0.0095,  0.0553]],
       requires_grad=True)

encoder.encoders.13.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.2861, 1.0334, 0.9422,  ..., 1.2466, 1.2353, 1.0718],
       requires_grad=True)

encoder.encoders.13.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.1077,  0.1413, -0.0246,  ...,  0.1706,  0.0627, -0.0920],
       requires_grad=True)

encoder.encoders.13.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.0640],
         [-0.0849],
         [-0.0410],
         ...,
         [-0.0061],
         [-0.0072],
         [-0.0058]],

        [[-0.0779],
         [ 0.0198],
         [-0.0027],
         ...,
         [-0.0426],
         [-0.0031],
         [ 0.1141]],

        [[ 0.0090],
         [ 0.0203],
         [ 0.0139],
         ...,
         [-0.0093],
         [ 0.0881],
         [-0.0128]],

        ...,

        [[ 0.0819],
         [-0.1099],
         [-0.0520],
         ...,
         [-0.0343],
         [ 0.0365],
         [ 0.0688]],

        [[-0.0245],
         [-0.0748],
         [-0.0263],
         ...,
         [-0.0034],
         [ 0.0987],
         [ 0.0051]],

        [[ 0.0092],
         [-0.0398],
         [ 0.0374],
         ...,
         [-0.0225],
         [ 0.0709],
         [ 0.0534]]], requires_grad=True)

encoder.encoders.13.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-7.1014e-03, -1.5985e-04,  1.8030e-03,  ..., -2.0133e-02,
          -1.8002e-02, -8.1141e-02]],

        [[ 5.2390e-03, -3.7325e-03,  3.3690e-03,  ..., -1.1293e-05,
          -9.0329e-03,  9.1034e-03]],

        [[-4.0831e-02, -4.6862e-03, -2.8367e-02,  ...,  2.3165e-03,
           1.6998e-03,  1.4776e-02]],

        ...,

        [[-2.7158e-02,  5.1601e-03, -1.1840e-02,  ..., -2.0740e-02,
          -1.9483e-02, -4.5722e-02]],

        [[-4.1316e-02, -1.8265e-02, -3.2543e-02,  ..., -1.7113e-03,
           3.7289e-05, -5.4635e-03]],

        [[ 3.9390e-02,  1.0301e-02,  7.7494e-03,  ...,  1.8807e-02,
           1.0245e-02,  6.3403e-02]]], requires_grad=True)

encoder.encoders.13.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([1.0383, 0.9688, 0.9830,  ..., 1.0026, 0.9958, 0.9822],
       requires_grad=True)

encoder.encoders.13.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0795, -0.1113, -0.1185,  ..., -0.0534, -0.0097, -0.0808],
       requires_grad=True)

encoder.encoders.13.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0298],
         [ 0.0216],
         [-0.0249],
         ...,
         [ 0.0197],
         [ 0.0431],
         [ 0.0031]],

        [[-0.0342],
         [ 0.0513],
         [-0.0302],
         ...,
         [-0.0325],
         [-0.0808],
         [ 0.0794]],

        [[-0.0197],
         [ 0.0165],
         [ 0.0164],
         ...,
         [-0.0601],
         [ 0.0613],
         [-0.0264]],

        ...,

        [[ 0.0455],
         [ 0.0724],
         [ 0.0255],
         ...,
         [-0.0305],
         [-0.0278],
         [ 0.0316]],

        [[ 0.0940],
         [-0.0310],
         [-0.0289],
         ...,
         [ 0.0336],
         [ 0.0999],
         [-0.0334]],

        [[ 0.0886],
         [-0.0348],
         [ 0.0395],
         ...,
         [-0.0190],
         [ 0.0772],
         [-0.0713]]], requires_grad=True)

encoder.encoders.13.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.1770, 1.0626, 0.9918,  ..., 1.0994, 1.0431, 0.9872],
       requires_grad=True)

encoder.encoders.13.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.2629,  0.2844,  0.2182,  ...,  0.1239, -0.1781,  0.0587],
       requires_grad=True)

encoder.encoders.13.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0371, -0.0132,  0.0359,  ...,  0.1419,  0.0141, -0.0599],
        [-0.0625,  0.0566, -0.0706,  ...,  0.0032, -0.0225, -0.0237],
        [-0.0208, -0.0191,  0.0248,  ..., -0.0802,  0.0375, -0.0023],
        ...,
        [ 0.0431, -0.0345,  0.0327,  ..., -0.0209,  0.0612, -0.0783],
        [-0.0490,  0.0315,  0.0165,  ..., -0.1059,  0.1979,  0.0040],
        [ 0.0235,  0.0257, -0.0485,  ...,  0.0466,  0.1006,  0.0917]],
       requires_grad=True)

encoder.encoders.13.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0193, -0.0200, -0.0257,  ..., -0.0153, -0.0026, -0.0319],
       requires_grad=True)

encoder.encoders.13.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[-0.0629, -0.0175,  0.0204,  ...,  0.0097,  0.0575,  0.0433],
        [-0.0757,  0.0404,  0.0471,  ..., -0.0393, -0.0011,  0.0397],
        [-0.0038, -0.0501, -0.0713,  ...,  0.0641,  0.1492, -0.0422],
        ...,
        [-0.0066,  0.0473, -0.0692,  ..., -0.0064, -0.0434,  0.0380],
        [ 0.0003,  0.0614, -0.0971,  ...,  0.0772, -0.0314, -0.0182],
        [ 0.0823,  0.1338, -0.0145,  ..., -0.0085, -0.0366, -0.0446]],
       requires_grad=True)

encoder.encoders.13.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0841,  0.0020, -0.0279,  ...,  0.0045, -0.0165, -0.0420],
       requires_grad=True)

encoder.encoders.13.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3039, 1.4086, 1.4913,  ..., 1.2921, 1.2788, 1.3891],
       requires_grad=True)

encoder.encoders.13.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.1887,  0.0088,  0.0478,  ...,  0.0082, -0.0725, -0.0694],
       requires_grad=True)

encoder.encoders.14.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.1255, 0.8932, 0.7986,  ..., 1.0005, 0.9885, 0.9211],
       requires_grad=True)

encoder.encoders.14.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.2415,  0.1281,  0.0296,  ...,  0.0853,  0.0518, -0.0175],
       requires_grad=True)

encoder.encoders.14.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0277, -0.0338, -0.0711,  ..., -0.0125,  0.0368, -0.0459],
        [ 0.0163, -0.0213,  0.0164,  ...,  0.0248,  0.1345, -0.0772],
        [ 0.0257,  0.0133, -0.0405,  ...,  0.0008,  0.0021,  0.0363],
        ...,
        [-0.0074, -0.0183,  0.0956,  ..., -0.0324,  0.0015,  0.0094],
        [ 0.0073,  0.0081, -0.0772,  ..., -0.0448,  0.0082, -0.0577],
        [-0.0034,  0.0287, -0.0109,  ..., -0.0239,  0.0489, -0.1168]],
       requires_grad=True)

encoder.encoders.14.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0285, -0.0142, -0.0252,  ..., -0.0335, -0.0196, -0.0144],
       requires_grad=True)

encoder.encoders.14.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0209,  0.0018, -0.0143,  ..., -0.0583,  0.0291,  0.0384],
        [ 0.0486, -0.0530,  0.0309,  ...,  0.0128, -0.0207,  0.0028],
        [ 0.0471, -0.0148, -0.0121,  ...,  0.0119, -0.0072,  0.0028],
        ...,
        [ 0.0012, -0.0191, -0.0196,  ...,  0.0062, -0.0267,  0.0286],
        [-0.0214,  0.0889, -0.0213,  ..., -0.0916,  0.1174,  0.0659],
        [ 0.0503, -0.0451,  0.0283,  ..., -0.0451,  0.0282, -0.0535]],
       requires_grad=True)

encoder.encoders.14.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0852, -0.0211,  0.0253,  ...,  0.0025, -0.0407, -0.0372],
       requires_grad=True)

encoder.encoders.14.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[ 0.0061,  0.0813, -0.3046,  ...,  0.1523,  0.2793,  0.1701],
        [-0.3276, -0.0065, -0.0198,  ..., -0.1420,  0.3321, -0.2630],
        [-0.3311,  0.1995, -0.2412,  ..., -0.1172, -0.1570,  0.1033],
        ...,
        [-0.3053,  0.1364,  0.1500,  ...,  0.0538,  0.0859, -0.1626],
        [-0.1080, -0.1489, -0.1896,  ..., -0.0577,  0.0267, -0.2405],
        [-0.2985, -0.1411,  0.0681,  ...,  0.1505, -0.2284,  0.0105]],
       requires_grad=True)

encoder.encoders.14.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.2539, -0.0846,  0.3427,  ..., -0.2672, -0.3249, -0.3035],
        [ 0.3435, -0.0079, -0.1729,  ..., -0.0915, -0.1825, -0.0767],
        [ 0.2857, -0.0751, -0.0468,  ..., -0.0497,  0.0552,  0.0596],
        ...,
        [ 0.3171,  0.3194, -0.3077,  ..., -0.0733, -0.1387,  0.3851],
        [-0.1662,  0.1563,  0.1759,  ..., -0.0896,  0.0019, -0.2468],
        [-0.1876, -0.0406,  0.2050,  ..., -0.0524,  0.0974, -0.0356]],
       requires_grad=True)

encoder.encoders.14.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0543,  0.0125, -0.0536,  ...,  0.0363, -0.0358, -0.0076],
        [ 0.0213, -0.0322, -0.0699,  ..., -0.0045,  0.0127,  0.0800],
        [-0.0619, -0.0352, -0.0434,  ..., -0.0621,  0.0622,  0.0504],
        ...,
        [ 0.0049, -0.0409, -0.0142,  ...,  0.0560,  0.0186,  0.0761],
        [-0.0147, -0.0229, -0.0101,  ..., -0.0186, -0.0075, -0.0051],
        [ 0.0203,  0.0396, -0.0432,  ..., -0.0118,  0.0647,  0.0238]],
       requires_grad=True)

encoder.encoders.14.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0220,  0.0427,  0.0052,  ...,  0.0549, -0.1030, -0.0056],
        [-0.0475, -0.0613, -0.0561,  ...,  0.0373, -0.0340,  0.0151],
        [ 0.0742,  0.0311,  0.0155,  ..., -0.0116, -0.0032,  0.0035],
        ...,
        [ 0.0064,  0.0770, -0.0639,  ..., -0.0190,  0.0073,  0.0256],
        [ 0.0678,  0.0367,  0.0020,  ...,  0.0492, -0.0419,  0.0061],
        [-0.0384,  0.0480, -0.0537,  ..., -0.0025,  0.0208, -0.0697]],
       requires_grad=True)

encoder.encoders.14.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 6.1338e-05,  2.2624e-02,  2.1585e-03,  ..., -5.0278e-02,
          1.4934e-02,  2.8384e-02],
        [ 1.8085e-02,  8.7058e-03, -3.2831e-02,  ...,  6.8049e-04,
          1.7746e-02,  2.5753e-02],
        [ 5.8042e-02,  7.7754e-03,  6.6277e-02,  ..., -1.1352e-02,
          1.3108e-02, -5.7559e-02],
        ...,
        [-2.3490e-02,  2.8328e-02,  5.9321e-02,  ..., -5.2571e-02,
          6.5492e-03, -9.7834e-02],
        [-1.5645e-02,  1.0805e-02,  2.1869e-02,  ..., -3.1286e-02,
         -1.9372e-02, -1.7356e-02],
        [ 2.3242e-02, -1.3387e-02,  1.4730e-02,  ...,  4.6511e-02,
         -4.0402e-02,  3.3472e-02]], requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.6921, 0.6181, 0.5527,  ..., 0.6971, 0.6855, 0.6448],
       requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([-0.0262, -0.0204, -0.0119,  ..., -0.0752,  0.0042, -0.0187],
       requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.8028, 0.8283, 0.8260,  ..., 0.8348, 0.8083, 0.7859],
       requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0145,  0.0001, -0.0348,  ...,  0.0004,  0.0205, -0.0016],
       requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.5791, 0.5549, 0.5411,  ..., 0.5664, 0.5638, 0.5801],
       requires_grad=True)

encoder.encoders.14.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.1099, -0.0322, -0.0626,  ..., -0.0349,  0.0535,  0.0276],
       requires_grad=True)

encoder.encoders.14.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0305,  0.0311,  0.0044,  ...,  0.0306, -0.0136,  0.0143],
        [-0.0245,  0.0348, -0.0284,  ..., -0.0067,  0.0047,  0.0531],
        [ 0.0149, -0.1006,  0.0305,  ...,  0.0151,  0.0273,  0.0325],
        ...,
        [-0.0034, -0.0025,  0.0306,  ...,  0.0844, -0.0222, -0.0414],
        [-0.0083, -0.0061,  0.0091,  ..., -0.0537, -0.0532, -0.0718],
        [-0.0207,  0.0165, -0.0121,  ...,  0.0381,  0.0228, -0.0480]],
       requires_grad=True)

encoder.encoders.14.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0679,  0.0189, -0.0186,  ..., -0.0687,  0.0201,  0.0134],
        [-0.0123, -0.0110, -0.0556,  ..., -0.0250, -0.0365,  0.0511],
        [ 0.0190,  0.0840, -0.0565,  ..., -0.0073,  0.0109, -0.0481],
        ...,
        [-0.0080,  0.0373,  0.0095,  ..., -0.0855, -0.0070, -0.0216],
        [-0.0306,  0.0440, -0.0194,  ..., -0.0058,  0.0405, -0.0262],
        [ 0.0066,  0.0317,  0.0067,  ..., -0.0259,  0.0293,  0.0638]],
       requires_grad=True)

encoder.encoders.14.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.2011, 1.1030, 0.9857,  ..., 1.1431, 1.1633, 1.1389],
       requires_grad=True)

encoder.encoders.14.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.1679, -0.1434, -0.0160,  ..., -0.0562, -0.0684, -0.1146],
       requires_grad=True)

encoder.encoders.14.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[-0.1185],
         [ 0.0439],
         [-0.0097],
         ...,
         [-0.0425],
         [-0.0053],
         [-0.0296]],

        [[ 0.0144],
         [-0.0074],
         [ 0.0191],
         ...,
         [ 0.0264],
         [-0.0329],
         [-0.0645]],

        [[ 0.0536],
         [-0.0734],
         [-0.0912],
         ...,
         [ 0.0308],
         [ 0.0094],
         [-0.0152]],

        ...,

        [[-0.0413],
         [-0.1480],
         [-0.0411],
         ...,
         [-0.0507],
         [ 0.1471],
         [-0.0868]],

        [[ 0.0774],
         [ 0.0162],
         [-0.0069],
         ...,
         [-0.0039],
         [ 0.0426],
         [ 0.0592]],

        [[-0.0155],
         [ 0.0347],
         [ 0.0543],
         ...,
         [ 0.0516],
         [-0.0014],
         [ 0.0727]]], requires_grad=True)

encoder.encoders.14.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0032, -0.0074, -0.0151,  ...,  0.0075,  0.0187,  0.0017]],

        [[-0.0068, -0.0137, -0.0327,  ..., -0.0214, -0.0165, -0.0514]],

        [[-0.0015, -0.0091, -0.0026,  ..., -0.0318, -0.0483, -0.0594]],

        ...,

        [[-0.0035, -0.0068, -0.0024,  ..., -0.0123, -0.0067, -0.0019]],

        [[ 0.0231, -0.0088, -0.0122,  ..., -0.0016,  0.0039, -0.0195]],

        [[ 0.0117, -0.0185,  0.0183,  ..., -0.0293, -0.0350, -0.0500]]],
       requires_grad=True)

encoder.encoders.14.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([0.9896, 1.0612, 1.0053,  ..., 1.0727, 0.9666, 0.9692],
       requires_grad=True)

encoder.encoders.14.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0914, -0.0812, -0.1025,  ..., -0.0376, -0.0656, -0.0607],
       requires_grad=True)

encoder.encoders.14.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[-0.0452],
         [ 0.0051],
         [ 0.0578],
         ...,
         [ 0.0360],
         [-0.0695],
         [-0.0308]],

        [[ 0.1022],
         [ 0.1118],
         [-0.0501],
         ...,
         [-0.0764],
         [ 0.0687],
         [ 0.0451]],

        [[ 0.0187],
         [-0.0403],
         [-0.0013],
         ...,
         [-0.1023],
         [-0.0455],
         [ 0.0947]],

        ...,

        [[ 0.0711],
         [-0.0073],
         [ 0.0072],
         ...,
         [ 0.0044],
         [-0.0414],
         [ 0.0377]],

        [[-0.0720],
         [-0.0341],
         [-0.0899],
         ...,
         [ 0.0002],
         [-0.0469],
         [ 0.0121]],

        [[-0.0018],
         [ 0.0472],
         [-0.0432],
         ...,
         [-0.0638],
         [ 0.0225],
         [-0.0727]]], requires_grad=True)

encoder.encoders.14.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.1478, 0.9703, 1.0202,  ..., 1.0648, 1.2245, 1.0931],
       requires_grad=True)

encoder.encoders.14.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.2401, -0.1693,  0.1009,  ...,  0.0252, -0.3201, -0.0838],
       requires_grad=True)

encoder.encoders.14.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.1097,  0.0134, -0.0166,  ..., -0.0520, -0.0102,  0.0503],
        [ 0.0270, -0.0312,  0.0980,  ...,  0.0944, -0.0604, -0.0253],
        [ 0.1276, -0.0350, -0.0611,  ...,  0.0653,  0.0381, -0.0482],
        ...,
        [ 0.0328, -0.0605,  0.0134,  ...,  0.0003,  0.0765,  0.0066],
        [-0.0215,  0.0693, -0.0061,  ...,  0.0583, -0.0682,  0.0775],
        [ 0.0257,  0.0522,  0.0402,  ..., -0.0471,  0.0261, -0.0396]],
       requires_grad=True)

encoder.encoders.14.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0317,  0.0061, -0.0276,  ..., -0.0301, -0.0294, -0.0448],
       requires_grad=True)

encoder.encoders.14.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0445,  0.0016,  0.0097,  ...,  0.0338,  0.0888,  0.0757],
        [ 0.0836, -0.0119, -0.0035,  ..., -0.0154,  0.0108,  0.0439],
        [-0.0529,  0.0424, -0.0022,  ..., -0.0300,  0.0030,  0.0095],
        ...,
        [ 0.0176, -0.0513,  0.1055,  ..., -0.0599, -0.0749, -0.0261],
        [-0.0247,  0.0481,  0.0533,  ..., -0.0417,  0.0209, -0.0662],
        [ 0.1004, -0.0135,  0.0059,  ...,  0.0619,  0.0002, -0.0014]],
       requires_grad=True)

encoder.encoders.14.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0880, -0.0290,  0.0123,  ...,  0.0116, -0.0592, -0.0307],
       requires_grad=True)

encoder.encoders.14.norm_final.weight-torch.Size([1280])-torch.float32
tensor([1.3235, 1.3747, 1.4153,  ..., 1.3189, 1.2951, 1.3354],
       requires_grad=True)

encoder.encoders.14.norm_final.bias-torch.Size([1280])-torch.float32
tensor([-0.1399, -0.0076,  0.0232,  ..., -0.0300, -0.0930, -0.1141],
       requires_grad=True)

encoder.encoders.15.norm_ff_macaron.weight-torch.Size([1280])-torch.float32
tensor([1.1024, 0.9293, 0.9175,  ..., 0.9875, 1.0390, 1.0064],
       requires_grad=True)

encoder.encoders.15.norm_ff_macaron.bias-torch.Size([1280])-torch.float32
tensor([-0.2874, -0.1346,  0.0060,  ..., -0.0056, -0.1217, -0.0718],
       requires_grad=True)

encoder.encoders.15.feed_forward_macaron.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[ 0.0404,  0.0392, -0.0154,  ...,  0.0756,  0.0263,  0.0310],
        [ 0.0087,  0.0127, -0.0021,  ..., -0.0479,  0.0098, -0.0279],
        [-0.0367, -0.0657,  0.0499,  ..., -0.0015,  0.0105,  0.0467],
        ...,
        [-0.0531, -0.0404,  0.0149,  ...,  0.0291,  0.0305, -0.0291],
        [ 0.0112,  0.0228, -0.0764,  ...,  0.0070,  0.0822,  0.0647],
        [-0.0021,  0.0052,  0.0358,  ..., -0.0949,  0.0360,  0.0284]],
       requires_grad=True)

encoder.encoders.15.feed_forward_macaron.w_1.bias-torch.Size([5120])-torch.float32
tensor([ 0.0079, -0.0435, -0.0517,  ..., -0.0401, -0.0369,  0.0039],
       requires_grad=True)

encoder.encoders.15.feed_forward_macaron.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0058, -0.0129, -0.0316,  ..., -0.0818, -0.0439,  0.0186],
        [-0.0544,  0.0262,  0.0174,  ..., -0.0056, -0.1133,  0.0149],
        [ 0.0250,  0.0069, -0.0076,  ..., -0.0600,  0.0115, -0.0255],
        ...,
        [ 0.0564, -0.0658,  0.0382,  ...,  0.0663, -0.0013, -0.0384],
        [-0.0715, -0.0413,  0.0310,  ..., -0.0068,  0.0282, -0.0330],
        [ 0.0076, -0.0309,  0.0007,  ..., -0.0531,  0.0870,  0.0480]],
       requires_grad=True)

encoder.encoders.15.feed_forward_macaron.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.0791,  0.0136,  0.0007,  ...,  0.0024, -0.0880, -0.0821],
       requires_grad=True)

encoder.encoders.15.self_attn.pos_bias_u-torch.Size([20, 64])-torch.float32
tensor([[-0.1553,  0.3293, -0.3554,  ..., -0.2377, -0.0101, -0.0135],
        [-0.0516,  0.3237,  0.0522,  ...,  0.0894, -0.1985, -0.1012],
        [ 0.3389, -0.1938,  0.1606,  ..., -0.2090, -0.1052,  0.2724],
        ...,
        [ 0.0325,  0.1826, -0.1643,  ...,  0.1826, -0.0655,  0.1485],
        [ 0.0064,  0.0775, -0.0935,  ...,  0.1797, -0.1065, -0.0264],
        [-0.0132,  0.2183,  0.2171,  ..., -0.1016, -0.2352, -0.2216]],
       requires_grad=True)

encoder.encoders.15.self_attn.pos_bias_v-torch.Size([20, 64])-torch.float32
tensor([[-0.0092, -0.2497,  0.2289,  ...,  0.2044, -0.1002, -0.0619],
        [ 0.3271,  0.0525,  0.2372,  ..., -0.1301,  0.1912, -0.0094],
        [ 0.0504,  0.1773,  0.0570,  ..., -0.1757,  0.0429,  0.1098],
        ...,
        [-0.0655,  0.0270, -0.1417,  ..., -0.1047, -0.1959,  0.1833],
        [-0.1053,  0.0876, -0.0401,  ...,  0.2908,  0.3270, -0.2756],
        [ 0.2107,  0.1604, -0.0986,  ...,  0.1448,  0.1995,  0.1383]],
       requires_grad=True)

encoder.encoders.15.self_attn.linear_q.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0322,  0.0024, -0.0022,  ..., -0.0477, -0.0401, -0.0464],
        [ 0.0199, -0.0757,  0.0415,  ...,  0.0315, -0.0147, -0.0587],
        [-0.0611,  0.0776, -0.0048,  ...,  0.0056, -0.0040,  0.0005],
        ...,
        [ 0.0400,  0.0330, -0.0288,  ..., -0.0090, -0.0406, -0.0142],
        [ 0.0391, -0.0418, -0.0388,  ...,  0.0674,  0.0059, -0.0076],
        [ 0.0272, -0.0404,  0.0563,  ..., -0.0103, -0.0336,  0.0378]],
       requires_grad=True)

encoder.encoders.15.self_attn.linear_k.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0521,  0.0146,  0.0216,  ..., -0.0086, -0.0045,  0.0394],
        [-0.0336,  0.0334, -0.0356,  ..., -0.0863,  0.0005,  0.0135],
        [-0.0295,  0.0201,  0.0608,  ..., -0.0579,  0.0047, -0.0247],
        ...,
        [-0.0495,  0.0507,  0.0347,  ...,  0.0015, -0.0170, -0.0203],
        [-0.0516, -0.0241, -0.0206,  ..., -0.0505, -0.0359,  0.0378],
        [ 0.0318, -0.0273, -0.0235,  ...,  0.0141, -0.0108, -0.0060]],
       requires_grad=True)

encoder.encoders.15.self_attn.linear_v.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0267, -0.0174, -0.0370,  ..., -0.0007, -0.0169, -0.0904],
        [ 0.0133, -0.0675, -0.0555,  ...,  0.0061, -0.0465, -0.0251],
        [-0.0349, -0.0482,  0.0810,  ...,  0.0109,  0.0267, -0.0252],
        ...,
        [-0.0241,  0.0003, -0.0378,  ..., -0.0273,  0.0333, -0.0003],
        [ 0.0337, -0.0396,  0.0276,  ...,  0.0201, -0.0006, -0.0001],
        [ 0.0128,  0.0542,  0.0287,  ..., -0.0486,  0.0600, -0.0116]],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_q.weight-torch.Size([1280])-torch.float32
tensor([0.6994, 0.6781, 0.5876,  ..., 0.7122, 0.6647, 0.7006],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_q.bias-torch.Size([1280])-torch.float32
tensor([ 0.0119, -0.0244, -0.0450,  ...,  0.0271, -0.0180,  0.0178],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_k.weight-torch.Size([1280])-torch.float32
tensor([0.9151, 0.8666, 0.7634,  ..., 0.8922, 0.8997, 0.9040],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_k.bias-torch.Size([1280])-torch.float32
tensor([-0.0330, -0.0522, -0.0211,  ..., -0.0732, -0.0023, -0.0018],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_v.weight-torch.Size([1280])-torch.float32
tensor([0.6175, 0.6296, 0.6113,  ..., 0.6501, 0.6466, 0.6512],
       requires_grad=True)

encoder.encoders.15.self_attn.layer_norm_v.bias-torch.Size([1280])-torch.float32
tensor([ 0.0544, -0.0080, -0.0250,  ..., -0.0049, -0.0063,  0.0042],
       requires_grad=True)

encoder.encoders.15.self_attn.linear_out.weight-torch.Size([1280, 1280])-torch.float32
tensor([[ 0.0042, -0.0211, -0.0173,  ...,  0.0442,  0.0328,  0.0218],
        [ 0.0255, -0.0344, -0.0766,  ...,  0.0424,  0.0534,  0.0134],
        [ 0.0337,  0.0556,  0.0396,  ...,  0.0187, -0.0709,  0.0379],
        ...,
        [-0.0622, -0.0366,  0.0250,  ...,  0.0266,  0.0011, -0.0265],
        [ 0.0306,  0.0213, -0.0317,  ..., -0.0699, -0.0103, -0.0114],
        [ 0.0416, -0.0323, -0.0195,  ...,  0.0128, -0.1071, -0.0542]],
       requires_grad=True)

encoder.encoders.15.self_attn.linear_pos.weight-torch.Size([1280, 1280])-torch.float32
tensor([[-0.0667, -0.0003,  0.0043,  ..., -0.0543, -0.0069,  0.0295],
        [ 0.0767, -0.0256,  0.1010,  ...,  0.0078,  0.0060,  0.0677],
        [-0.0596, -0.0016, -0.0593,  ...,  0.0093,  0.0337,  0.0603],
        ...,
        [-0.0226, -0.0298, -0.0362,  ...,  0.0750,  0.0504,  0.0154],
        [ 0.0106,  0.0587,  0.0075,  ..., -0.0404, -0.0131,  0.0099],
        [-0.0272, -0.0490, -0.0280,  ...,  0.0403, -0.0099, -0.0240]],
       requires_grad=True)

encoder.encoders.15.norm_conv.weight-torch.Size([1280])-torch.float32
tensor([1.1271, 1.1236, 1.0607,  ..., 1.2295, 1.1977, 1.2087],
       requires_grad=True)

encoder.encoders.15.norm_conv.bias-torch.Size([1280])-torch.float32
tensor([-0.0915,  0.0231, -0.0820,  ..., -0.0794, -0.0107, -0.0717],
       requires_grad=True)

encoder.encoders.15.conv_module.pointwise_conv1.weight-torch.Size([5120, 1280, 1])-torch.float32
tensor([[[ 0.0029],
         [ 0.0481],
         [ 0.0486],
         ...,
         [ 0.0008],
         [-0.0345],
         [ 0.0483]],

        [[-0.0449],
         [ 0.0149],
         [ 0.0622],
         ...,
         [ 0.0724],
         [-0.0693],
         [ 0.0397]],

        [[-0.0506],
         [ 0.0044],
         [ 0.0485],
         ...,
         [-0.0457],
         [-0.0376],
         [-0.0331]],

        ...,

        [[ 0.0462],
         [-0.0356],
         [ 0.0648],
         ...,
         [ 0.1145],
         [-0.0026],
         [-0.0492]],

        [[ 0.0867],
         [ 0.0926],
         [-0.0517],
         ...,
         [ 0.0021],
         [ 0.0627],
         [ 0.0622]],

        [[ 0.0265],
         [-0.0246],
         [-0.0124],
         ...,
         [ 0.0124],
         [-0.0002],
         [-0.0686]]], requires_grad=True)

encoder.encoders.15.conv_module.depthwise_conv.weight-torch.Size([2560, 1, 33])-torch.float32
tensor([[[-0.0124, -0.0139, -0.0089,  ..., -0.0111,  0.0109,  0.0156]],

        [[-0.0388, -0.0285, -0.0477,  ..., -0.0215,  0.0067,  0.0153]],

        [[-0.0158, -0.0005, -0.0117,  ..., -0.0266, -0.0085,  0.0010]],

        ...,

        [[ 0.0117,  0.0019,  0.0182,  ..., -0.0284, -0.0185, -0.0496]],

        [[-0.0068, -0.0322, -0.0144,  ..., -0.0162, -0.0237, -0.0029]],

        [[-0.0237, -0.0254, -0.0125,  ..., -0.0108, -0.0085, -0.0184]]],
       requires_grad=True)

encoder.encoders.15.conv_module.norm.weight-torch.Size([2560])-torch.float32
tensor([0.9710, 0.9905, 1.0345,  ..., 1.0157, 1.0097, 0.9831],
       requires_grad=True)

encoder.encoders.15.conv_module.norm.bias-torch.Size([2560])-torch.float32
tensor([-0.0876, -0.0600, -0.0595,  ..., -0.0598, -0.0557, -0.0630],
       requires_grad=True)

encoder.encoders.15.conv_module.pointwise_conv2.weight-torch.Size([1280, 2560, 1])-torch.float32
tensor([[[ 0.0160],
         [-0.0048],
         [-0.0102],
         ...,
         [ 0.0154],
         [-0.0719],
         [-0.0626]],

        [[-0.0096],
         [ 0.0360],
         [-0.0108],
         ...,
         [ 0.0859],
         [ 0.0163],
         [-0.0386]],

        [[-0.0355],
         [-0.0366],
         [-0.0352],
         ...,
         [-0.0251],
         [-0.0006],
         [-0.0732]],

        ...,

        [[ 0.0279],
         [ 0.0273],
         [-0.0500],
         ...,
         [ 0.0112],
         [ 0.0437],
         [-0.1378]],

        [[-0.0562],
         [-0.0769],
         [-0.0617],
         ...,
         [ 0.0717],
         [-0.0659],
         [-0.0637]],

        [[ 0.0778],
         [-0.0634],
         [ 0.0168],
         ...,
         [ 0.0756],
         [ 0.0030],
         [ 0.0169]]], requires_grad=True)

encoder.encoders.15.norm_ff.weight-torch.Size([1280])-torch.float32
tensor([1.1133, 1.1245, 1.0759,  ..., 1.2147, 1.2728, 1.2305],
       requires_grad=True)

encoder.encoders.15.norm_ff.bias-torch.Size([1280])-torch.float32
tensor([-0.0370,  0.0720,  0.0641,  ..., -0.1279, -0.1719, -0.1422],
       requires_grad=True)

encoder.encoders.15.feed_forward.w_1.weight-torch.Size([5120, 1280])-torch.float32
tensor([[-0.0288,  0.0252,  0.0208,  ...,  0.0816, -0.0312,  0.0326],
        [ 0.0383, -0.0774,  0.0467,  ..., -0.0387,  0.0709,  0.0226],
        [-0.0599, -0.0901,  0.0359,  ...,  0.0504, -0.0261, -0.0178],
        ...,
        [-0.0014, -0.0536, -0.1070,  ..., -0.0383,  0.0204, -0.0381],
        [ 0.0523, -0.0864,  0.0855,  ...,  0.0298,  0.0212,  0.0136],
        [ 0.0010,  0.0954, -0.0065,  ..., -0.0272, -0.0521, -0.0763]],
       requires_grad=True)

encoder.encoders.15.feed_forward.w_1.bias-torch.Size([5120])-torch.float32
tensor([-0.0056, -0.0485, -0.0564,  ...,  0.0037, -0.0129,  0.0043],
       requires_grad=True)

encoder.encoders.15.feed_forward.w_2.weight-torch.Size([1280, 5120])-torch.float32
tensor([[ 0.0082,  0.0035, -0.0670,  ..., -0.0386,  0.0226, -0.0403],
        [ 0.0011, -0.0007,  0.0486,  ...,  0.0077,  0.0433, -0.0462],
        [-0.0400,  0.0082,  0.0117,  ..., -0.0027, -0.0228, -0.0045],
        ...,
        [-0.0661,  0.0756, -0.0555,  ...,  0.0072,  0.0992, -0.0665],
        [ 0.0088, -0.0190,  0.0097,  ..., -0.0044,  0.0010, -0.0230],
        [ 0.0172,  0.0701, -0.0429,  ...,  0.0070, -0.0122, -0.0852]],
       requires_grad=True)

encoder.encoders.15.feed_forward.w_2.bias-torch.Size([1280])-torch.float32
tensor([-0.1033, -0.0339, -0.0162,  ..., -0.0404,  0.0138, -0.0640],
       requires_grad=True)

encoder.encoders.15.norm_final.weight-torch.Size([1280])-torch.float32
tensor([0.6705, 0.7086, 0.6973,  ..., 0.6836, 0.6640, 0.6913],
       requires_grad=True)

encoder.encoders.15.norm_final.bias-torch.Size([1280])-torch.float32
tensor([ 0.0019, -0.0434, -0.0445,  ..., -0.0097,  0.0054, -0.0127],
       requires_grad=True)

